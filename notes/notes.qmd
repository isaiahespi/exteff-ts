---
title: "notes"
---

## Tentative Abstract

It is not sufficiently clear what is being measured by external political efficacy measurement items. Not only is the conceptual definition of external efficacy conflated with similar concepts, empirical results are too closely related to satisfactorily distinguish external efficacy as a distinct component on par with internal political efficacy. @chamberlain2012 attempted to address this problem in the hopes that results would elucidate the meaning from the measurement. Drawing from the usual conceptual definition of external efficacy, Chamberlain hypothesized that external efficacy beliefs would be dynamically responsive to changes in the political environment. Results from the study could not reject the null; aggregated external efficacy was apparently unresponsive across time to predictors representing the political environment. Extending his analysis to include years since the original study partially replicates the original findings. Following the same methodology, updated results show that external efficacy in the aggregate is positively associated with presidential approval ratings with a one year lag. However, similar to the previous results, statistical significance disappears upon inclusion of consumer sentiment and trust in government. Such results pose a severe challenge to the validity of measurement for external political efficacy. However, results from then and now are contestable on the grounds that the predictors of the analysis are untenable as proxies for the political environment. To conduct a fairer test of the meaning and measurement of external efficacy, I examine whether external efficacy has been responsive to changes to the political environment since 2013 after the Supreme Court decision in *Shelby County v. Holder* which ruled Section 4(b) of the Voting Rights Act unconstitutional.


## An expanded brief of the theory

-   For his part, Chamberlain deserves praise for considering that which prior scholars had not considered. It makes sense that a person's judgement of their efficacy within a particular space would be affected by changes to that space; in broad strokes the theory is quite sensible.
    -   It goes without saying that conditions of the political environment have definitely changed overtime, especially within the short time period that the ANES began including political efficacy items. As such, a properly constructed survey instrument would capture the public's evaluation of their capacity as conditions of the political environment changed over time.

-   To put it more formally: given that external political efficacy is based on a person's evaluation of the external political environment, and in so far as the external efficacy survey items validly cohere to the given meaning of the construct, then changes to the political environment should result in movement of external efficacy in the aggregate over time. If shifts in the external efficacy index are not significantly associated with factors reflective of the political context across time, then the external efficacy survey items do not coherently correspond with the given meaning of the construct, rendering the survey items and index invalid.


-   Updating the concept and theory; given that a person's capacity (modal condition) as a political actor is determined by the external political environment...


## More On the Concept

-   If internal political efficacy refers to a person's self-evaluation of their ***competence*** as an individual political actor to engage in the political process meant to influence the outcomes and shape conditions thereof, then external political efficacy would refer to a person's evaluation of their ***capacity*** to influence the outcomes of the political process and shape conditions of the political environment.

-   It is vital to understand that one's judgement of their own political competence is determined by *internal conditions*, otherwise understood as individual differences; internal efficacy is a certain kind of self-esteem conditioned upon various internal factors such as level of education, personal confidence, political interest, knowledge of political affairs, government processes, and so on.

-   In contrast, one's judgement of their own capacity as a political actor is determined by the external political conditions in which they are subject on par with other political actors of common status. Thus, one's appraisal of their own external political efficacy must directly reference the extent of their own capacity 1) as a political equal 2) to shape conditions of the political environment 3) as determined by the very political conditions in which they are subject. 

-   This appraisal of external efficacy is made of themselves as a political actor which is also necessarily an appraisal of all political actors subject to the same conditions (hence "People like me"). Thus, when a person evaluates their capacity as a citizen, they necessarily evaluate the capacity of all citizens of equal status strictly because said evaluation is not based upon individual differences, but rather based on that in which they do not differ: the conditions of their common status. Thus, in the first sense, external efficacy is an appraisal of their capacity to shape the political environment as subjects of that political environment. 
    -   But there's more to it than that, as this isn't to say that the citizenship renders all citizens of equal capacity to shape the political environment. Citizenship is merely used as an example to illustrate the point. Indeed, the status of citizen does not necessarily guarantee equal conditions placed on one's capacity. For one, many citizens in the United States are incapacitated by their disenfranchisement in accordance with laws of a particular state. For two, many citizens of the United States who reside in non-state territories are unable to engage or participate in the governance of the political environment in which their citizenship pertains. In fact, the right of citizens to vote is not constitutionally protected considering that the United States constitution very meekly prohibits the United States or any State from denying or abridging the right of citizens to vote on account of particular conditions. For instance, the fifteenth amendment prohibits denial or abridgment of the right of citizens to vote on account of race, color, or previous condition of servitude---but not on current condition of servitude.

-   This is worthy of emphasis: the capacity (to shape the political environment) of the individual as a political actor does not differ from other political actors who are all subject to the very same conditions. 
-   Where internal efficacy is a metric of one's self-assessed competence based on their individuality, external efficacy is one's appraisal of the public's capacity to shape the political environment under conditions which they share in common as subjects.  

-   Common to both (supposed) dimensions of political efficacy is the common purpose, or point, of political participation and engagement, which is ultimately to shape the conditions of the political environment. Prominent research and scholarship of yesteryear has unwittingly, but detrimentally, constrained the whole point of engagement and participation to imposing influence on the considerations of government officials. That is to say, previous scholars have stated that the point of participating in the political process is, at most, meant to influence those political actors who govern rather than to govern as political actors. Regardless of the political system or regime type, the purpose of political action is to shape the political environment and conditions thereof.



## Writing 

The question posed and investigated by @chamberlain2012 was whether external political efficacy in the aggregate is responsive to changes in the political environment. His reported findings suggest no. However, the predictors (explanatory variables) chosen as factors of the external political environment were not, indeed, factors of the political context. That is, the factors selected as predictors in Chamberlain's model can not be understood as representative, in part or in whole, of the political environment. Said predictor variables, of which there were three, were not independent of the individual nor could they be understood as representative of the political context at point in time. 

He critiques the reliance or use of structural equal modeling in development of the measurement instrument on the basis that the question wording and definition of external political efficacy "implies a dynamic relationship" [-@chamberlain2012, 119], suggesting that novel measurement items would better cohere to the conceptual understanding of external efficacy if results captured individual's response to variation in government performance and economic conditions in retrospect. In other words, if external efficacy items measured perceptions of government responsiveness in reference to relatively recent actions of political actors, political institutions, and ever-changing economic conditions, then external efficacy in the aggregate would appropriately respond the such dynamic variation over time. 

Accordingly, Chamberlain's study is intended to test the validity of the construct in reference to how it is understood, defined, and measured in political science and public opinion. However, while sensible, the study misses the mark in a few clear ways;  

- Chamberlain used predictors which were not tenable as representative of the external political environment. Such contextual factors (or variables) are those independent of the individual, yet the predictors of the original study were attitudinal and not at all coherent with the proposed theory of the study. 
- given the understanding of external political efficacy, shifts in the external political context 


In addition, while Chamberlain was right to call into question the validity of the concept and measure of external political efficacy, his proposed 'new test for external efficacy' only *further* deviates from a cogent understanding of external efficacy. That is, as an underlying, latent, psychological factor that generalizes across (influences) responses to attitudinal survey items and individual behaviors. 

The subtly of the issue is that this conception detracts from any coherence as a dimension of political efficacy or as a construct coherent with the meaning of efficacy. 

This understanding of external political efficacy has little to nothing to do with an individual's appraisal of their ability to affect, change, or control the political environment in which they are subject. Indeed, under Chamberlain's notional framework, external political efficacy stands as more of a performance review on government actors, institutions, and the economy writ large; a more appropriate moniker would be 'political satisfaction' or something of the sort.  

## 

::: {.callout-note}
The below was written on 2025-03-25
:::

One clear case is the controversial redistricting of Congressional districts in GA. If I recall correctly, the issue arose shortly after the 2010 Census and continued on up to 2020 at least. Although the public is not commonly sensitive to immediate shifts or changes to the size, shape, and composition of Congressional districts in general, nor their own specifically, the GA case renders the issue salient and substantial to voters in the affected districts. 

-  Yet the GA case also potentially imparts influence among the public at the national level given that suspect redistricting practices conveys multiple messages about the state of the union and conditions therein. For one, undermining the Voting Rights Act, whether expressive or rendered *de jure* by judicial decision, is apt to impose influence upon one's sense of external efficacy---the extent to which they are capable of shaping the political context. Second, politicking from the bench from supposed politically impartial Justices imparts both obstacles and avenues depending on one's political inclinations and ambitions. However, although changes to who currently sits on the bench of the Supreme Court are not necessarily changes to conditions of the political environment, judicial appointments likely signal such change as more likely in the future. 

- Though one need not consider whether particular nominees or appointments influence external efficacy, because the decisions of the Justices shape and re-shape conditions of the political environment every year. While normally the effect of a ruling on public opinion comes down to issue salience among the public, i.e., whether the general public is aware, interested, or perturbed by Supreme Court rulings, the shift in the political reality is substantial and directly attributable to rulings by the Supreme Court. The repeal of Roe v. Wade changed conditions across multiple states but not uniformly as state governments were endowed with novel possibilities for action formerly prohibited as violations to individual privacy implied by the U.S. Constitution. Yet as it concerns external efficacy, we should not expect external efficacy to vary based on the ruling alone, but based on whether the state changed conditions of the political environment subsequent to the ruling of the Supreme Court. Some states enacted restrictive prohibitions, others codified legal protections in their state constitutions, whereas some (presumably) have not instituted changes in law or enforcement. 

- In addition, in some states where changes to abortion laws took place, such changes were initiated or assented to by the public as either citizen initiatives to amend the state constitution or as referendums to do the same. In other states, the state legislature acted without input or initiation by the public^[In some cases, certain state laws were triggered to go into effect only in case the substantial ruling of *Roe v. Wade* was ever over-turned by the Supreme Court. Such cases sought to prohibit abortion, as state legislatures are not beholden to rulings from the court in order to instantiate, codify, or expand upon individual rights within the bounds of federal law but only to repeal, prohibit, or constrain individual liberties.] in concert with the state executive to either codify protections or prohibitions. 

Given the variation in how changes to the political environment came about, who initiated (public or government actors), and public opinion on the issue at the time, we would expect current indices and measures of external efficacy to be contingent on one's particular position when it comes to the issue at hand, yet independent of how the change came to pass and whether public input was an essential component. That is to say, given contemporary measures, I expect external political efficacy to be independent of (i.e., unrelated, not significantly associated with) the conditions of the people's popular capacity to shape the political environment, but instead strongly associated with partisanship and issue position---in particular whether one endorses a pro-choice or pro-life position on abortion in states where changes took place, and congruence of partisan identification with the partisan makeup of the state government.

Supporting results would invalidate the contemporary conception and measure of external political efficacy as coherent and valid, respectively. To be clear, it would be a mistake to interpret findings as indicative of public opinion, individual dispositions, or as saying something about the public generally if our instruments for measuring one thing are, not only inadequate, but instead measure something else entirely. That is, it would be wrong to conclude that the people are insensitive to changes in the political environment when we have no instruments available to measure their sensitivity in that respect. Since we have no ability to assess their appraisal of their own capacity to shape their political environment, we cannot conclude whether or not they are attuned to conditions of the political environment in which they are subject.        




# 

**External efficacy**--- refers to citizens' perceptions of the "responsiveness of political bodies and actors to citizens' demands (e.g., Balch 1974; Converse 1972)" [@craig1990, 290]

**External Political efficacy**
1.  "People like me don't have any say about what the government does." [NOSAY]

2.  "I don't think public officials care much what people like me think." [NOCARE]


### Multiple versions tested in the ANES 2008

[vers.C] E9c. 'Public officials don't care much what people like me think.'
[vers.C] E9d. 'People like me don't have any say about what the government does.'
[1= strong agree…5=strong disagree, -1=inap, -8=dk, -9=refused]


[vers.D] E10c. How much do public officials care what people like you think?
[vers.D] E10d. How much can people like you affect what the government does?
[1 = great deal…5=not at all,  -1=inap, -8=dk, -9=refused]




## Potential text and garbage

one of the issues raised by @chamberlain2012 was that, "aggregate external political efficacy does not appear to be dynamically responsive to changes in the political environment" [-@chamberlain2012, 125]. This might not be problematic if we suppose that people, generally, are insensitive to changes in the political environment. Surely an argument can be made there, but it is predicated on the notion that the measurement of external political efficacy is solid---i.e., sufficiently measures the concept in question. However, we can't presume as such for the simple issue that we don't really have a good, distinct, proper, solid conceptual definition for external political efficacy. Never mind it's relationship to its sister component internal political efficacy; external political efficacy is so conceptually ambiguous that it is sufficient to stand as whatever isn't internal political efficacy.

We would expect external efficacy to be conceived as an individual-level attitude reflective of (based upon) the variable conditions of the external political environment from the perspective of the subject. However, not only is it **not** conceptualized as such, it is not measured in accordance with that conceptual understanding. Rather, external efficacy is usually confused with responsive government. To illustrate metaphorically, external efficacy is defined as the extent to which a person believes their voice echoes in the cave; those who report hearing less of an echo report lower external efficacy. 

That metaphorical description of external political efficacy is just as good as the standard contemporary definition, "...beliefs about the responsiveness of governmental authorities and institutions to citizen demands" [@craig1990, 290; @niemi1991a, 1408]. However, the measures don't ask respondents to evaluate and report the extent to which they think governmental authorities and institutions respond to national public opinion or grievances. Nor do items make clear what it means for the government or institutions to be responsive. Rather, the two survey items that purport to measure external political efficacy are, 1) "People like me don't have any say about what the government does." \[NOSAY\], and 2) "I don't think public officials care much what people like me think." \[NOCARE\]. Response options usually range on a 5-point or 7-point scale from strongly agree to strongly disagree. From that, we can see that "having a say about what the government does" and "what people like me think" comprises "citizen demands" in the conceptual definition. The measurement items better reflect a judgement about how aligned government action and concern is with the individual's general political predilections and sentiment.

@chamberlain2012 is an important article that demonstrates the weakness and ill-fit of both the concept and measurement of external political efficacy. Validity of measurement of the concept appeared hard to ignore as Chamberlain recognized measurement problems at the outset. Importantly, he takes note that the original authors of the survey items used to measure external political efficacy were unsure of what those items actually measure. 

> “...[Niemi et al. (1991)]  note that the two questions "are tapping something quite different from the new efficacy questions" but that "whatever they do measure. . .they do not measure internal efficacy" (italics in original) (Niemi et al. 1991, p. 1412).3 Thus, the authors who created the measure are unclear as to what it really measures.” [@chamberlain2012, 118]

He also noted that the ANES has adopted and still utilize this definition and measurement for external political efficacy, indicating scholarly acceptance. Chamberlain cites to other research where external political efficacy is used as a meaningful variable construct as evidence that its conventional measurement has generally been accepted in research and scholarship.

Rather than propose new items or offer a new conceptual understanding, Chamberlain attempts to discern whether this individual-level construct is even sensitive to external factors in the environment as would be expected given its current conception and measurement. That is, whether aggregate levels of external political efficacy shift over time in response to dynamic changes in the environment.

> “External efficacy is a measure that takes into account a government's responsiveness; people should draw on past experiences with government before assessing whether they have any effect on its behavior. Past government performance, and the economic conditions it presides over, should have an effect on changes to external efficacy over time.” [@chamberlain2012, 119]

What is notable is that he takes into account the definition of the conception and wording of the measurement items, as both imply that an individual must draw upon the past in order to evaluate the degree to which they believe the government is responsive to public demands. In other words, external political efficacy is conceived as an individual’s judgement of how responsive the government is with respect to how responsive government has been.

Although the definition of external efficacy situates public demands as that reference point from which to judge government responsiveness, the survey items don’t make the efficacy of public action or expression the focal point of the appraisal. Instead, the items segregate the public into “People like me” to compare against an implicit “others unlike me”. The difficulty in this is just that each individual is poised to have a different reference point for “People like me” to judge how far government outcomes deviates from their demands. So rather than government responsiveness to *public demands*, the items already deviate from the concept by having individual’s appraise government official responsiveness to demands of people like me.

The second issue is that what qualifies as government responsiveness is undefined nor made concrete in the survey items. There’s two things the items have respondents consider: what the government does and what government officials care about. The former may be readily understood as, broadly, outcomes of government and politics. However to the individual respondent, what the government does is not necessarily the official productions of government, e.g., legislation, policy, resolution, court opinions, orders, etc. Rather, what the government does is broad enough to include practically anything that government officials do. The latter, however, forces the respondent to consider what, or who, is important to government officials generally. The item refers to ‘Public officials’ in the general sense, and so an individual either bases their judgement on a hasty generalization about what or who all government officials care about, or bases consideration on only a particular subset of public officials. More importantly, however, is that the focal point of this item does not lead respondents to appraise the *efficacy of their actions* or expressions on the concerns of public officials. In other words, the items have respondents assess the levels of concern of public officials, but they do not evaluate the efficacy of their intervention on those levels of concern. This would be akin to ascertaining blood sugar levels but not the effect of one’s diet on blood sugar levels.

The time-series analysis is an interesting way to assess whether external efficacy moves with shifts of the external environment. However, what this implies is that external efficacy is linked to particular factors of the environment chosen by the researcher.


Note too that external efficacy and internal efficacy are treated as distinct *components* rather than latent factors. This means that, as scores are linear sum scores of responses to the respective items wherein all variance is preserved. Correlation is expected and found [@morrell2003] when internal and external efficacy are considered to be distinct latent factors. However, the usual method is to treat internal and external efficacy variables as components manifested from a linear sum of responses to their respective items rather than as latent factors.  

To put in other words, conceptually, internal and external efficacy are theorized as latent factors which influence an individual's responses to the respective survey items, but individual scores are computed as though internal and external efficacy are components manifested by the given items. This may be fine, more or less, for research concerning internal political efficacy given the sufficiently high factor loadings and support that the items indicate a homogeneous underlying factor. However, the same strategy is more objectionable given that the measure of external political efficacy consists of only two items. In addition, it is common for researchers to modify item wording or add in novel items not yet tested or validated when it suits their research endeavors [@wolak2018].

Factor analysis has been used as a method to validate the items as imperfect indicators of two separate but related homogeneous constructs [@niemi1991a; @morrell2003], but researchers still utilize methods that assume perfect measurement of the constructs in order to generate individual scores. 

[Even still, factor analysis of all the conventional internal and external efficacy items demonstrates that a significant amount of variance is attributable to a common factor, but the factor loadings of the external efficacy items on their own distinct factor are insufficient to validate that the items measure what they purport to measure.]

... 


Yet therein lies the problem: external efficacy **is not** understood in the literature as a belief about one's ability to impose effects upon the political environment, and so changes to particular external conditions shouldn't have any effect on one's external efficacy unless the conditions in question relate directly to the people's capacity to effectuate change within or upon the political realm. 

If we expect an increase after some shift of some arbitrary predictor variable such as Presidential approval, then we betray the conception of external efficacy as a measure of satisfaction and not an appraisal of popular capacity. The crucial missing element is that we don't know whether, nor to what extent, people believe they can shape their political environment as a popular political actor.


If the political environment does change in one way or another, why would we have any expectation that the people's perception of their capability to shape that environment would change? That is, in what direction would we expect aggregate external efficacy to shift if the external political context does change in accordance with popular political activity? We would either expect 
  1)  external efficacy to remain steady as belief that the system is receptive to popular input holds *as expected* (i.e., the system works as expected, no surprise here); or 
  2)  aggregate external efficacy to increase proportionate to the *unexpected* change that comes about by popular activity; or
  3)  external efficacy would decrease in response to changes in the political environment that result in spite of popular political activity.
  
Thus, if the people were to unify as one to dramatically shift, change, or reform some aspect of the political system, then we'd expect the shift in aggregate external efficacy to increase in relation to the baseline reference of external efficacy in the aggregate prior to the change taking place, and only insofar as the change that comes about is attributed to the people's popular political activity.


## Note on the current release of the ANES CDF data set

:::{.callout-note}
The following is pulled directly from the ANES Time Series CDF Code book
:::

Data used in the ANES Guide are weighted with VCF0009z, VCF0010z, VCF0011z

> "The current release (2022-09-16) of the Cumulative Data File contains 1030
variables. Sixty-nine variables have been updated to include data from the
2020 Time Series study. Three (VCF9056, VCF9057, and VCF9060) have been
revised to include the full range (0-100) of feeling thermometer values with
missing data being recoded to values greater than 900. This release also
includes a full sample post-election weight variable (VCF9999), for study years
and cases for which a post-election weight is available." (ANES 2022, 3)

When using the combined sample, one of the following three CDF weight variables can apply:

- VCF0009z
- VCF0010z
- VCF0011z

Since I am using the combined sample (FTF and web) from 2012, and the External efficacy items indicate `Type 0` for 1970 time series, then I must use the variable `VCF0009z`

## The problem of the coding scheme of the external efficacy index

External political efficacy, in the Time Series Cumulative Data file (CDF), is captured by two variables which are used as components to construct the external efficacy index variable. The external efficacy index variable (VCF0648) is a composite of NOCARE (VCF0609) and NOSAY (VCF0613). Values of the index reflect an average, ranging from 0 to 100. The values of the index variable in the dataset, however, reflect the coding scheme of an ordinal categorical variable where the value codes of each category are arbitrary. That is to say, the response categories for the NOCARE and NOSAY variables are collapsed from the original survey data of a particular year and re-coded such that "Strongly agree" or "agree/agree somewhat" = 1 , "strongly disagree" or "disagree/disagree somewhat" = 2, "neither agree nor disagree"^[for years 1988 and later only] = 3, and "Don't know" = 9. These re-coded variables are included in the CDF data, which I refer to as NOCARE (VCF0609) and NOSAY (VCF0613). Then, these re-coded variables are again re-coded and combined into the external efficacy index variable, where 1 = 0, 2 = 100, and 3 = 50. Presuming the appropriate weights have been applied, the values of the index are totaled, then divided by the number of valid responses (for that year, presumably), and finally rounded to the nearest integer.

A score of 0 indicates the "least efficacious", corresponding with those who *agreed* (strongly or somewhat) with item statements from NOSAY and NOCARE. A score of 100 on the index reflects "most efficacious", corresponding to those who disagreed (strongly or somewhat) with the external efficacy item statements. A score of 50 supposedly reflects a middling point on the index. Thus an average score of the external efficacy index presumably reflects the average external efficacy of the nationally representative survey sample for a given year.  

However, it is easy to confuse the coding scheme of response categories as reflective of values of the index, which is an average. The variable for the external efficacy index (VCF0648) is coded such that agree = 0, disagree = 100, and neither agree nor disagree = 50. However, given that an individual may agree with one statement, but disagree with the other, all combinations of responses between NOSAY and NOCARE item statements would need to be accounted for by the coding scheme. Thus, responding with "neither agree nor disagree" to one but "disagree" to the other item statement corresponds to a value code of 75; whereas agreement with one but "neither" with the other corresponds to a value code of 25.

The coding scheme is complicated by situating "neither agree nor disagree" as a middling value while treating the index as a unipolar scale. For instance, a person who responds with "neither agree nor disagree" to both items would obtain a raw score of 50, whereas full agreement with both external efficacy item statements would amount to 0. Thus, a person who neither agrees nor disagrees with both external efficacy item statements would be considered more externally efficacious (so to speak) than a person who agrees with both statements; the coding scheme of the index takes "neither agree nor disagree" responses as positive evidence of external efficacy despite respondents making no such expression. This coding scheme undermines the credibility of the index itself, further complicating the meaning and measure of external political efficacy.

The justification for coding "Neither agree nor disagree" responses as 50 presupposes a unipolar scale for the external efficacy index. However, the response categories presented to respondents are bipolar, especially for items presented in 1988 and later. Thus, a person who neither agrees nor disagrees with both NOCARE and NOSAY external efficacy item statements is considered as externally efficacious by default. Subsequently, as raw values are totaled and then averaged to create the index, the average level is inflated as any "neither" responses contribute positively to the average, giving a false impression of aggregate external political efficacy in the United States.

```{r}
#| label: tbl-2
#| results: asis


# create a small dataframe (tribble) that represents the potential values of the
# external efficacy index
coding_scheme <- tibble::tribble(
  ~NOSAY,         ~NOCARE,        ~'NOSAY+NOCARE',                ~EEINDEX, ~INTERPRETATION,
  '[0] NA',       '[1] agree',    '[0] NA AND [1] agree',          0, "Not Efficacious at all",
  '[0] NA',       '[3] neither',  '[0] NA AND [3] neither',        50, "Moderately Efficacious",
  '[0] NA',       '[2] disagree', '[0] NA AND [2] disagree',       100, "Fully Efficacious",
  '[1] agree',    '[0] NA',       '[0] NA AND [1] agree',          0, "Not Efficacious at all",
  '[1] agree',    '[1] agree',    '[1] agree AND [1] agree',       0, "Not Efficacious at all",
  '[1] agree',    '[3] neither',  '[1] agree AND [3] neither',     25, "A little Efficacious",
  '[1] agree',    '[2] disagree', '[1] agree AND [2] disagree',    50, "Moderately Efficacious",
  '[2] disagree', '[0] NA',       '[2] disagree AND [0] NA',       100,"Fully Efficacious",
  '[2] disagree', '[1] agree',    '[2] disagree AND [1] agree',    50,"Moderately Efficacious",
  '[2] disagree', '[3] neither',  '[2] disagree AND [3] neither',  75, "Very Efficacious",
  '[2] disagree', '[2] disagree', '[2] disagree AND [2] disagree', 100,"Fully Efficacious",
  '[3] neither',  '[0] NA',       '[3] neither AND [0] NA',        50,"Moderately Efficacious",
  '[3] neither',  '[1] agree',    '[3] neither AND [1] agree',     25, "A little Efficacious",
  '[3] neither',  '[2] disagree', '[3] neither AND [2] disagree',  75, "Very Efficacious",
  '[3] neither',  '[3] neither',  '[3] neither AND [3] neither',   50,"Moderately Efficacious",
) 

# print a grid style markdown table of the coding scheme and potential values
pander::pandoc.table(coding_scheme, style = "grid", justify = "llcrl",
                     split.tables = Inf)


```


## Obtaining historical presidential approval ratings from Gallup Org

One of Chamberlain's predictor variables is a yearly average of monthly polls from the Gallup Polling Organization. This data, however, is not super easy to obtain like ANES data usually is; there is no ready-made cumulative time series data file freely available. Gallup does provide access to such data via its platform 'Gallup Analytics', but access is limited to those who subscribe or pay for such access. One might have access through an affiliate university. Mine didn't. An alternative is to gather Gallup survey data provided through the [Roper Center's iPoll database](https://ropercenter.cornell.edu/ipoll/), though again, access is limited to those who subscribe or are affiliated with a subscribing university. Fortunately, mine did. 

Drawing from the Roper iPoll database, I searched for presidential approval ratings by entering in a verbatim search query of the typical question posed by monthly Gallup polls, "Do you approve or disapprove of the way...is handling his job as president". I then filtered results by organization (Gallup) and topic (Presidential approval). From the results that populated, I downloaded topline response data pertaining to the questions rather than entire data sets for each survey where the approval question was asked^[To be clear, the Roper iPoll database permits those with access to download entire survey data sets when available. Alternatively, users are also able to download topline response data pertaining to particular questions of interest from a multitude of surveys. Simply, a percentage proportion of a given sample who selected a particular response category, appropriately weighted in accordance with the survey study. Given that I was seeking presidential approval ratings spanning almost a century, it was best to forego downloading every data set available for monthly Gallup polls from 1938 onward.]. I download the topline data as both a .csv file and .txt file. I extracted Roper archive numbers and citations for each data set from the .txt file and merged that information into a single data set.  

Just to note, I initially attempted to download and rely on the Roper Trends data provided, but this trends data was incomplete and. Approval ratings for both Ronald Reagan and George Bush (Sr.) were missing entirely from the available Roper Trends data. Ultimately, the Roper Trends data was insufficiently useful as a data source for my purposes.

Since I have no reference for the Gallup approval ratings data Chamberlain used, I cannot be entirely sure that the data I have matches or even approximates the presidential approval ratings data he gathered (sure, I could attempt to contact him, but that's not the point). I attempted to approximate presidential approval ratings I managed to find presented by other sources and publications. The only references I could find were 

1)  Presidential Approval ratings from [Gallup Historical Statistics and Trends](https://news.gallup.com/poll/116677/presidential-approval-ratings-gallup-historical-statistics-trends.aspx) (which did allow me to download monthly approval ratings for each President, but excluded any 'Disapproval" and "undecided" or "unsure" response data); 

2)  Presidential job approval data derived from Gallup from [The American Presidency Project](https://www.presidency.ucsb.edu/) 
  2a) access to Google sheets data spreadsheet [here](https://www.presidency.ucsb.edu/statistics/data/presidential-job-approval)
  2b) presentation of table and trend line graphs for each president [here](https://www.presidency.ucsb.edu/statistics/data/presidential-job-approval-all-data)

3)  A replication data set for a paper by Ghitza et al. (2022) in the Harvard Dataverse that contained historical Gallup polling data.

First, I sought to determine whether the ratings data from each source matched each other. None of the data completely matched each other one-to-one. One issue was that the actual Gallup poll/survey/study source citation was not included in any of the data sets. Some provided question reference IDs which should have worked to locate the particular data sets from which ratings data was drawn, but many of the question reference IDs did not match. Moreover, approval ratings for seemingly matched Gallup polls differed between data sets. The difference wasn't usually large, but deviated by a percentage point in many cases. In addition, for many cases, the start and end dates of particular surveys did not match between data sets. 

I was only able to partially match the approval ratings from the other sources with the Gallup data I gleaned from Roper iPOLL. I was not able to fully replicate the Gallup data to match approval ratings found elsewhere. 


## 2025-04-16

We would expect external efficacy to drop upon increased constraints placed upon a group or population's capacity to effectuate change---to shape their political environment---regardless of the construct or face validity of the current measurement instrument. If the instrument validly measures the construct (i.e., construct validity) as I have defined it, then there should be no increase in external efficacy among groups who are/were not subject to increased restrictions or prohibitions on a different group. That is, if political conditions change to be more restrictive (or indeed, oppressive) for women, or Black people, or any other reconciled minority population in the United States, then this should not in turn increase the levels of efficacy among that population not subject to coercive or oppressive restrictions. The political conditions of this group have not changed and as such their status remains unaffected by restrictive laws placed upon other groups. Simply, the favored subject is still subject.

Thus, for example, U.S. citizens are not endowed with new powers of government when further restrictions and prohibitions are placed upon non-citizen immigrants; their capacity to shape the political environment has not changed from its *status quo*. Therefore, from the perspective of the subject, the maximum effect possible given their engagement (intervention) in the political process of government, would or should remain unchanged. 

The issue is determining the general purpose, or end, of political engagement (intervention) for a person of said status. If the purpose of political engagement is, at best, to influence the choices and behaviors of those actors empowered to govern, then the maximum effect of citizen engagement is limited to that end.  In such a case, appraisals of efficacy are beholden to perceived validation of political influence. That is, efficacy beliefs are inherently defined as the extent to which a person believes themselves, or their group, as influential---capable of imposing influence on the actors engaged in the process of governing.

However, despite that stated purpose being the underlying standard consensus in much political science research and theory over the years, it is in contradiction to a system in which the people rule. Thus, our conception of political efficacy in political science and theory is based upon the implied purpose of political participation professed by scholars as to *influence* empowered actors.

## 2025-04-17

Throughout U.S. history, political conditions have changed, sometimes quite significantly from what had been the *status quo* prior to. But as it relates to political efficacy, the political conditions that changed were not always conditions pertaining to the capacity of the people to shape the political environment. To be sure, many changes that pertain to the people *en mass* were ordained in order to prohibit and protect against arbitrary discrimination of one group or another, which no doubt contributes to the people's popular capacity. 

The subject, in this case, doesn't merely refer to one individual person, but to all those people who are equally subject to the same political conditions.

So when considering changes to the 'external' political environment that may relate to efficacy attitudes, consideration must be constrained to the conditions of the political environment that shape the people's popular capacity to shape that very same environment. That is to say, people are subject to conditions of the political environment, but what is of interest in regards to political efficacy is the capacity of the subject, in turn, to subject the political environment. 

To put in other terms, the popular capacity of the people to shape, change, reform, or otherwise constitute the conditions of their political environment is the basal purpose of engagement and participation within, and without, the political system. 


Political efficacy has been conceived as an individual's attitude in regard to themselves situated along two component dimensions, but the conception falters as soon as we move to consider the so-called 'external' dimension. In one dimension, political efficacy is conceived as one's personal confidence in their ability to merely encounter or confront political topics, issues, or affairs; internal political efficacy is no more than an individual's self-qualification as more or less politically competent. The conception of the other dimension, external political efficacy, immediately forgoes an appraisal of the individual's ability to do or accomplish or produce or          


## Sometime prior to 2025-04-20

Chamberlain (2012) states that the dependent variable in his analysis was "external efficacy values from 1952 to 2008, taken every two years except from 1952 to 1964 and from 2004 to 2008"^[He notes that the Time Series Cumulative Data File did not, nor does not, include data collected from the 2006 ANES Pilot study. New external efficacy items were run in the ANES 2006 Pilot study before being fielded in 2008 ANES on a much smaller sample.].

Basically, Chamberlain relies on the CDF from 1952 to 2008, simply excluding years of which external efficacy items were not asked. The index score from 1986 even though only one item was asked.

NOTE: the NOSAY external efficacy item was not asked in 1986 for some unknown reason. Neither NOSAY or NOCARE were asked in years 1948, 1954, 1958, 1962, and 2012, but only NOSAY was omitted from the survey in 1986. I think it best to exclude these years and only include the years wherein both items were asked. Even though the NOCARE was asked in 1986, NOSAY was not. It's already problematic (methodologically) to take an average of two arbitrarily coded ordinal categorical variables, yet it becomes more dubious to rely on a average of a single item as though it were an index. However, for the sake of replication, I will first include the same years included by Chamberlain.


# 2025-04-21 and 2025-04-22

Now the ANES isn't a yearly survey; the ANES has been conducted every two years starting from 1964. In his article, Chamberlain lags the dependent variable (external efficacy) by 4 years---i.e., a four year lag.

His reasoning mostly hangs on theoretical grounds---primarily the notion that the definition of the concept itself implies that past government performance should influence external efficacy. Or simply, evaluations of perceived government responsiveness to public demands leaves lasting impressions on later evaluations of the same. Yet, this reasoning seems a bit loose; there isn't a thorough explanation offered by Chamberlain for why a person's level of *external efficacy* at one point in time will influence their level of *external efficacy* at some later point in time. All the definition implies is that perceived government responsiveness---drawn from considerations of today and yesteryear---will influence one's sense of external political efficacy. So based on the current conceptual definition for external efficacy, my feelings of external efficacy today are informed by my impressions about the extent to which I believe government officials have been responsive to public demands, i.e., the extent to which I believe government officials care about what people like me think and the extent to which I believe people like me have any say in what government does.

There is one line of reasoning that justifies a dynamic model time series analysis as a test of measurement validity. In a dynamic time series model, a change to levels of external efficacy at one point in time will have downstream impact on one's sense of external efficacy in the future. That is, it is the *change* to one's sense of external efficacy that is remembered and influential upon later appraisals. 

When looking back, the experience of when one's feelings changed is conjured up whenever one must consider the extent to which government officials care about and follow public demands. External efficacy beliefs may be relatively persistent, especially when low, and especially since it is harder to earn trust then it is to lose it. An instance of unresponsive government may seem like "more of the same" to the person whose belief has been settled. However, for the person whose appraisal of external efficacy is relatively high, certain events may negatively shift one's views of the conditions of the political environment, and thus influence levels of external efficacy.  

Another line of reasoning may be that one's feelings of external efficacy---being partially, but largely, influenced by the contemporary political context---is considered and then stored in memory only to be recalled upon the next instance where its consideration becomes relevant again. That is to say, an individual remembering the impression or conclusion they reached previously, however partial, in regard to whether government officials care or follow public demands. This previously settled attitude affects their current and later evaluations of the same. While sensible, this line of thought suggests that we would expect a degree of bias in contemporary and future levels of external efficacy towards some previously settled reference level of external efficacy. Therefore the reasoning is predicated on the assumption that the individual has at one point in time considered and settled their attitude about whether government officials care or follow public demands. 


Such a line of reasoning would justify a dynamic model, yet this relies on the presumption that an individual has at some point formulated some impressionistic sense of their own external efficacy prior to the questions being asked in a survey. In order to substantiate this theoretical framework, some default reference level of external efficacy must be presumed. Sure enough, the default reference for external efficacy is simply the ideal---that government officials and productions are responsive to public demand. A sticky point is the ambiguity of what is meant by "public demands", i.e., does it refer to expressed preferences of the public or to the common interests of the public? In either case, a normative ideal for how responsive the government should be is implicitly assumed as the reference point of external efficacy.     It is unclear from this theoretical digression whether an individual's level of external efficacy would be biased toward some *status quo* reference level---perhaps hovering around some unknown (but presumed) prior impressions; or whether levels would be biased to continuously increase or decrease depending on the trajectory of the last most influential factor. The implications of the definition alone merely suggest that external efficacy is, indeed, an attitude formed by retrospective, 


# 2025-04-22

Chamberlain's study is valuable because it proposes to test whether aggregate results over time conform to what we'd expect given the standard conception of external political efficacy. Simply put, Chamberlain posited that according to the definition of external efficacy, we would expect to see dynamic shifts in aggregate levels of external efficacy in accordance with changes in the political environment. The theory of Chamberlain's study is sensible so long as the common understanding and conceptual definition of external efficacy is taken as a given. His study stands as a unique way to test the construct validity of external efficacy that isn't reliant upon methods of common factor analysis or structural equation analysis. And it is appropriate considering that external efficacy, as conceived and measured, has remained generally unchallenged by scholars despite common acknowledgement of issues in measurement.


In that case, results showing that external efficacy in the aggregate is not "dynamically responsive to changes to the political environment" presents a significant challenge to its contemporary conception and measurement. However, even taking the standard conceptual definition of external efficacy as a given, Chamberlain selects predictors that are not reflective of the political environment while treating them as such. His conclusion holds only if one accepts the three predictors he selected as a partial representation, or proxy of, the political environment. Yet, presidential approval ratings, consumer sentiment, and trust in government are not tenable as factors representative of the political environment. As such, it is difficult to substantiate the null results as informative or reflective of the author's conclusions.  

The value of the study is that it stands as an open question---an untested hypothesis, or rather, an improperly tested hypothesis. Given the standard definition and common understanding of external political efficacy, we would expect changes to the political environment to concur with shifts in aggregate external efficacy over time. However, considering the trouble posed by not using predictors that could be reasonably stated as reflective of the political environment, novel predictors would need to be incorporated into the same test. If aggregate external efficacy does not appear to be responsive to said changes over time (dynamically or otherwise), then construct validity for the measurement of external political efficacy is invalid. Doubly so if null results are found provided the novel predictors can be more reasonably understood as reflective of the political environment. The implication would be that the items composing the external efficacy index, while predictive of behavior at the individual level, cannot be said to be measuring external efficacy as understood in the literature. More importantly, external political efficacy would be challenged, if not wholly invalidated, as a distinct dimensional component of political efficacy.

First, I attempt to replicate Chamberlain's results published in 2012 using similar data. Chamberlain's study was limited to evaluating time series data from 1952 to 2008, the most recent data available at the time. My replication will attempt to extend that analysis to range from 1952 to 2020^[Preliminary data from the 2024 ANES is available at the time of writing, but had yet to be finalized and incorporated into the ANES Time Series Cumulative data file.]. Replication of Chamberlain's results wouldn't be too informative---his study produced null results that, while interesting, are substantive only if one accepts his interpretation of the predictors as reflective of the political context. If, however, while following the same methodology employed by Chamberlain, external efficacy does appear to be responsive to the same chosen predictors in the years beyond his original analysis, then further study would be needed to explain why external efficacy appeared unresponsive until late.

Then, I conduct a second time series analysis using a new model with different predictors. Complimentary results would not only replicate Chamberlain's findings, but further substantiate challenge to the concept and measurement of external political efficacy.



> "This article is an attempt to gain leverage on the measurement issue by using an aggregate, dynamic time-series model to uncover what factors cause external efficacy to change over time." [@chamberlain2012, 118].

Here Chamberlain makes a mistake: we can't determine the causes of some thing or event when we don't have a proper conception nor measurement of it. We may find that the results of our measurements fluctuate up and down and we may be able to attribute such fluctuation to particular factors; but if we don't know what it is we are measuring in the first place, then such measurements are meaningless. Or if we know what we'd like to measure but don't have valid methods of measuring it, then not only are measurement results of the construct invalid but discovering factors that significantly (or not) influence  those measurement results isn't informative. 


In that case, we are merely naming patterns observed through particular combinations of data and attributing conceptual substance post-hoc. This is different from inference because instead of letting the patterns of observed data inform us of what is present, we are constricting the information to form the patterns we want to see. 

Or if we **do** know what we'd like to measure---as in, we have a proper conception of some attitude or phenomenon or thing in theory---but haven't developed measurement instruments that consistently validate the concept as theorized nor reliably capture it as well, then nothing can be said about what causes fluctuations in what is being measured. For one, until a measurement method is validated, we must assume that we're not measuring the thing we claim. Factors attributed to fluctuations in its levels can not be informative of its meaning.  

 As it stands, external political efficacy refers to    

(For instance, I understand what my body weight is conceptually, but the measurement instruments I have for it cannot be said to validly measure my weight at all. Whenever I supposedly measure my weight by use of these invalid instruments, the results I have can't be said to accurately reflect my body weight. Finding other factors that significantly influence results drawn from invalid measurement of my weight tells me nothing about my current weight, nor about trends in my weight over time, nor of the validity of the measurement instrument itself. However I have an unobjectionable definition for body weight that clearly tells me what body weight refers to and hints at how it might be ascertained. 

External political efficacy, however, refers to a component dimension of a hypothetical construct in theory. Measurement of it must validly conform to its conception, surely, but the conception itself must first be reasonable and (relatively) unobjectionable.)

> "External efficacy is a measure that takes into account a government's responsiveness; people should draw on past experiences with government before assessing whether they have any effect on its behavior. Past government performance, and the economic conditions it presides over, should have an effect on changes to external efficacy over time." [@chamberlain2012, 119]

This is where Chamberlain's reasoning falters. He just said that people should draw on "past experience with government" as in, past experience engaging with government and the with the outcomes thereof, if any. Yet he posits that past government ***approval***, in general, and impressions of contemporary economic conditions should influence the way external efficacy changes over time. 

People can't assess whether they have any effect if there is no experience to draw upon. Experience of engagement is the basis for which one evaluates whether said engagement was effective towards accomplishing or producing the ends sought. Without experience of engagement to draw upon, the basis of their expression, then, is simply how satisfied they are with government officials. It isn't simply evaluating past government performance in general, but rather evaluation of government performance in regard to how responsive government officials and government outcomes *appear to be* to public input. Essentially, respondents are grading government in the category referred to as "responsiveness to public input".

:::{.callout-note}
## 2025-08-15
I added more to a comment on the PDF in Zotero that is worth including here too
:::

If external efficacy takes into account a government's responsiveness, then measurement items should have people evaluate *the maximum effect of their input upon government outputs*, i.e., on the things that government produces (e.g., laws, policies, regulations, etc.). The government responds by enacting new laws, making changes, declaring war, or ultimately **producing outcomes**. Sponsoring legislation, for example, is not enough to qualify as responsive even if said legislation was submitted to Congress due to some kind of popular public input. People aren't evaluating whether government actors or politicians are putting forth effort or trying their best; they are evaluating whether their own popular political activity amounts to effects upon or production of government outputs. Literally, whether the public attempts to stimulate government activity works to bring about desired outcomes. That would be a measure that assessed the efficacy of the means of popular political production---i.e., whether political outcomes are produced upon popular political activity. 

To give an illustrative analogy, a pharmaceutical drug or medicine meant to cure some illness may excite some part of a persons body, or may generate some chemical activity upon ingestion, but ultimately not result in any positive improvement or effective cure of a person's condition. The efficacy of the drug would then be considered null despite whatever somatic excitement.

A government would be unresponsive if popular input did not produce outcomes. Moreover, a government would still be considered unresponsive even if public input stimulated, aroused, or excited politicians into action. The criteria for responsiveness is an actual outcome, not whether politicians are perceived to have put forth effort.


# 2025-04-23

the ANES CDF supplies weights, which must be used. How I incorporate this into
the analysis, however, isn't clear to me. I am using time series data, but I
know of no function or method for using the weights supplied.
I know using the survey/srvyr R packages is pretty standard, but I am not sure.

From ANES documentation "How to Analyze ANES Survey Data" by DeBell (2010)

> "ANES studies use probability samples, in which each person in the target population has a known, nonzero probability of being selected for the study. All ANES studies use procedures known collectively as complex sampling to distinguish them from simple random sampling." [@debell2010, 5]

> "Among the key methods that various ANES studies have employed that make ANES samples complex are the following."

> **Oversampling**: In some ANES studies, members of minority groups, such as blacks and
Hispanics in the 2008 Time Series, have been sampled at a higher rate than their proportion in
the population. This is done in order to obtain larger numbers of members of these groups in
the sample, increasing the precision of statistics estimated for members of these groups

> **Stratified cluster sampling**: Samples for ANES surveys conducted using face-to-face interviews are drawn using geographic areas. A simple random sample of Americans would result in a sample of people scattered all over the country, and visiting each one for a face-to-face
interview would be prohibitively expensive. Area sampling involves first drawing a sample of
regions of the country, and then sampling successively smaller geographic areas within those
regions, before sampling specific households within the sampled small areas. The benefit of
this procedure is that it is far less expensive to conduct interviews when members of the sample are clustered together in a limited number of areas

> **Within-household sampling**: ANES studies conducted face-to-face select households within geographic areas. Studies conducted by telephone select households served by a telephone
number. In both types of study, one stage of the process involves selecting one individual who
lives in a household. If a person lives alone, once his or her household has been contacted, the ANES will seek an interview with that person. In a sampled household with just one resident
meeting ANES eligibility criteria (such as being an adult U.S. citizen), there is a 100% chance
that ANES will seek an interview with that resident. In a sampled household with more than one
eligible resident, ANES will seek an interview with one resident who is randomly selected from
those who are eligible. Thus, the probability that ANES will seek an interview with any particular eligible resident is equal to the inverse of the number of eligible residents in the household.

This following excerpts are important,

> "The ANES time series has panel components and cross-sectional components. Each time series study of one presidential election year consists of a pre-election survey and a post-election survey. Respondents to the post-election survey previously completed that year’s pre-election survey, so as a study of a single election, each study in a presidential election year is a two-wave panel study. In addition, in some years, ANES re-contacted respondents to surveys from previous years, adding a further panel component to these studies. However, in most studies, from one election year to the next, entirely new samples are drawn. Thus the decades-worth of time series data primarily constitute a set of repeated cross-sectional surveys, not longitudinal surveys"

> "ANES data require special analysis techniques because the respondents are not selected using a simple random sample. In a simple random sample, each member of the population has an equal
probability of selection that is not affected by the selection of any other member. In the ANES, each member of the population has a theoretically knowable probability of selection, but some population members are more likely to be selected than others. In ANES surveys conducted by random-digit-dialing on the telephone, people who live in households with two telephone lines are twice as likely to be selected as those who live in households with one telephone line. In ANES surveys conducted face to face, the cluster design means that people living near one another are sampled in groups, and these people who live near one another are likely to resemble one another in other ways. In all households, the ANES practice of selecting one household member means that people who live in large households are less likely to be selected than people who live alone or in small households." [@deBell2010, 14]

> "Two statistical techniques adjust for these complex aspects of the ANES design. The first is weighting the data and the second is an adjustment to the way we calculate standard errors and statistical significance to produce design-consistent estimates. Weighting accounts for unequal probability of selection, and also helps correct random and systematic errors due to non-response. The special techniques for calculating standard errors account for the clustering of the sample. Together, these techniques are called “design-consistent” estimation."

> "For the datasets on which they are provided, weights correct for unequal probability of selection and for nonresponse to the survey. This makes the survey’s representation of the population more accurate than it would be without the weights. Therefore, always use the weights if you wish to generalize resultsto the population."

From the Time Series Cumulative Data file page on the [ANES site](https://electionstudies.org/data-center/anes-time-series-cumulative-data-file/)

> "Over the years, the most common ANES study design has been a cross-section, equal probability, sample. These designs are typically “self-weighting” — i.e., the respondents do not need to be weighted to compensate for unequal probabilities of selection in order to restore the “representativeness” of the sample. On several occasions, however, ANES has departed from this standard design. In some years, ANES “oversampled” certain groups (African-Americans in 1964, for example). In other years, the Election Study combined a panel reinterview with a cross- section design (as in 1974, for example). It is important to understand that the Time Series Cumulative File is a file of pooled cross- section studies: any respondent for a particular study who is strictly “panel” or “supplement” has been deleted from the Time Series Cumulative File."

> "Because not all of the cross-section samples included in the Time Series Cumulative Data File are equal probability and thus self- weighting, all pooled cross-section descriptive analyses should be run using Variable 9, the weight variable. For most years, the value of that variable for all respondents is simply “1.0”"

> "The ANES Time Series Cumulative Data File includes three sets of weight variables (combined sample, face-to-face sample, and web sample), with documentation at the beginning of the codebook appendix. For the ANES 2020 Time Series Study, a single combined sample weight is present. The 2020 weight appears in variable VCF0009z and also in VCF0010z and VCF0011z."

So the takeaway I am getting here is that the cumulative data file should be treated as *repeated cross-sectional data*, rather than strictly time series data. Repeated cross-sectional data consists of multiple independent cross-sections collected at different points in time. Unlike panel data, where the same individuals are tracked over time, repeated cross-sections draw a fresh sample in each survey wave. Use of repeated cross-sectional data allows researchers to analyze aggregate trends over time, but it does not track individual-level changes.

Specific methods are said to be used to analyze changes over time, such as pooled cross-sectional regression (Time fixed-effects). Essentially, combines multiple survey waves into a single dataset (like the CDF) while controlling for time effects.

$$
y_{i} = x_{i}\beta + \delta_{i}y_{1} + \dots + \delta_{T}y_{T}+\epsilon_{i}
$$

where:

- $y_{i}$ is the outcome for individual $i$
- $x_{i}$ are explanatory variables (independent variables, predictors, etc.)
- $y_{t}$ are time period dummy variables 
- $\delta_{t}$ captures the average change in outcomes across time periods

Two advantages of this method are that it allows for different intercepts across time periods, capturing shifts in baseline outcomes; it tracks overall population trends without assuming a constant effect of $x_{i}$ over time.

Another advantage allows for structural change in pooled cross-sectional data in order to examine time-dependent effects. That is, to test whether relationships between variables change over time, one can examine interaction between a time variable (dummies) and explanatory/predictor variables. Such analysis of interacting $x_{i}$ with time period dummy variables produces different slopes for each time period, allowing one to examine whether effects of $x$ are *specifically* time-dependent.

# 2025-04-23

A dynamic model of aggregate external efficacy implies that external efficacy today is a function of external efficacy four years ago modified by new information on, or changes to, the the political environment. However, this is valid only insofar as the new information ascertained over the lagged time period pertains to conditions of the political environment associated with external efficacy beliefs. The explanatory variables that Chamberlain employs as predictors are untenable as factors representative of the political environment. Rather, the factors he employs are attitudinal variables---opinions, sentiments---related to the political environment, once or twice removed. Thus, in Chamberlain's study, the dynamic model implies that external efficacy today is a function of external efficacy four years ago modified by new public sentiment within that period. In particular, sentiment concerning presidential approval, the economy, and trust in government. 

As commonly defined, external efficacy beliefs take into account a government's responsiveness. Chamberlain uses government responsiveness as interchangeable with government performance, thus justifying the use of factors such as presidential approval, consumer sentiment, and trust in government as sufficient proxies. These factors are arguably evaluations of, or related to, government performance in some way, though such an argument is not my own. What these factors are definitely not, however, are reflections of the political environment or conditions thereof. 

This is in spite of there already being a closely related, if not conflated, index of government responsiveness consistently measured in national election studies.  


# 2025-04-29

In order to resolve the issue of external efficacy, our conceptual understanding of it must first be addressed and scrutinized. We don't know what we're measuring if we do not have a clear, concise, and distinct conception of it (whatever it is). Especially in relation to the supposed contrast, internal efficacy. Whether that relationship is both coherent and valid is not purely an empirical matter that can be resolved through complex measurement methodology or creative use of the methods of statistical inference. We first must be clear about what it is we mean when we refer to this concept in theory, which, in turn, means that the theory of the concept itself must be valid on its own terms. 

We must understand what we want to know, which is fundamental to scientific inquiry. When we select a measurement instrument, it is presumed that we have clearly identified what we'd like to know because of what results the measurement instrument can produce. When I want to know how much I weigh, I use the appropriate measurement instrument that reliably provides me with valid results corresponding to my weight in an appropriate unit metric for (e.g., pounds lbs, kilos, grams).  

Then we must recognize whether we are forming the theory of a concept instrumentally to further the aims of research---to find the answer to the question we have---or whether we are merely giving a name to a pattern or phenomenon observed in nature.

...

Chamberlain states, 

> "Some might question the causal ordering and argue that external efficacy could predict all of these variables. Theoretically, this would then be a problem with the definition of external efficacy, for the public must assess government responsiveness based on past performance." [@chamberlain2012, 122]

Yes, conceptually, this is a big issue with external efficacy. But also the idea here would also imply that the public's current approval of the incumbent president wouldn't be conditioned on their past appraisals of government responsiveness. Yet, why wouldn't it be? Why wouldn't presidential approval today be influenced by assessments of past gov responsiveness (external efficacy) of the past?

What influences presidential approval? Is past external efficacy independent of presidential approval today?


> "Without a government to assess, external efficacy could not conceptually exist." 

Ugh, no.

> "Statistically, the dynamic nature of the lagged time-series approach helps ensure that past performance is being used to predict current levels of external efficacy. External efficacy at time t cannot cause the values of trust and presidential approval at times t - 1, t - 2, or t - 4." [@chamberlain2012, 122]

But what if the external efficacy at $t_4$ influences the predictors at $t_1$, $t_2$, etc.? The lagged external efficacy variable is, in effect, used as an independent predictor in the dynamic model, but if the DV at $t_4$ is significantly related to the other predictors at $t_1$, $t_2$, or $t_3$, then wouldn't the lagged-DV introduce endogeniety and bias estimates?

The other thing is this issue where a lagged dependent variable soaks up, or essentially steals, the effect of both excluded and included variables [@achen2000]. That is, when the independent variables included in the model are "sufficiently trending", then including a lagged dependent variable causes bias.  

One could hypothesize that past values of external efficacy predict current (or recent) values of presidential approval, trust, and economic sentiment. If past external efficacy is an influential factor to current levels of all three, then current levels of external efficacy probably predict later values of the predictors. The causal path is muddled up quite a bit.

However, a more recent study [@ghitza2023] suggests that the cumulative impression left by political events...


:::{.callout-note}
Quick thought on the citation below
:::

Norris, Mikel. 2015. “The Economic Roots of External Efficacy: Assessing the Relationship between External Political Efficacy and Income Inequality.” Canadian Journal of Political Science/Revue canadienne de science politique 48(4): 791–813. doi:10.1017/S0008423915001080.


My initial thoughts on this [@norris2015], before reading the full paper, is that the relationship between external efficacy and income inequality supports my contention that measurement instrument for external efficacy has little to nothing to do with efficacy at all. If lower income inequality improves external efficacy, then all that tells us is that the measures for external efficacy are instead measures of contemporary life or government satisfaction. When I am fat and happy, I feel “externally efficacious”. Thus, *democracy* is actualized when the people are satiated---not necessarily while they are in power. Otherwise said, the power of the people has nothing to do with external efficacy as it is understood and measured today. And that is, chiefly, my primary contention.


Then there's the study from the following citation again linking income inequality to external efficacy beliefs. The hint is consistently slapping political scientists in the face but the results are too significant to be concerned with my contrived pedantry. Income inequality depressing external efficacy is interesting in itself, but the substantive importance left unrecognized is that the relationship suggests that 1) measures for "external efficacy" are not related to the belief about the capacity to shape the political environment, and 2) people believe they live in a democracy so long as they are affluent, or at least "economically comfortable". I would imagine (hypothesize) that those with greater affluence would readily endorse the statement that "The United States is a Democracy" compared to those who are, for lack of a better term, poor. If the mechanism of democracy is tied to income, to wealth, then one's conceptions of power are tied to the vehicle rather than the destination. That is to say, the democratic status of the regime is left unquestioned so long as me and mine prosper. Our prosperity may very well be expanded or limited to the extent allowed by our subjugator, but so long as it is prosperity indeed, then to me it feels like *democracy* in fact.

Bienstman, Simon, Svenja Hense, and Markus Gangl. 2024. “Explaining the ‘Democratic Malaise’ in Unequal Societies: Inequality, External Efficacy and Political Trust.” European Journal of Political Research 63(1): 172–91. doi:10.1111/1475-6765.12611.


There's more to be said about class, and its seemingly inextricable relation to, well, everything. But I am tired.


# 2025-05-01

A two-way fixed effects model to estimate difference-in-difference effects utilizing the time-series (panel) data (which is, really, repeated cross section data, also referred to as rolling cross section data) seems appropriate. 

$$

y_{it} = \alpha_{i} + \tau_{t} + \beta_{3}(Treated_{i} \times After_{i}) + \beta_{4}X_{it} + \epsilon_{it}

$$

- the $\alpha_{i}$ terms (the unit-specific fixed effects) capture differences that exist across units both before and after the treatment (or event)
- the $\tau_{t}$ terms (the time-specific fixed effects) capture differences that exist across all unit in every period. For instance, if homicide rates are higher in 2007 than 2003, then the $\tau_{i}$ for 2007 will be higher than $\tau_{i}$ for 2003.
- $Treated_{i} \times After_{i}$ is an interaction of a variable indicating whether a unit is a treated unit (treated = 1 for states that enacted some kind of voting laws) and $Post_{t}$, which indicates whether the observation occurred post-treatment (meaning the observation occurred after the state passed whatever law). This interaction variable will equal 1 for treated states in the post-treatment period (after 2013) and 0 for all other observations. 

So controlling for pre-existing differences in state external political efficacy (via state fixed effects), and national trends in external efficacy (via time fixed effects) and maybe some additional controls, did external political efficacy shift after states implemented laws that affect their capacity to effectuate change in the political environment?


# 2025-05-03

## Temporal Dependence with a Lagged Dependent Variable

Lagged dependent variable model without fixed effects

$$
Y_{it} = \gamma Y_{i,t-1} + \beta_{0} + \beta_{i}X_{1it} + \beta_{2}X_{2it} + \epsilon_{it}
$$
- $\gamma$ is the effect of the lagged dependent variable
- $Y_{i,t-1}$ is the dependent variable of the previous period (i.e., lagged by one time period)
- $\beta$'s are the immediate effects of the independent variables
- $\epsilon_{it}$ is the error term uncorrelated with the independent variables and homoscedastic.

As usual, a unit-increase of $X_{it}$ will be associated with a $\beta_{1}$ increase in $Y_{it}$ that period. An increase in $Y_{it}$ in one period affects $Y_{it}$ in subsequent periods via the $\gamma Y_{i,t-1}$ term in the model. Thus, a change in $X_{it}$ not only corresponds with a $\beta_{1}$ effect on $Y_{it}$, but also corresponds with a $\gamma \times \beta_{1}$ effect on $Y$ in the next period.

If there is **serial autocorrelation** and **tending** in the independent variable $X$, then including a lagged dependent variable $Y_{i,t-1}$ will bias estimated coefficients downward. Even though autocorrelation does not cause bias in OLS models, autocorrelation can cause bias in dynamic models. 

The model needs to be estimated with and without the lagged dependent variable. There needs to be no serial autocorrelation nor trending in the independent variables of the model. There are a few ways to test for autocorrelation

- auxiliary regression
- Durbin-Watson Test
- Ljung-Box Test
- Visual inspection

First, I have to estimate the models without the lagged dependent variable. Then I test for autocorrelation of those models. So the external efficacy model,

$$
Y_{t} = \beta_{0} + \beta_{1}X_{t}+\epsilon_{t}
$$

The $t$ of $Y_{t}$ and $X_{t}$ represents the value of the dependent and independent variable at time $t$. In the data set I have, each row represents average values of each variable for the particular year. So estimating the basic models is as simple as including each variable without lags.  

$$
Ext.Efficacy_{t} = \beta_{0} + \beta_{1}Presidential Approal_{t}+ \beta_{2}ICS_{t} + \beta_{3}Trust in Government_{t} + \epsilon_{t}
$$

The first table of results Chamberlain [-@chamberlain2012] displays consists of seven models: 

- one model for each individual lagged predictor including the lagged dependent variable (one included congressional approval ratings, which I am ignoring). 
- one that includes the lagged DV, lagged presidential approval, and lagged ICS 
- one that includes the three predictors and the lagged DV (i.e., the full model)
- one that includes only the lagged DV

I must first estimate the models without lagged variables and test for serial autocorrelation. I'm not sure if this step was taken by @chamberlain2012.

External political efficacy is difficult as it is not entirely clear what, exactly, is being measured. Especially in relation to other similar hypothetical constructs^[Note the distinction between a hypothetical constructs and a concept] such as trust in government and perceived government responsiveness. External efficacy is too easily conflated with these two at the conceptual level, but has at various times been shown to be somewhat distinct by way of common factor analysis methods. The idea seems to be that the survey items are measuring something distinct enough, so external efficacy should continue to be measured as a relatively distinct homogeneous construct. The problem is that there's not a clear and concise notion as to what the survey items are actually measuring. In other words, responses to the two survey items appear to be influenced by some underlying factor distinct, but related to, similarly conceived political constructs, but there isn't enough for researchers to distinguish a cogent concept in theory that could be referred to as external political efficacy^[Note the common issue in factor analysis known as the 'naming fallacy'. Just because a factor is given a name doesn't mean that is what influences the various indicators (i.e., survey item responses)].

@chamberlain2012 attempts to address this problem in the hopes that results would elucidate the meaning from the measurement, regardless of whether results were supportive or null. His idea is that a dynamic time-series model of aggregate external efficacy would reveal factors that shift (or don't shift) external efficacy overtime, thus aiding in the ability of researchers to draw meaning from, and hopefully clarify, what is actually being measured by the survey items. In order to do so, particular external factors must be selected.

:::{.aside}
So if whatever is being measured is moved by some systematic "mover", we may better understand what *it* is. That's the idea anyway. The thing is, we already claim to know what is being measured, but the measurement doesn't really validate the theory or understanding of the concept. As a hypothetical construct of political interest, external efficacy is inherently conflated with government responsiveness, easily conflated with trust in government, and detached from even the lexical meaning of efficacy---the power to produce an effect^[See [Merriam-Webster Dictionary](https://www.merriam-webster.com/dictionary/efficacy). Also simply defined as "the ability of something to produce the intended result" in the [Cambridge Dictionary](https://dictionary.cambridge.org/us/dictionary/english/efficacy).].
:::

For reference, external political efficacy is usually defined as referring to "...citizens' perceptions of the responsiveness of political bodies and actors to citizens' demands" [@craig1990, 290]. In order to select appropriate external factors, Chamberlain begins from what he says is implied by the definition of the concept of external political efficacy---that, "...the measure is affected by the broader political environment" [@chamberlain2012, 118]. Accordingly, he states,

> "External efficacy is a measure that takes into account a government's responsiveness; people should draw on past experiences with government before assessing whether they have any effect on its behavior. Past government performance, and the economic conditions it presides over, should have an effect on changes to external efficacy over time." [@chamberlain2012, 119]

Following this logic, he selects three predictors as representative of the political environment: presidential approval ratings, the index of consumer sentiment, and trust in government.

## some notes on a relevant article

> "Alternately, one can skip individual-level analyses by collapsing data into mean values and applying time-series analyses to the aggregate data." [@lebo2015, 243]

Aggregating data by year reduces the number of observations $N$ quite dramatically. The dynamic time-series examination of the repeated (rolling) cross-section data aggregated by yearly average values is proposed as an attempt to better understand what is being measured at the individual level. 

> "Studying data in the aggregate has theoretical support if causal ordering at the individual level is in question" [@lebo2015, 243-244]

> "If some independent variables vary only over time (e.g., the inflation rate) there is a natural tendency to construct a model in the aggregate. Yet, aggregating participants by day/week/month/quarter can reduce data sets to a thousandth of their original size." [@lebo2015, 244]

> "Since a multilevel model allows the use of all the data, the aggregate- versus individual-level debate is a false dichotomy. Researchers can explore complex relationships rather than entirely avoid an important level of analysis. In doing so, they can also investigate individual-level relationships that might vary over time." [@lebo2015, 244]

> "Thus, two problems are evident. First, most published work using RCS has relied on techniques that study static or dynamic processes, not both. Second, ventures into MLM with RCS data have barely considered the statistical consequences of the various modeling choices. Given the wealth of RCS data available, we explore its challenges and consider the efficacy of several modeling choices." [@lebo2015, 244]



  


## 2025-05-08

::: {.callout-note}
I was attempting to write out a simple abstract but digressed into other stuff. Some may be worthwhile. The first part I was trying to...formalize the argument against why Chamberlain's chosen predictors were invalid.
:::

To be clear, the argument goes as follows:

- The individual is subject to the political context (i.e., conditions of the political environment)
- Attitudinal variables about the context are from the perspective of the subject (i.e., subjective)
- Political context is not a deterministic influence on attitudes
- Attitudes about context may or may not related to the political context (i.e., independent of context)
Therefore...

Attitudinal variables about the political context from the perspective of the subject are not suitable as proxy for the political conditions thereof. 

Simply, attitudes about the environment are not sufficient proxies for the environment.

External political efficacy has been fraught with conceptual and methodological issues since inception. 


Tentative abstract: 

It is not sufficiently clear what is being measured by external political efficacy measurement items. Not only is the conceptual definition of external efficacy conflated with similar concepts, empirical results are too closely related to satisfactorily distinguish external efficacy as a distinct component on par with internal political efficacy. @chamberlain2012 attempted to address this problem in the hopes that results would elucidate the meaning from the measurement. Drawing from the usual conceptual definition of external efficacy, Chamberlain hypothesized that external efficacy beliefs would be dynamically responsive to changes in the political environment. Results from the study could not reject the null; according to the original study, aggregated external efficacy was apparently unresponsive across time to predictors representing the political environment. Extending his analysis to include years since the original study partially replicates the original findings. Following the same methodology, updated results show that external efficacy in the aggregate is positively associated with presidential approval ratings with a one year lag. However, similar to Chamberlain's study, statistical significance disappears upon inclusion of consumer sentiment and trust in government. Such results pose a severe challenge to the validity of measurement for external political efficacy. However, results from then and now are contestable on the grounds that the predictors of the analysis are not tenable as proxies for the political environment. To conduct a fairer test of the meaning and measurement of external efficacy, I examine whether external efficacy has been responsive to changes to the political environment across and between states since 2013 after the Supreme Court decision in *Shelby County v. Holder* which ruled Section 4(b) of the Voting Rights Act unconstitutional.         

One may argue that external efficacy refers to beliefs about responsiveness of government authorities and institutions to public demands, but given that Supreme Court rulings need not be responsive to contemporary demands of public opinion or preference, then no shift in external efficacy over time would be expected or attributable to rulings from the high court. Indeed, the rulings of the Supreme Court are not responsive but rather expressive of constitutional authority. The power vested in the Supreme Court, as with the other branches of government, are capable of shaping and re-shaping the political environment*. The legitimacy of federal and state law is contingent on conformity with the constitution, i.e., subject to conditions established as constitutional. And individuals are subject to such political conditions within the jurisdictions of the United States. 

This highlights the conceptual distortion of external efficacy in that the underlying focus is constrained on the people's capacity to *influence* government officials and institutions in reference to perceived sensitivity to public opinion. 

The ideal is not that government actors and institutions, of whatever form, creed, or regime type, are responsive to public demand, opinion, preference, or even common interests, but rather that the popular capacity of the people is not subordinate in relation to the bodies vested with the power to govern political conditions of the state. Indeed, in the the first three articles of the U.S. Constitution, particular powers of government are explicitly *vested* within the three branches. Such power, not by divine right or by laws of nature, is vested by the people for the purposes enscribed in the preamble,

"We the People of the United States, in Order to form a more perfect Union, establish Justice, insure domestic tranquility, provide for the common defense, promote the general Welfare, and secure the Blessings of Liberty to ourselvs and our Posterity, do ordain and establish this Constitution for the United States of America."

The point of the matter is to make clear that power is vested, not surrendered, to the particular branches to govern the conditions of the state for the purposes outlined by the Preamble. 

  *Note the irony that the power of the people is not to shape the political environment but is limited to influencing those who can and do.    



Presidential approval doesn't tell us whether political conditions have changed. Steep spikes and dips in approval may correspond with some event, but is not indicative of the political context. The index of consumer sentiment may be expressive of how the public feels about contemporary economic conditions, but consumer sentiment is not independent from presidential approval ratings. Thus the model already risks endogeneity. 


# 2025-05-09

::: {.callout-note}
Throwing all the draft writing here up to now just to clear out the index.qmd doc.
:::

External political efficacy is difficult as it is not entirely clear what, exactly, is being measured. Especially in relation to other similar constructs[^1] such as trust in government and perceived government responsiveness. External efficacy is too easily conflated with these two at the conceptual level, and also has been shown to be strongly correlated with trust in government in common factor analysis methods. The idea seems to be that the survey items are measuring *something* just distinct enough to qualify its continued measurement as a relatively distinct, homogeneous, psychological construct. The problem is that there's not a clear and concise notion as to what the survey items are actually measuring. In other words, responses to the two survey items appear to be influenced by some underlying factor distinct, but related to, similarly conceived political constructs, but there isn't enough for researchers to distinguish a cogent concept in theory that could be referred to as external political efficacy[^2].

[^1]: Note the careful connotation of *construct* as in reference to a theoretical concept created by researchers (hence, *construct*). I take care to avoid reification of the construct of interest as a literal object under study. See @slaney2015

[^2]: Note the common issue in factor analysis known as the 'naming fallacy'. Just because a factor is given a name doesn't mean that is what influences the various indicators (i.e., survey item responses)

@chamberlain2012 attempts to address this problem in the hopes that results would elucidate the meaning from the measurement, regardless of whether results were supportive or null. Rather than propose new measurement items or offer a novel conceptual understanding, Chamberlain aimed to discern whether this individual-level construct is even sensitive to external factors in the environment as would be expected given its conventional understanding. His idea was that a dynamic time-series model of aggregate external efficacy was needed to reveal factors that shift (or don't shift) external efficacy overtime, thus aiding in the ability of researchers to draw meaning from, and hopefully clarify, what is actually being measured by the survey items. In order to do so, particular external factors reflective of the political context were selected.

Accordingly, Chamberlain's study was an attempt to validate the meaning and measure of external political efficacy in reference to how it is understood, defined, and measured in political science and public opinion. However, while sensible, the study misses the mark in a few clear ways.

The question posed and investigated by @chamberlain2012 was whether external political efficacy in the aggregate is responsive to changes in the political environment. If external efficacy was unresponsive, then it would be necessary to reconsider the meaning more so than the measurement of external political efficacy. He devised a model of temporal dependence with three predictors he claimed were representative of the political environment. The reported findings suggested no: aggregated external efficacy was seemingly unresponsive to changes to the political environment. However, the predictors chosen to serve as proxies of the external political environment were not, indeed, tenable as such. That is, the factors selected can not be understood as representative, in part or in whole, of the political environment. The independent variables of the model were not independent of the individual, of each other, nor could they be understood as representative of the political context along the time series.

However, even taking the standard conceptual definition of external efficacy as a given, Chamberlain selects predictors that are not reflective of the political environment while treating them as such. His conclusion holds only if one accepts the predictors he selected as a partial representation, or proxy, of the political environment. Yet, presidential approval ratings, consumer sentiment, and trust in government are not tenable as factors representative of the political environment. Rather, these are attitudinal variables also arising from the perspective of the subject^[To be clear, the individual is subject to the political context, and attitudinal variables about that context from the perspective of the subject are not suitable as proxy for the political conditions thereof]. As such, it is difficult to substantiate the null results as informative or reflective of the author's conclusions. 

The aim of this paper is to conduct a fairer test of external efficacy given its contemporary definition. As a first step, I replicate his results and then extend them to include observations since the original study. I then examine whether external efficacy beliefs shifted after the Supreme Court ruling in *Shelby v Holder* in 2013. 

The decision of the court struck down the coverage formula of the Voting Rights Act used to determine which jurisdictions were subject to seek preclearance before making changes to state voting laws. The Supreme Court ruling in 2013 is the event that changed political conditions *writ large*, empowering states to emplace conditions on state constituents related to their capacity to simply engage and participate. No new laws were necessitated by the decision; rather the possibilities of what state governments could do expanded. Since 2013 many states across the country have enacted restrictive, and expansive, changes to voting laws (e.g., voter ID, registration, voting method). Yet of particular interest are those states and jurisdictions which were previously subject to preclearance; it is these states in particular where political conditions changed most dramatically after the ruling. The *Shelby v Holder* decision changed conditions of the political environment, thus shifting relations of power between governing actors and those subject to governance.

Chamberlain's study is valuable because it proposes to test whether aggregate results over time conform to what we'd expect given the standard conception of external political efficacy. Simply put, Chamberlain posited that according to the definition of external efficacy, we would expect to see dynamic shifts in aggregate levels of external efficacy in accordance with changes in the political environment. The theory of Chamberlain's study is sensible so long as the common understanding and conceptual definition of external efficacy is taken as a given. His study stands as a unique way to test the construct validity of external efficacy that isn't reliant upon methods of common factor analysis or structural equation analysis. And it is appropriate considering that external efficacy, as conceived and measured, has remained generally unchallenged by scholars despite common acknowledgement of issues in measurement.

Two survey items have been consistently used to measure external efficacy: 1) "People like me don't have any say about what the government does." [NOSAY]; 2) "I don't think public officials care much what people like me think." [NOCARE]. Historically, survey respondents simply stated their agreement or disagreement with the two statements, though response options are now usually expanded to include "Strongly agree", "Strongly disagree" and "Neither agree nor disagree" as response options; Disagreement with either statement is thought to imply positive expression of external efficacy. The American National Election Studies (ANES) have included these two items in almost every survey wave since 1952, which are composed into an index of external efficacy.


@chamberlain2012 conducted a dynamic time-series analysis on aggregate external political efficacy from 1952 to 2008.

The question posed and investigated by @chamberlain2012 was whether external political efficacy in the aggregate is responsive to changes in the political environment. His reported findings suggest no. However, the predictors (explanatory variables) chosen as factors of the external political environment were not, indeed, factors of the political context. That is, the factors selected as predictors in Chamberlain's model can not be understood as representative, in part or in whole, of the political environment. Said predictor variables, of which there were three, were not independent of the individual nor could they be understood as representative of the political context at point in time. 

He critiques the reliance or use of structural equal modeling in development of the measurement instrument on the basis that the question wording and definition of external political efficacy "implies a dynamic relationship" [-@chamberlain2012, 119], suggesting that novel measurement items would better cohere to the conceptual understanding of external efficacy if results captured individual's response to variation in government performance and economic conditions in retrospect. In other words, if external efficacy items measured perceptions of government responsiveness in reference to relatively recent actions of political actors, political institutions, and ever-changing economic conditions, then external efficacy in the aggregate would appropriately respond the such dynamic variation over time. 

Accordingly, Chamberlain's study is intended to test the validity of the construct in reference to how it is understood, defined, and measured in political science and public opinion. However, while sensible, the study misses the mark in a few clear ways.

Chamberlain [-@chamberlain2012] was one of a few who focused on external political efficacy and exposed substantive faults in both its conception and measurement. Rather than propose a new measurement or offer a new conceptual understanding, Chamberlain attempted to discern whether this individual-level construct was sensitive to external factors in the environment as would be expected given its conception and measurement. His research showed that aggregate external efficacy was not responsive to particular changes in the political environment. However, immediately brought into question is whether the predictors he selected are reflective or representative of the external political environment in the first place. 

Despite Chamberlain's revelations, no subsequent work has been done to reconsider the conceptual foundation of external political efficacy in relation to it's twin component, internal political efficacy, nor with respect to any sensible theoretical framework in the current age. Although vital at exposing fault lines of efficacy research in political science, Chamberlain relied on a conception of external efficacy conflated with government responsiveness. Moreover, his selected predictors are dubious as factors representative of the external political environment. Indeed, the independent variables used in his analysis are not factors or variables of the external political context but individual attitudes related to satisfaction with, and trust in, government.

Although one interpretation may conclude the public as relatively insensitive, inattentive, or myopic to their present conditions, another is that the concept of external political efficacy itself is poorly conceived.

The issue realized by Chamberlain was that external efficacy in the aggregate was insensitive to dynamic shifts of certain predictors. This invited challenge to both the concept and measure of external efficacy [-@chamberlain2012; see also @chamberlain2013]. However, @chamberlain2012's external predictors used to assess aggregate levels of external efficacy were a yearly average of Presidential approval, a yearly average of consumer confidence in the economy, and an average score on the trust in government index. These predictors were, nor are, hardly of the sort that have anything to do with the people's capacity to shape their political environment. Rather, these predictors are more inclined to show strong relationship with satisfaction with government. 

Yet therein lies the problem: external efficacy **is not** understood in the literature as a belief about one's ability to impose effects upon, or very well *shape*, the political environment. In fact, its conceptual definition is most often described as "...referring to beliefs about the responsiveness of governmental authorities and institutions to citizen demands [@craig1990, 290; @niemi1991a, 1408]. In other words, external political efficacy is conceived as a measure of an individual's evaluation of the government's sensitivity to public preference by reference to the government's perceived responsiveness to "people like me".

## Background (Literature Review)

The literature on political efficacy in political science is stagnate.

The bad news here is that external political efficacy is, and has been, conceptually ambiguous and easily conflated, which leads to inevitable problems in measurement and a severe challenge to any notion of construct validity. It is questionable that the two standard external efficacy items measure what scholars profess they measure, and worse, it isn't clear *what* these two items actually measure in the first place. Especially as a hypothetical construct distinct from, but related to, a multitude of other attitudinal constructs. On the one hand, external political efficacy is expected to correlate with internal political efficacy, but distinct enough from it that it falls along its own dimension, hence the "internal" and "external" distinction. Relatedly, external efficacy is also expected to relate to a variety of other political attitudes such as trust in government.

The approach of prior research has been to try and reformulate these two survey items so that the results correspond to our understanding of the concept. Hence, @chamberlain2012 expected to see dynamic shifts in aggregate external efficacy as certain predictors of the political environment shifted. Other researchers have modified or supplemented external efficacy items ad-hoc instrumentally to serve their given research agenda [@wolak2018; @phoenix2024]. In an excellent review and validation of the standard measurement used for internal political efficacy, even @morrell2003 glossed over the substantive conceptual and methodological weakness in standard measures for external political efficacy, noting mainly that prior researchers failed to properly distinguish between internal and external political efficacy. Earlier investigations into the meaning and measure of external political efficacy struggled to find alignment of conception with empirical data gleaned from survey observations [@abramson1972]. For his part, @converse1972 is cited to presumably as a weighty confirmation of the distinction between the dimensions of political efficacy by analysis and interpretation of longitudinal data on political efficacy gathered since its conception.

> "As implied at several points. it is useful conceptually to partition gross feelings of political efficacy as we have measured them over the years into at least two components, which might he more precisely labeled "personal feelings of political competence" and "trust in system responsiveness." The first term refers to the individual's sense of his own fundamental capacities and experience in operating in a political domain. The second refers to perception of properties of the political system as it stands at a point in time. The distinction is essentially the same as one made by Gamson between "efficacy" and "trust"" [@converse1972, 334].

However, the fundamental conceptual distinction of political efficacy into two component dimensions first must be attributed to Robert Lane [-@lane1959a]. It is with @lane1959a that the two dimensions of political efficacy begin an asymmetric development, writing in "*Political Life: Why People Get Involved in Politics*". He bases much of his consideration of individual political efficacy upon a quality he refers to as "ego strength",

> "Lying behind the capacity to assert oneself against the environment is the general concept of *ego strength*, a quality which is usually associated with the capacity to order one's life in a rational fashion, controlling at once the impulses which rise anarchically to the surface from within, and external events, in so far as they can be controlled....A person with a weak ego, one that has been thwarted in its development by repressive measures or simply never encourage to develop--"babified," so to speak--will tend to view the social scene as something over which he has no control." [@lane1959a, 147, emphasis original]  

@lane1959a assessed that political efficacy distinguishes into two component internal and external sub-dimensions relating to "...the image of the self and the image of democratic government" (149).

> "Men who have feelings of mastery and are endowed with ego strength tend to generalize these sentiments and to feel that their votes are important, politicians respect them, and elections are, therefore, meaningful processes. This constellation of attitudes has been variously called "a sense of political efficacy," "political self-confidence," and, in reverse, "sense of political futility. It has, of course, two components--the image of the self and the image of democratic government--and contains the tacit implication that an image of the self as effective is intimately related to the image of democratic government as responsive to the people." [@lane1959a, 149].

Solidifying the divide of political efficacy into its internal and external components was @balch1974's analysis, which applied a unique multitrait-multimethod matrix method [@campbell1959] to test the construct validity of survey measurement items. Analysis since then has primarily aimed to bolster the internal and external dimensions [@hayes1993; @morrell2003].

## 2025-05-15

> "Perhaps in no domain might the potential for these policy feedback effects be more obvious than in the context of electoral reforms, which affect the most central and visible of democratic processes and have the potential to personally impact how each member of the polity engages in the political process." [@trexler2025, 3]

Recent research provides further evidence that bolsters the notion that external political efficacy is invalid in both concept and measure[@trexler2025]. The study by @trexler2025 found that, "...election reforms designed to expand access to mail voting systematically influence people's feelings of political efficacy or trust across time or in response to the unique circumstances of specific elections..." [-@trexler2025, 2].

Shifts in policy, especially shifts related to the means of political production (i.e., voting in elections), should relate to the public's appraisal of their popular capacity to shape the political environment. Reform intent on expanding access to to voting are indeed policy changes that can be understood as changes to the people's capacity to shape the political environment. This is because such policies affect the public's *means of political production* which correspond to the public's appraisal of their popular capacity to effectuate change. Thus, policies which affect the means should influence appraisals of popular efficacy from the perspective of the subject (to which those means apply).

However, according to the commonplace definition of external political efficacy, shifts in such policy can only be expected to relate to shifts in external efficacy with regard to the individual's impressions about government responsiveness to public demand. That is, so long as the individual interprets such policy changes as government action spurred (stimulated) in response to public demand, and so long as such policy changes are considered to be congruent with public demand. 

:::{.good-but-cut}
A clear issue is the extent to which policy support or endorsement is cued from political elites, i.e., from the top-down. That is, whether a person favors or disfavors a particular policy or political outcome is more-often-than-not informed by a person's partisan inclinations. 

The individual's evaluation is contingent on whatever they believe to be demanded by the public. More importantly, which ever party holds majority power may easily inform one's feelings about the government *writ large*. That is to say, the affective component of one's consideration is easily tempered by partisanship. Yet it is somewhat unclear how those who are generally ambivalent inform their evaluation of government responsiveness. In fact, it is questionable whether any such consideration ever occurs prior to asking the question.

The individual must have reconciled their impressions about the overall responsiveness of government officials and institutions to public demand with the policies and outcomes of government and politics. One clear issue is the limited extent to which the public considers policy at all in their evaluation of government and government officials. Partisanship is a simple heuristic that evidently forms much of the basis of one's impressions about, and evaluations of, government and politics. Such is the case for the most sophisticated as it is for even those of marginal interest and understanding.
:::

Different policies and regulations that out pour from government action shift and change political conditions regularly. The changes that would be expected to relate to, or influence, a person's beliefs about the capacity to shape conditions of the political environment are those policies that directly pertain to the means incorporated for doing so. As such, it is reasonable to expect that policy changes to elections and voting significantly relate to external political efficacy.

I think one of my strongest arguments against external efficacy is that it can easily be referred to as something else without confusion. For instance, it can be simply referred to as a crude concept and measure of perceived government responsiveness, "...beliefs about the responsiveness of governmental authorities and institutions to citizen demands". Yet better concept and measures for perceived government responsiveness have emerged. The measurement items may serve well if included in a bank of items so long as they are appropriately validated using IRT methodology. 

# 2025-05-16

Previous research has already demonstrated that changing the rules significantly effects voter turnout, participation, vote choice, and the like [@ang2019]. The question is whether particular efficacy beliefs are concurrently impacted. That is, we would expect efficacy beliefs to shift when the rules change; especially those rules pertaining to the people's capacity to effectuate change in their political environment through government and politics. If the measurement instruments in use are sound, then we're better able to determine whether, and to what extent, public attitudes are sensitive or insensitive to actual shifts within the political environment. However, if the measurement instruments in use are not sound (invalid), then credibility of our conclusions are dubious at best.

To put in other words, the event here is the ruling in Shelby County v Holder which empowered state governments to change voting laws without need for preclearance from the federal government. so across the different states, voting laws changed or did not change. The question is whether changes in laws that pertain to popular efficacy stimulate efficacy beliefs *in general* as measured by external political efficacy measures. 

So to be clear, the aim of this study isn't to determine whether changes to voting laws influence external efficacy *per se*. Rather, the aim of this study is to determine whether the meaning and measurement of external efficacy is sound. If the shifts in external efficacy are not significantly related to changes to political conditions (such as voting laws), there are two potential interpretations: either attitudes/beliefs are insensitive to changes in the political environment or the measurement instrument in use is unable to measure the attitude of interest. We can only suppose the former is the case insofar as we are confident that the measurement of the construct is sound. However, multiple studies over time have noted inconsistencies [] and efforts to validate the meaning and measure of external political efficacy are not only sparse but throw a substantial amount of doubt on the validity of the measurement. Moreover the conceptual understanding of external efficacy is hardly distinguishable from government responsiveness, which is further complicated by such strong relation to political trust (trust in government). In fact, early literature attempting to disentangle the conceptual ambiguity refers to external political efficacy as the "responsiveness component" and "perceived responsiveness" [@craig1979]. 

Yet if it happens to be the case that shifts in external efficacy are not related to changes in political conditions, the most damning evidence against the implication that attitudes/beliefs are merely insensitive to changes in the political environment is the evidence showing that significant changes in political behavior can be attributed to, or associated with, changes within the political environment. We may be able to detach political behavior from having a necessary relationship with attitudes; attitudes don't necessarily cause political behavior. Yet it is untenable to consider that shifts in the environment, which subsequently spur changes to political behavior, won't also elicit some shift or development of relevant attitudes. 

The problem with external political efficacy, or political efficacy as it is understood generally, is that nothing seems to account for an upward shift in efficacy despite significantly substantive changes of political conditions in history common to the public writ large. When reviewing average scores of the external efficacy index over time, a steady decline in external efficacy begins from its height in 1960 ($73.5$) downward to 2020 ($28.5$), with yet unexplained spikes and dips from 1984 to 2002. Although comparison shows that higher levels of average external efficacy in the aggregate are most prominently distinguished by educational attainment over time, there is a clear decline despite changes that expanded or further enabled the public to shape the political environment by the means available during the Civil Rights Era. When distinguishing by race, average external efficacy among White non-Hispanics is considerably higher compared to Black non-Hispanic throughout the extent of external efficacy's history of measurement^[I don't think there's an issue with breaking down the trend by race, seeing as how the ANES includes weights so as to be representative of the national population]. However, simply reviewing the external efficacy index does not hint that any dramatic political changes regarding public capacity came about during the era in which the Voting Rights Act (VRA) was enacted and repeatedly affirmed.

In particular, the Voting Rights Act incorporated monumental change in the political environment that affected all subject to that same environment in common^[Perhaps technically speaking, the VRA changed the political environment by serving as an act "[t]o enforce the fifteenth amendment to the Constitution of the United States, and for other purposes.". Ratified in 1870, the fifteenth amendment had already explicitly prohibited government from denying or abridging the citizen's right to vote on account of race, color, or previous condition of servitude. Although prior laws were in place that included provisions intended to guarantee voting rights, the VRA of 1965 conditioned the capacity of state governments to deny or abridge voting rights by imposing criminal penalties for violation of the law, subjected state governments to federal oversight of voting laws, and directed federal intervention to guarantee voting rights.]. Although the extent of what the people could do (i.e., could produce or bring about as governors) didn't change, the conditions shifted to restrain governing actors of the many states from incapacitating whole swaths of the public from participation in the endeavor. Such change in political conditions directly relates to the people's capacity to shape the political environment given the changes pertain to the means of popular political production (even if it is limited to electing persons into official government positions).

The point is not that we would expect to see shifts in political efficacy or external efficacy to be most prominent among Black people or other racial or ethnic minorities during or sometime after this time period. Rather, the point is that levels of external efficacy in the aggregate clearly decline despite changes where we would expect otherwise. Especially as the effect of the VRA on voter turnout and registration was immediate and dramatic in the years following 1965. However, under a conceptual definition of external efficacy seemingly interchangeable with government responsiveness and on par with political trust, the decline in 'external efficacy' as measured seems a bit more reasonable. This is apparent in @converse1972's early conjecture listing common events during the 1960's which, to him, appeared somewhat obvious as influential on the decline of political efficacy,

> "It is not hard to imagine what some of these events were during the 1960's, although specific items on any list would produce somewhat different impact in various segments of the electorate. A list should undoubtedly include the three shocking political assassinations in 1962, 1967, and 1968; the perception in some small but articulate quarters early in 1965 that Lyndon Johnson, after winning a landslide vote for his campaign against Goldwater's proposals to escalate the war, immediately had turned himself to escalating that war; resentment in other larger sectors of the population concerning official pressures toward school desegregation, particularly after 1964; race riots and campus disorders from 1965 on; and throughout, the increasing weariness and frustration with the bleeding war in Vietnam that the government could not seem to win or otherwise terminate. This sequence of national catastrophes, disruptions, and blunders seems adequate *to account for a considerable loss of confidence in the government and politics on the part of the public*. Nor is there much doubt that the decline of efficacy is functionally related to the weakening in sense of partisanship after 1965, which was discussed earlier." [@converse1972, 330, italics added]

Note that, while this small list can't account for all that was eventful during the 1960s, this list of events is indicative of how political efficacy---in particular, external political efficacy---was and has been understood *as an evaluation of government performance*. Converse refers to these events as "national catastrophes, disruptions, and blunders", yet the relation to efficacy in any sense of the word is not clearly explicated. How or why political assassinations would impact or relate to political efficacy is not obvious, at least not to me. In my view, this should have no impact on an appraisal of people's capacity to shape the political environment. Nor does the President's behavior in office concerning campaign promises made. However, if the meaning of 'efficacy', political or external, refers to satisfaction with government performance, then the short list offered by Converse does come off as a somewhat reasonable---though idiosyncratic---explanation for declining efficacy levels over time.       

(and this is my contribution I think) The conceptual understanding of external efficacy is too far removed from the meaning of efficacy to make sense as its own concept.    

The relation of political trust and political (or external) efficacy is, I think, due to the circumstance of the political system and regime type. Trust is requisite when powerless. Power, to be clear, denotes a condition of (having) possibilities for action and representing those possibilities as such. When the capacity to bring about a preferred outcome is unavailable to the one who prefers it, then they must rely on empowered others to take action and bring about preferred outcomes in their stead. Political trust is apt considering the regime type of the United States where a scheme of representation is in place. The actions and outcomes of politics and government are divorced from direct popular control. Those elected to office are vested with the power of government for the purposes outlined in the Preamble to the U.S. Constitution. 

As such, there is a degree of uncertainty that arises from the empowerment of the branches of government. Indeed, there is always uncertainty in the realm of possibility---when possibilities for action are present before actors. Even if the power of the people was explicated as being equal, or superior, to the branches of government and actors therein, there would still arise uncertainty with respect to the power of government and the relations of power. However, if the power of the people were on par with the power of governing actors, concerns over the loss of trust in government would be far reduced from what they are today and have been. Thus, the substantive significance and concern for the public's trust in government is itself an indicator of the relations of power between the people and their government.

Trust concerns how others will act provided the possibilities for action present before them, in particular, whether empowered others will act in accordance with some preference or stipulation. The public's trust of whether those vested with the power to govern the state will purpose their actions toward common ends.

The key difference between political trust and political efficacy must be that the latter is more relevant to appraisal of a state or regime as democratic, whereas the former is not relevant. A lack or absence of political trust in a political system wherein the popular capacity of the people is on par, and ultimately superior to, those agents vested with authority to govern bears no relevance as to the status or regime type of the political system. Of course, high levels of political trust writ large and in general is probably healthy and preferred, but trust is not necessitated due to the relations of power among the people and governing actors. Whatever disfavored acts that government takes is possible for the people to rectify by means of their popular self-governance; sufficient mechanisms of accountability in place render political trust of government a nice privilege but not necessary. In contrast, in a political environment wherein the people's popular capacity is stunted, restrained, or simply notional by the means present within the political system and processes, then a sufficient degree of political trust in government seems necessary to pacify the subjected populace.   

# 2025-05-19

The cost of voting index (COVI) measures the relative restrictiveness of each state's electoral environment [@schraufnagel2020]^[Note, "the 2020 COVI captures only "permanent" changes in state electioneering practices and does not count temporary changes adopted in response to the COVID-19 pandemic." [@schraufnagel2020, n1]]. 

>"Both stages of the voting process in the United States—registering to vote and casting a ballot are combined into a single index value." [@schraufnagel2020, 504]

Note from the authors in the 2022 publication update. Correct variable to use is the "Final COVI"

> "Erratum—Since the publication of the 2020 update in the Election Law Journal (Schraufnagel, Pomante, Li 2020), and making available a full replication dataset, third party researchers uncovered errors in our previous data collection efforts. We have made corrections and the new values are available as the “Final COVI” at costofvotingindex.com. We base the comparisons presented in the 2022 update on the corrected 2020 values." [@schraufnagel2022, 2020]

The method of calculating (note, not estimating) the index is by principal components analysis.

> "In each presidential election year, the assortment of relevant state laws is subject to principal component analysis (PCA), which has been used for many years now ‘‘to reduce the dimensionality of a data set consisting of a large number of interrelated variables’’ (Jolliffe 2002, 1). More specifically, PCA is a statistical procedure that uses an orthogonal transformation, which converts a set of observations of potentially correlated variables into a set of values of linearly uncorrelated items called principal components." [@li2018, 237]

> "In using PCA, the number of principal components extracted is always less than or equal to the number of original variables included in the analysis; in our case, seven different indicators each representing different issue areas. The first principal component accounts for as much of the variability in the data as possible, and each of the succeeding components has the topmost variance possible under the limitation that it is orthogonal to the previous components."


> "The first '*few*' (Jolliffe 2002, ix *emphasis in the original*) components are then normally weighted and combined to illuminate the internal structure of the data, in a way that best clarifies variance in the data."

So from my understanding, calculation of the index involves computing multiple component indicator variables each representing nine (initially, seven) different issue areas. Then, for a particular presidential year, PCA is conducted which returns two, three, or four components with eigenvalues greater than one. The number of components is selected so that their cumulative variance explained is greater than 70%. The selected principal components are normally weighted and combined to create a final index score. 

It is important to note that the index values themselves are not comparable from election to election, 

> "...it is not possible to simply compare COVI values from one election cycle to the next because there is a different set of laws in each of the 50 states, each election cycle, and the COVI scores derived are not comparable." [@li2018, 241]

However, as the authors note, it is feasible to test changes in relative state *rank*.

Regardless, this COVI may work well to test the meaning and measure of external political efficacy in accordance with what Chamberlain [-@chamberlain2012] initially posited. According to @chamberlain2012, the conceptual definition and measurement of external political efficacy implies that levels of the construct in the aggregate would be a function of prior shifts within the (*external*) political environment. 

Following Chamberlain's hypothesis, one would expect that external efficacy and COVI rank would be significantly associated over time. As a better indicator of the political environment across states, it should be feasible to regress external efficacy on state rank. As state laws change from one election year to the next, their relative rank based on COVI values change as well; states where voting laws became more restrictive from one year to the next will have lowered in rank relative to other states.

After the 2010 midterms, many states began introducing and enacting laws pertaining to voting and registration. After 2010 but prior to the *Shelby County v Holder* decision in 2013, 13 states had enacted new voting laws that were in place for the 2012 election. 

State voting and registration laws condition to the public's capacity to shape political conditions, at both the state and national level. Thus, we would expect that evaluations about the very capacity to shape the political environment---from the perspective of the subject---would shift in accordance with changes to the political environment. In particular, in states where public capacity is expanded, efficacy should be higher; whereas in states where public capacity is constrained or reduced, then efficacy would expected to be lower. Importantly, I would expect to see significant shifts in external efficacy corresponding with the changes in state voting laws that proliferated after the 2013 *Shelby County v. Holder* decision. 

Importantly, the point is not that the individual evaluates whether changes in state law were or are induced by public demand. Rather, the individual evaluates the extent to which the people are capable of changing political conditions given the means of political production. In this case, state voting laws pertain directly to the means available to the people for production of political ends. Voting laws that are more restrictive in turn hinder the capacity of the people, not necessarily by nullifying the people's input, but by reducing the extent to which they represent the possibilities as being possible for them. A proper measure of efficacy would is an appraisal of the people's popular capacity to self-govern from the perspective of the subject. 

The goal is not merely to participate, nor merely influence governing actors. The question posed to the individual is whether the people are able to shape the political environment given the means available for doing so. Thus, an individual evaluates the people's popular capacity to shape the political environment by appraising the means of political production available to them. In the United States, the people are relatively divorced from producing political outcomes directly, and so government officials function as intermediaries toward the ends of the state. 


An improved conception of efficacy would not refer to the perceived responsiveness of government officials and institutions, but rather an appraisal of the people's capacity to shape the political environment given the means of political production available to them

Note that the 'cost of voting index' scores for a particular year are not comparable to a subsequent election year. Although (from my understanding) the COVI values cannot be compared to themselves

However, if measures of external efficacy are valid, but simply not sensitive enough, then the magnitude of any shift of aggregated public sentiment would appear dull, if significant at all. If measures are invalid---that is, if measurement items are capturing something unrelated to political efficacy---then any observed relationship would not be explained by the changes to the political environment, but by some other factor, thus failing to conform with theoretical expectations.  

An enormous wrinkle is that public perception measured by external efficacy items have been shown to be influenced by partisanship and policy congruence, at least at the state level [@wolak2018]. In particular, (state) external efficacy is higher if the state legislative chambers and governor's office is controlled by partisanship of the individual, but lower if not. In addition, (state) external efficacy is higher insofar as ideology is congruent with a state's policy liberalism score. That is, self-identified strong conservatives feel more efficacious in states with a score that indicates stronger conservative policy.

> "People are more likely to believe that politicians listen to the public when state officials produce policy outcomes that align with their ideological preferences." [@wolak2018, 776]

> "Feelings of external efficacy are thought to reflect people’s subjective sense of being represented in politics, where those high in external efficacy believe that politicians listen to the public and respond to their concerns. What makes people feel like state politicians listen to what people like them think? I find that when state officials act in accord with people’s preferences and produce policies that align with constituents’ interests, people are more likely to believe that they are influential in state politics. I also find that people feel more external efficacy when state government is controlled by in-partisans and less efficacy when state government is led by out-partisans." [@wolak2018, 780]

The trouble with this is that the public's capacity to shape or change their political environment transcends partisanship and ideology. Political efficacy concerns the capacity of the people as those who are subject to the political environment. Partisanship pervades and distorts perceptions of political reality. Considering that external efficacy is referred to as an individual's perceptions about the responsiveness of government and institutions to public demand, then it should be clear that partisanship is a potent influence upon that perception. The decisions by the Supreme Court apply nationally as supreme law of the land. Although differing policy outputs of the states may conform to a more liberal or conservative ideological classification, laws pertaining to voting and registration apply to people in their status as citizens. In many cases, the purpose of these changes are to marginalize and oppress particular groups of citizens---notably racial and ethnic minority groups.

# 2025-05-22

The coverage formula was used to determine which states would be subject to preclearance under Section 5 of the VRA. Once the coverage formula was ruled unconstitutional, states that were previously subject to preclearance were no longer, and no new states could be made subject to preclearance unless by court order under a different section of the VRA. To put in perspective, the capacity of state government actors to restrict, expand, or otherwise modify the means of political production was subject to conditions established by the VRA and for the purposes thereof. In other words, prior to the 2013 ruling, the power of those elected to govern was limited so as not to encroach upon the popular capacity of the people. 

The *Shelby County v Holder* ruling empowered governing actors to shape conditions of the political environment that directly related to the popular capacity of the people to do the very same. The VRA may be seen as empowering the people to engage in the design, shape, and direction of their political reality, but this is only in relation to the power of governing actors to impede upon the means available to the people for doing so. That is, the VRA simply affirmed that the means of political production are not to be made inaccessible to anyone of citizen status, nor privilege anyone on a basis beyond such status. As citizens are subject to the political environment, governing actors are capable of subjecting the political environment just as well. However, the extent to which governing actors can shape or re-shape the political environment (by modifying the conditions thereof) is subject to conditions ordained and established by the Constitution. 

:::{.callout-note}
The following is probably useful to consider as thoughts pertaining to my prospectus.
:::

As citizens are subject to the political environment, governing actors are capable of subjecting the political environment just as well. However, the extent to which governing actors can shape or re-shape the political environment (by modifying the conditions thereof) is subject to conditions ordained and established by the Constitution. This is the case regardless of whether the people themselves are capable to act as governing actors. Yet that is the very question that concerns inquiry of the people's political efficacy: whether, and to what extent, are the people capable of subjecting the conditions in which they are equally subject? Said in other words, to what extent can the people shape their political environment? 

It is implied that this inquiry regards the people in their capacity (i.e., status) as both citizens subject to governance of the state and and as governors of the state. That is, the power of interest here is that which is in accordance with the political system and not beyond it. Beyond the state of the political environment---i.e., the political reality as constituted and governed by recognized political actors---is the state of nature. Thus my interest is not in regard to the power of people in nature---beyond the conditions that comprise the political environment. To put simply, my interest is of the popular capacity of the people as a political actor within a particular political system and context. Yet therein lies an essential point regarding the power of the people as recognized political actors, or indeed recognizable as a popular political actor. 

There is no similar question about the power of government since such powers are vested in the particular branches of government. Indeed, the only questions that arise is whether the actions of government are within the bounds of what is or has been afforded (vested) to governing actors as established or necessarily implied by the Constitution. The branches of government, as well as any officials thereof, are clearly established and recognized as political actors. In fact, one of those branches, the Judiciary, is responsible for confronting such questions about the power of government with respect to the Constitution. 

Yet as it concerns the people, there is nothing so explicit in regard to their power as the supreme popular actor from which all possibilities for action are derived. In theory, it is implied that the people not only have all power of government implied or established explicitly in the Constitution, but also whatever power beyond it. That is to say, it is notional that the possibilities present before the people are represented by them as such (as possible). Yet such notions are merely that: not ordained, not established, but made real only by conviction to legitimacy of the idea and adherence to the same. The power of the people is unwritten, abstract, and *apocryphal*.

Given the means of political production available to the people in accordance with the political system, what is the extent of the people's popular capacity to shape the political environment?  

# 2025-05-27

Political efficacy arose instrumentally as a concept for researchers aiming to explain political behavior. In other words, the concept of political efficacy was invented merely as a tool to explain political behavior---an explanation of behavior based on, or in, the psychology of the individual. Although behavior isn't always coherent with attitudes, nor is it simple to conclude that one's behavior is primarily driven by their attitudes, it is harder to deny links between behavior and the environment. A link without which the field and study of economics cannot do. 

:::{.callout-note}
2025-05-29, the following is a short little digression that I didn't relate back to the paragraph above.
:::

The link between behavior and attitudes is far more troublesome, as the assumptions of traditional economic theory---i.e., rationality and self-interest---fail to hold on observation of human behavior in relation to conditions of the environment. Behavioral economics focuses on studying the failures of these assumptions by developing models of behavior consistent with findings from psychology. In particular, behavioral economics incorporates cognition into studying the link between environment and behavior. Incorporating cognition incorporates the study of how humans reason, process information, acquire knowledge, hang on to knowledge, and the like. Thus, what is found in the discipline are concepts and theories related to heuristics, or mental shortcuts, biases, patterns, modes, and methods of thought and the effects thereof on decision-making and judgement; mostly with reference to some deviation from logic into fallacy. 

As such, behavioral economics stops just short of being a disciplinary field focused on the study of opinions, opinion formation, sentiment, attitudes, or simply, beliefs, although there is much overlap and relation. Conditions of the environment are understood as affecting cognition which is doubtlessly connected with behavior in one way or another, thus affirming the link between environment and behavior through cognition. But attitudes are somehow their own beast not wholly detached from any of these but also not necessitated by any of them either. Although the relation is readily apparent, the link is ultimately less clear between attitudes and behavior, the environment and attitudes, and the interconnection between the environment, attitudes, and behavior. Even the coherence between cognition and attitudes is fugitive. A person's cognition may be observed as responsive to the environment, which may help to explain this or that behavior, but an attitude can be studied in much the same way while observed as independent from the particular behavior, and sometimes even seemingly independent of cognition itself. Simply put, attitudes are weird. 

Attitudes are something like fickle conclusions, evanescent in nature. Attitudes are sometimes settled after some cognitive process spurred on by environmental stimuli, or sometimes not. A resulting attitude can be wildly incoherent from, while still significantly related to, contextual stimulus and subsequent cognition. Or sometimes attitudes are seemingly not the result of any conceivable cognitive process or rationale, yet still vary from being weakly held and transient, to strong, intense, and stable over time. 

:::{.callout-note}
the following is copied from an earlier entry from 2025-05-16, but I added a lot today so I'm copying it here.
:::

Previous research has already demonstrated that changing the rules significantly effects voter turnout, participation, vote choice, and the like [@ang2019]; changes to the political environment affect subsequent political behavior. The question is whether particular efficacy beliefs are concurrently impacted. That is, we would expect efficacy beliefs to shift when the rules change; especially those rules pertaining to the people's capacity to effectuate change in their political environment through the processes of government and politics. If the measurement instruments in use are sound, then we're better able to determine whether, and to what extent, public attitudes are sensitive or insensitive to actual shifts within the political environment. However, if the measurement instruments in use are not sound (invalid), then credibility of our conclusions are dubious at best.

To put in other words, the event here is the ruling in *Shelby County v Holder* which empowered state governments to change voting laws without need for preclearance from the federal government. so across the different states, voting laws changed or did not change. The question is whether changes in laws that pertain to popular efficacy stimulate efficacy beliefs *in general* as measured by external political efficacy measures. 

So to be clear, the aim of this study isn't to determine whether changes to voting laws influence external efficacy *per se*. Rather, the aim of this study is to determine whether the meaning and measurement of external efficacy is sound. If the shifts in external efficacy are not significantly related to changes to political conditions (such as voting laws), there are two potential interpretations: either attitudes/beliefs are insensitive to changes in the political environment or the measurement instrument in use is unable to measure the attitude of interest. We can only suppose the former is the case insofar as we are confident that the measurement of the construct is sound. However, multiple studies over time have noted inconsistencies [] and efforts to validate the meaning and measure of external political efficacy are not only sparse but throw a substantial amount of doubt on the validity of the measurement. Moreover the conceptual understanding of external efficacy is hardly distinguishable from government responsiveness, which is further complicated by such strong relation to political trust (trust in government). In fact, early literature attempting to disentangle the conceptual ambiguity refers to external political efficacy as the "responsiveness component" and "perceived responsiveness" [@craig1979]. 

Yet if it happens to be the case that shifts in external efficacy are not related to changes in political conditions, the most damning evidence against the implication that attitudes/beliefs are merely insensitive to changes in the political environment is the evidence showing that significant changes in political behavior can be attributed to, or associated with, changes within the political environment. We may be able to detach political behavior from having a necessary relationship with attitudes; attitudes don't necessarily cause political behavior. Yet it is untenable to consider that shifts in the environment, which subsequently spur changes to political behavior, won't also elicit some shift or development of relevant attitudes. 

The problem with external political efficacy, or political efficacy as it is understood generally, is that nothing seems to account for an upward shift in efficacy despite significantly substantive changes of political conditions in history common to the public writ large. When reviewing average scores of the external efficacy index over time, a steady decline in external efficacy begins from its height in 1960 ($73.5$) downward to 2020 ($28.5$), with yet unexplained spikes and dips from 1984 to 2002. Although comparison shows that higher levels of average external efficacy in the aggregate are most prominently distinguished by educational attainment over time, there is a clear decline despite changes that expanded or further enabled the public to shape the political environment by the means available during the Civil Rights Era. When distinguishing by race, average external efficacy among White non-Hispanics is considerably higher compared to Black non-Hispanic throughout the extent of external efficacy's history of measurement^[I don't think there's an issue with breaking down the trend by race, seeing as how the ANES includes weights so as to be representative of the national population]. However, simply reviewing the external efficacy index does not hint that any dramatic political changes regarding public capacity came about during the era in which the Voting Rights Act (VRA) was enacted and repeatedly affirmed.

In particular, the Voting Rights Act incorporated monumental change in the political environment that affected all subject to that same environment in common[^1]. Although the extent of what the people could do (i.e., could produce or bring about as governing actors) didn't change, the conditions shifted to restrain governing actors of the many states from incapacitating whole swaths of the public from participation in the endeavor. Such change in political conditions directly relates to the people's capacity to shape the political environment given that the changes pertain to the means of popular governance (even if it is limited to electing persons into official government positions).

[^1]: Perhaps technically speaking, the VRA changed the political environment by serving as an act "[t]o enforce the fifteenth amendment to the Constitution of the United States, and for other purposes.". Ratified in 1870, the fifteenth amendment had already explicitly prohibited government from denying or abridging the citizen's right to vote on account of race, color, or previous condition of servitude. Although prior laws were in place that included provisions intended to guarantee voting rights, the VRA of 1965 conditioned the capacity of state governments to deny or abridge voting rights by imposing criminal penalties for violation of the law, subjected state governments to federal oversight of voting laws, and directed federal intervention to guarantee voting rights.

The point is not that we would expect to see shifts in political efficacy or external efficacy to be most prominent among Black people or other racial or ethnic minorities during or sometime after this time period. Rather, the point is that levels of external efficacy in the aggregate clearly decline despite changes where we would expect otherwise. Especially as the effect of the VRA on voter turnout and registration was immediate and dramatic in the years following 1965. 

However, under a misconceived definition of external efficacy---seemingly interchangeable with government responsiveness and on par with political trust---the decline in 'external efficacy' as measured seems a bit more reasonable. This is apparent in @converse1972's early conjecture listing common events during the 1960's which, to him, appeared somewhat obvious as influential on the decline of political efficacy,

> "It is not hard to imagine what some of these events were during the 1960's, although specific items on any list would produce somewhat different impact in various segments of the electorate. A list should undoubtedly include the three shocking political assassinations in 1962, 1967, and 1968; the perception in some small but articulate quarters early in 1965 that Lyndon Johnson, after winning a landslide vote for his campaign against Goldwater's proposals to escalate the war, immediately had turned himself to escalating that war; resentment in other larger sectors of the population concerning official pressures toward school desegregation, particularly after 1964; race riots and campus disorders from 1965 on; and throughout, the increasing weariness and frustration with the bleeding war in Vietnam that the government could not seem to win or otherwise terminate. This sequence of national catastrophes, disruptions, and blunders seems adequate *to account for a considerable loss of confidence in the government and politics on the part of the public*. Nor is there much doubt that the decline of efficacy is functionally related to the weakening in sense of partisanship after 1965, which was discussed earlier." [@converse1972, 330, italics added]

Note that, while this small list can't account for all that was eventful during the 1960s, this list of events is indicative of how political efficacy---in particular, external political efficacy---was and has been understood *as an evaluation of government performance*. Converse refers to these events as "national catastrophes, disruptions, and blunders", yet the relation to efficacy in any sense of the word is not clearly explicated. How or why political assassinations would impact or relate to political efficacy is not obvious, at least to me. In my view, this should have no impact on an appraisal of people's capacity to shape the political environment. Nor does the President's behavior in office concerning campaign promises made. However, if the meaning of 'efficacy', political or external, refers to satisfaction with government performance, then the short list offered by Converse does come off as a somewhat reasonable---though idiosyncratic---explanation for declining efficacy levels over time.

# 2025-05-28

Okay to bring it back.

The question at the heart of the issue is whether external efficacy is responsive to changes in the political context. 

The reason this question arises is because the meaning of the concept is divorced from the meaning of 'efficacy', conflated with government responsiveness, and far too easily confused with trust in government. Adding to this conceptual ambiguity, the measurement of external political efficacy offers no clarity and results from measurement lend little credence to construct validity. Only two items are utilized to construct an index, which itself is inadequate to consider as a measure of some homogeneous construct. 

The conventional, or standard, definition of external efficacy boils down to be understood as an individual's evaluation of government performance, composition, or behavior. Results of measurement might merely reflect one's satisfaction with government generally, though interpretation is easily construed in whatever way most convenient to the researcher. Indeed, external efficacy readily stands as an individual's evaluation of past government performance, but it just as easily stands as an individual's impression of government favor, or similarly, of system responsiveness to public input, or of government officials receptiveness to public preferences. 

For the two decades covering the 1950s and 1960s, @converse1972 noted that education, political attentiveness, and activism all closely correlated and increased together across time, whereas in contrast there was a general decline in the classic feelings of political efficacy as measured during that period [-@converse1972, 334]. Noting this divergence, Converse, as others, strove to decompose political efficacy into two distinguished components.

> "As implied at several points, it is useful conceptually to partition gross feelings of political efficacy as we have measured them over the years into at least two components, which might he more precisely labeled "personal feelings of political competence" and "trust in system responsiveness." The first term refers to the individual's sense of his own fundamental capacities and experience in operating in a political domain. The second refers to perception of properties of the political system as it stands at a point in time." [@converse1972, 334].

The deconstruction of political efficacy into two dimensional components was asymmetric.
Reading between the lines here and elsewhere in the literature impresses the idea that the goal of separating political efficacy into internal and external conceptual constituents was to parse out a construct that aligned suitably well with education, interest, attentiveness, and other characteristics based on individual-differences. The internal efficacy component mends well with these personal characteristics as a useful political correlate or function of them. 

There's a significant qualitative difference, however, between the explication of the first term and the obscure abstraction of the second. Indeed, "trust in system responsiveness" not only blends trust in government and government responsiveness into the external component, but is vaguely described as referring to a "perception of properties of the political system". Which properties? What kind of perception, exactly? That being said, Converse discusses an important point,

> "Although the distinction is easily made at a conceptual level, it is much more difficult to make empirically, for there are obvious causal interactions between the two terms. Moreover, *the sheer definition of personal skills that are politically effective is to some degree dependent on the shape of the political system itself, and most specifically, the kind of influence attempts to which it is open, if any*." [@converse1972, 334, italics added]

The evolution of internal efficacy has rendered its construal as one's personal confidence to competently confront political topics, affairs, or issues by measure of their general understanding and self-qualification in comparison to most other people in general. So feeling like one can personally be "politically effective" today largely rests on one's self-appraisal of their knowledge and understanding of politics. Yet Converse states that the requisite skills that are *in fact* politically effective is dependent on the shape of the political system itself, and importantly, "...the kind of influence attempts to which it is open, if any." 

Notable is the underlying notion that some set of individual personal skills are necessary for one to be politically effective. Converse, like others before and after him, afford special weight to an ideal model of citizenship; a citizen that is active, interested, well-informed, and otherwise engaged in the domain of government and politics is, and has been, modeled as the most efficacious since the conception of the term. Yet this contradicts the idea of political equality, where the input of one is no more or less than that of another of equal status. So if the shape of the political system is such that the status of each individual is politically equal---meaning equally subject to the law and so empowered---then individual differences such as personal skills are politically irrelevant. Unless the shape of the political system is such that unequal weight is provisioned to individuals of a certain class, caliber, group, or some other status distinction. Converse follows with an imaginary example to illustrate the distinction between the internal and external components while also noting the importance of the political context,

> "Imagine the articulate and gregarious individual with great organizational expertise transplanted from a democratic setting where he has employed his capabilities in party organization with high success to a dosed and heavy-handed authoritarian regime. The transplantation would not have affected his skills and, ideally, measurements should show a high sense of political competence but a low estimate of system responsiveness. However, most ways of assessing the individual's own sense of political competence would be inadvertently influenced in such a situation by limitations on skills that could plausibly achieve a political response in his immediate setting." [@converse1972, 334]

The setting---i.e., conditions of the political environment---are paramount in regard to political efficacy of any sort. What Converse seems to assume, however, is that for *democratic settings* a particular set of political skills, such as party organization capabilities, best contribute to one's capacity to produce responsiveness from government in return. 

Efficacy is inherently tied to the end for which some thing or act is purposed. Converse here makes clear that being effective means successfully influencing or being influential in some way in government and politics. Inherent to the notion of political efficacy is the underlying purpose of participating in the political process of whatever system. Implied here by Converse, and by authors everywhere else, is that the purpose of individual or popular political participation is ***to influence*** the actors and institutions of government. Therefore, it is conveyed by implication that *the maximum effect achievable through political activity* is but merely to influence governing actors of the political regime.


The core problem is that there is not a clear way to validate the construct as defined and understood because it is not defined well enough to be understood as a distinctive construct. 


# 2025-05-29

## What does the definition external efficacy imply?

Chamberlain's dynamic time series model with lagged dependent variable is insufficient to properly test the validity and congruence of both meaning and measurement of external efficacy. The theoretical justification for the method is lacking, and the chosen predictors are not tenable as factors representative of the political environment. 

Rather, I evaluate external efficacy over time from before and after 2013 when the Supreme Court invalidated the preclearance formula of the Voting Rights Act. After that ruling, many states since have passed a significant number of laws pertaining to voter ID, voter registration, methods of voting, and much more. Some states have passed laws that have are incredibly restrictive, yet other states have also passed laws aiming to expand voting rights^[Further complicating the matter is that states have passed a mix of restrictive and expansive voting and election laws.]. Of particular interest are states that passed restrictive laws immediately following the *Shelby v Holder* ruling. 

The hypothesis posited by Chamberlain still stands: external efficacy should shift upon changes to the political environment. However, this hypothesis relies on an alternate/competing conceptual understanding of external efficacy that substantially deviates from the conventional conceptual definition and understanding often professed in the literature.

The conventional, or otherwise, 'standard', definition of external political efficacy is conflated with government responsiveness and difficult to parse from trust in government. The expectation that external efficacy should shift in response to changes in the political environment doesn't necessarily follow from a conception of external efficacy as referring to "...beliefs about the responsiveness of governmental authorities and institutions to citizen demands" [@craig1990, 290; @niemi1991a, 1408]. Even when considering additional clarification regarding what survey items intend to measure and what low or lacking external efficacy implies, conceptual focus and operative measurement is based on the perceived responsiveness of governing officials and institutions.  

> "[External efficacy] measures expressed beliefs about political institutions rather than perceptions about  one's own abilities .... The lack of external efficacy . . . indicates the belief that the public cannot influence political outcomes because government leaders and institutions are unresponsive to their needs" [@craig1982, 86]

:::{.aside}
Note that a lack of external efficacy implies the "belief that the public cannot influence political outcomes...*because*..." shows that the end/goal/purpose "*to influence political outcomes*" is inherently included in the conception but glazed over by the presumptive cause of the belief. Moreover, the input isn't considered or consistent at all. Public *needs* aren't necessarily considered an input, but simply some stimuli the government is expected to be responsible for addressing. Later definitions speak of the input as "citizen demands" or something similar, but are mostly vague with respect to what is reasonable to expect government to be responsive to. It is a different question entirely to inquire into what stimulus (e.g., issues, situations, circumstances, events) one thinks the government should be sensitive to. Thus the input isn't clear and left vague for both the respondent and researchers alike.      
:::

Thus, it is hard to validate the expectation that external efficacy would shift upon changes to the political environment based on understanding of the concept expressed in the literature; the expectation doesn't follow from its conceptual definition. The political environment is not interchangeable with government responsiveness in meaning nor metric. Indeed, the very moniker of the construct as "external political efficacy" seems incoherent with its stated meaning.

## Does measurement of the construct imply its meaning?

Does measurement of external efficacy conform to a particular meaning of the construct that leads us to reasonably expect that external efficacy would shift in accordance with changes to the political environment? In other words, does measurement of the construct imply the given meaning of the concept? Evaluation of meaning from wording of the measurement items is certainly different from attempting to discern meaning from results of measurement. Yet the practice is worth doing considering measurement validity of the construct is exactly what is in question here.

The wording of the two measurement items imply that the individual's responses are based on evaluations of past government performance. Indeed, **all** evaluations of government performance or responsiveness are evaluations of past performance or perceived responsiveness; whether one's evaluations concern yesterday or yesteryear. However, for the sake of discerning whether the meaning is implied from measurement, it is not relevant when or how much of the past the individual considers in their evaluation. What matters is what those evaluations are about. Specifically, whether the evaluations are conclusively about government responsiveness. 

The problem is, however, that external political efficacy is not interchangeable with government responsiveness. These two concepts have been so heavily conflated that it is difficult for many reasonable scholars to consider external efficacy as referring to anything else. Conceptual issues inevitably result in measurement problems, and compound into difficulty in interpretation of results. The issue becomes easier to see when one considers how past government performance or responsiveness is evoked as interchangeable with the broader political environment.

Taken to understand external efficacy in this way, it seems reasonable for Chamberlain to argue that, "...the definition of the measure implies that past government performance should affect it." [@chamberlain2012, 119], but only insofar as an individual's evaluation of the contemporary political environment is coterminous with past government performance. The problem is that past government performance is treated as interchangeable with the political environment, "...as the definition of external efficacy implies, the measure is affected by the broader political environment" [@chamberlain2012, 118]. 

___

However, it cannot be readily assumed exactly what is being evaluated beyond what is stated in the survey items; nor can it be assumed just how much of the past is taken into account in order to make a response about today. One who takes much history into account is apt to consider things differently than one who takes into account only the incumbent regime or administration.

When a person agrees with the statement, "People like me have no say about what the government does", it is, of course, unclear how they have come to an agreement with that statement. It may be the case that a person considers the expressions and behavior of government officials writ large in order to decide whether they agree or disagree with the statement; but it may just as easily be the case that the individual relies on a general, holistic perception of the political environment as a proxy for what or who imposes influence on what the government does. 
In the first case, the individual bases their response on evaluation of perceived responsiveness of government officials to public opinion, demands, or interests of "People like me"^[Whether that is "People who think like me/agree with me" or "People who look like me" is mostly unclear and also confounds the issue to some extent. Note also the inherent collective aspect of external efficacy in contrast to the pure focus on the individual when it comes to internal political efficacy.]. 

In the second case, the individual bases their response on general impressions about the political environment as a proximate indication of who influences government officials or outcomes best in relation to "People like me". As such, if the political environment seems generally appeasing to "People like me", then one might come to disagree with the statement. Although, the 'political environment' in this case refers to whatever the individual conjures up to consider as a proximate indicator. For instance, the partisan makeup of government may suffice to inform the individual exactly who can successfully influence government. Or, more intimately, one's personal circumstances may suffice to convince them of who "has a say" in what government does. 

The point, however, is that the survey item has the individual consider what the government does as indication of who *can* successfully influence the behavior of government officials or political outcomes. Surely, a problem arises due to the need to compare between "people like me" and "others not like me".

___

provided a definition more coherent to the term 'efficacy' with respect to the purpose of the people's participation in government and politics, we can conceive of external political efficacy as referring to an individual's appraisal of the people's capacity to shape the political environment by the means (the possibilities for action present) of political production available. 


 
The theoretical support for the dynamic model that includes a lagged dependent variable seems justified under the notion that an individual's attitude, external efficacy, at time $t$ "is a function of that same attitude at $t-1$ as modified by new information" [@keele2006]. Chamberlain develops a dynamic model where external efficacy at time $t$ is a function of external efficacy at $t-4$ as modified by presidential approval at $t-1$, consumer sentiment at $t-1$, and trust in government at $t-2$. On its face, it seems a bit odd that external efficacy today at time $t$ would be partly a function presidential approval from a year ago but not, say, the same month, or the month prior, or even concurrently at time $t$. 

Regardless, what is more odd is the notion that presidential approval, consumer sentiment, and trust in government are all referred to as factors representative of the political environment. Surely these may be considered factors *about* the contemporary political environment, and these factors doubtlessly correlate with conditions of the political environment to some unknown extent, but it is far too much of a reach to consider these factors as sufficient proxies of the political environment. 

___

The trouble is selecting which states to consider as the "treatment" states, and which to consider the "control" states. An intuitively easy solution would be to simply designate the states formerly subject to preclearance as the "treatment" states, but this to me seems unsound. For one, the change of political conditions was general to all states after the ruling in *Shelby County v Holder*. The states that were previously subject to preclearance were, of course, no longer subject to preclearance, but the ruling rendered the coverage formula for determining which jurisdictions would be subject to federal intervention as unconstitutional. As it stands now, federal intervention in the electoral process of particular states may still happen under other sections of the VRA. 

Prior to the ruling, any state was susceptible to becoming subject to federal intervention (e.g., preclearance) in the electoral process if it met the criteria of the coverage formula. The VRA was amended multiple times over the years, and as new provisions were added to the VRA, other states and jurisdictions were added under new provisions included within the coverage formula. For instance, in 1975, the VRA was amended to include the "minority language provision" under the coverage formula to identify those jurisdictions where voting information was provided only in English and members of a single language minority comprised more than 5% of the citizens of voting age. As such, every state was keen to avoid implementing voting laws liable to charges of discrimination and anything else that was prohibited, while also keeping in consideration whether proposed voting legislation would be in effect discriminatory in ways not yet included in the VRA. In other words, *the possibility that future amendments could be provisioned added a conditional consideration for states aiming to change election and voting laws*.

So if one were to survey the states (as anthropomorphized beings capable of responding to survey questions), a certain efficacy question can be asked about the extent to which the state is capable of shaping its own political environment independent of the federal government and of the constituent populace therein. We would expect the political efficacy of these state-beings to have positively shifted after the *Shelby County v Holder* ruling even if no new voting laws had been enacted since. The condition of possibilities present before all states governments to dictate state voting laws, and thus subject the people to novel and potentially discriminatory conditions, had been expanded (or perhaps, regressed) to present additional possibilities for government action. In other words, the relations of power shifted such that states were empowered to condition the power of the people of the respective states. 

Not all states enacted restrictive voting laws since 2013. But selection of the states isn't necessarily about whether new laws were, in effect or intent, restrictive or expansive.  

The coverage formula was used to determine which states would be subject to preclearance under Section 5 of the VRA. Once the coverage formula was ruled unconstitutional, states that were previously subject to preclearance were no longer, and no new states could be made subject to preclearance unless by court order under a different section of the VRA. To put in perspective, the capacity of state government actors to restrict, expand, or otherwise modify the means of political production was subject to conditions established by the VRA and for the purposes thereof. In other words, prior to the 2013 ruling, the power of those elected to govern was limited so as not to encroach upon the popular capacity of the people. 

The *Shelby County v Holder* ruling empowered governing actors to shape conditions of the political environment that directly related to the popular capacity of the people to do the very same. The VRA may be seen as empowering the people to engage in the design, shape, and direction of their political reality, but this is only in relation to the power of governing actors to impede upon the means available to the people for doing so. That is, the VRA simply affirmed that the means of political production are not to be made inaccessible to anyone of citizen status, nor privilege anyone on a basis beyond such status. As citizens are subject to the political environment, governing actors are capable of subjecting the political environment just as well. However, the extent to which governing actors can shape or re-shape the political environment (by modifying the conditions thereof) is subject to conditions ordained and established by the Constitution. 

# 2025-05-30

Aggregation of the variable should allow us to observe whether systematic shifts in external efficacy are associated with relevant changes within the political environment. 

The changes in particular would pertain to conditions most relevant to external efficacy, namely to do with the capacity to influence the behaviors of government officials and outcomes of politics. That is, of course, given a conceptual definition of external efficacy that refers broadly to the capacity to *induce* response from government. This is in contrast to the capacity to influence the actions and outcomes of government. 

One would examine the actions and outcomes of government and judge whether government actions and political outcomes are responsive to a particular stimulus, namely public opinion[^1]. Alternatively, an individual could review political outcomes and government actions and report back with what or who government appears most responsive.   

Yet the measurement implies a meaning that refers to the degree to which it is the case that the actions and outcomes of government and politics are, and can be, influenced by the demands, preferences, or interests of some people compared to others. 


## 2025-07-30

### What's the problem

problems:
1.    Results no longer replicate with the inclusion of recent data 
2.    constraining analysis to 1986 and onward does result in significant results.
3.    Chosen predictors of Chamberlain's model are untenable as factors reflective of the political environment
4.    The given meaning of external political efficacy is confused.

In one sentence: we don't know what external efficacy survey items are measuring because we don't really know what we mean when we refer to external political efficacy. 

It's not because the measurement items poorly measure external efficacy as conceived, but rather because the very conception of external political efficacy is conflated, confused, and misconstrued.

Results derived from external political efficacy measures are readily accepted and given little to no scrutiny despite issues of measurement validity. Due to its confused meaning, researchers are given a wide berth of conceptual space where that very ambiguity is able to serve as a blank canvas. External political efficacy can range in meaning to such a degree that the conception seemingly detracts from even a simple semantic understanding of the word 'efficacy'.

## 2025-08-04

Note on considerations of RCS data

Even though Repeated Cross-Sectional designs are helpful in a number of ways, not all RCS studies are the same. Three things to consider:

-   Time between cross-sections. Time between repetitions of the survey. Variation in period can affect the nature of the sample.
-   Number of cross-sections. Are there enough cross-sections available to identify and analyze temporal trends?
-   Number of interviews at each time point. 

> "Depending on how these dimensions are combined, an RCS can be sensitive to different kinds of change. Larger samples with more interviews at each time point make it possible to distinguish true change from apparent change due to sampling variability. True change can come in two varieties. One is where the composition of the population is stable over time, but the units change their behaviors or attitudes. An obvious example is, where the members of an electorate decide that a candidate is better than they had originally thought, perhaps based on a performance in a debate. The other kind of change is compositional, where individuals do not change their proclivities but are themselves replaced by those with different characteristics. Both kinds of change can coexist in the population, but their relative prevalence and importance in samples depends on the interval between cross-sections and the total length of the data collection period." [@brady2015, 7]

> "The shorter the time between cross-sections, the more that true change must reflect change in individuals’ behavior or attitudes. Apart from sampling variability, change in the sample’s propensities can have no other source but the conversion of its component individuals. As the span of the series increases, on the other hand, attention is forced to compositional change, which typically takes years to register. Again, the passage of time may make possible—may even be necessary for—individuals to change their attitudes or characteristics, but the longer the span the more inevitable it is that samples will also be drawn from populations comprising different individuals." [@brady2015, 7]


> "Once again, better theories about how attitudes are affected by social and cultural change over time might be very useful." [@brady2015, 12]

This speaks to me.



# 2025-08-18 and 2025-08-19

A lot of today was spent reading up this and that around theories of measurement, validity and reliability, and the like. I started hand writing what was suppose to be a quick outline of my thoughts for today from the revelation I had the other night, but it quickly digressed. I'll try to copy down what I have hand written.

-   The hypothesis is that results will be uninterpretable regardless of significant or null results due specifically to the inadequacy of the common conceptual definition of external political efficacy.

-   Given the common definition of external efficacy as beliefs about the responsiveness of government to citizen demands, the external political environment is omitted from consideration. 

-   That fact is that when one appraises the efficacy of something or some act, the thing being evaluated must be the focal point of both the survey items and the definition of the idea. 

-   Efficacy items would be expected to place heavy emphasis on evaluating the extent to which political outcomes result from popular effort to induce government response towards particular ends, which may include but is not limited to, adherence to public demand, resolution of public grievances, amelioration of disfavorable conditions, or profit to common interests. In other words, the individual would evaluate and appraise the maximum effect of public intervention toward inducing government response to shape the political environment according to popular demand or common interests. 

-   This establishes a different focal point of the efficacy items, which would be the maximum effect of popular intervention toward political ends. Importantly, I start with what we want to know rather than *why* we want to know it or what knowing it would be good for. Political efficacy was conceived of instrumentally as a construct meant to help explain political behavior. The disadvantage is that this anchored the conception of what it meant to *feel* more or less efficacious to a prototypical model for the highly "efficacious" citizen.

-   Drawing from the seemingly putative purpose of political participation, early researchers sculpted the concept of "sense of political efficacy" from of the image of the kind of person they believed would engage in the most effective forms of political participation at the time. That is, they established the beliefs and behaviors of the efficacious citizen as the ruler by which one would measure their own sense of political efficacy. The beliefs of the efficacious individual were what theoretically explained a person's political behavior, and as such, researchers endeavored to test a set of beliefs about one's own political efficacy that would match what researchers ***recognized as a matter of fact*** about the efficacy of individual political action. To put in other words, it was, and likely still is, presumed that an individual's political capacity to impact the political process through political action is an objective fact of the political environment and system therein. Thus, the construct is developed to measure the extent to which the efficacy of political action is more or less correctly ascertained from the perspective of the subject (i.e., subjective). 

-   The researchers' understanding about the political system implied a steadfast belief that the political system completely facilitated individual efforts to participate in the political process, that the individual would not be inhibited from participation by the conditions of that system, and that said individual political participation doubtlessly influences the outcomes of government. To put in other words, to them the politically efficacious individual was knowledgeable about the way the political system worked because there was no question that it did in the way they understood, and the politically efficacious individual believed in their own capacity to bring about change just as much as the researchers *knew* this to be the case. There was, and perhaps there is, an underlying presumption inherent about the means of political production available to the individual via the political process. Hence the individual was more or less sensitive to the *actual* capacity of individual political action to influence the political process, and this "sense of political efficacy" was meant to be measured to the extent possible by the short number of survey items developed.

-   Now to be clear, this is only saying that researchers developed a set of items meant for the individual to subjectively evaluate the efficacy of individual political action without establishing what "having an impact on the political process" actually meant. There's plenty that is conveyed through such a vague statement, and in the evolution of the concept of political efficacy over time we see that "having an impact on the political process" came to mean rendering government responsive to public demands or needs, at least in the *external* sense of political efficacy. 

-   To put into perspective, the progenitors of the concept "sense of political efficacy" vaguely established the maximum effect of individual political action as "having an impact on the political process", whereas later on this vague purpose for political action would be more narrowly defined, and limited, to rendering government responsive. Moreover, the emphasis on one's feelings about the efficacy of "individual political action" is refined such that *expression* qualifies as meaningful political action within the political process. This permits more flexibility to promote public opinion as a means to stimulate government response, or rather establish the expectation that government actors ought to be responsive to public opinion, and reduces the purpose of popular political activity to the limit of influencing government actors.

-   The point is not that political expression does not qualify as political activity[^1], but rather that political expression is refined as an instrumental means to the end of popular political activity---which is implied as '*to influence government actors*'.  

[^1]: There have been strenuous attempts to set boundaries for what qualifies as political activity or participation, to create a taxonomy for a multitude of activities, as well as attempts to create a method to classify whatever modes and means arise in the future. 

-   The meaning of responsiveness that arises from review of the items merely speaks to ephemeral considerations of government actors---whether they take time to consider the thoughts and expressions of "people like me" as they carry on in their role as governing actors.

-   This eventually leads to where we are today wherein which the idea of external political efficacy is the extent to which government actors and institutions are responsive to public demands (or needs)---not necessarily responsive to any form of popular input or action. The items meant to measure external efficacy, however, have the respondent evaluate whether government actors appear to be influenced by their own considerations of public wants and needs rather than whether public input effectuates responsive government. In other words, the items have the respondent judge the quality of the ends given some means, instead of having the respondent evaluate the capacity of the means to bring about particular ends. 

-   As such, in the 1950s when the idea of political efficacy was devised, *the pursuit of influencing politicians* was achieved most effectively within a more intimate context less familiar today, and researchers modeled an efficacious citizen as an individual well aware of the possibilities present to them within the political system as they knew it then.  

-   Consideration about what the survey items are meant to measure, rather than what the measure would help explain or predict, suggests a different conception of efficacy coherent with the purpose of popular political activity.

-   conditions of the political environment must be viewed by the respondent as a product of government efforts made in response to public input of some kind. In other words, the individual must place the government at fault for contemporary conditions AND said conditions must have come about in spite of public demand or political activity. Or said another way, government actors and institutions of government are solely responsible for contemporary political conditions and the public cannot be held responsible for contemporary political environment.   


# 2025-08-20

I think I've worked out what I need or want to do.

I plan to conduct an analysis of external efficacy by states categorized according to the Cost of Voting Index. Because of the fact that state laws change quite significantly in the intervals between general election years, I am unable to simply compare the relationship between (external) political conditions and external political efficacy across time as if the political conditions per state remained constant over time: they do not. 

So long as we accept that a state's cost of voting is, at least in part, a reflection of that state's political environment, then  which conditions the capacity of the people to shape the state, and national, political environment.

As such, it is best to analyze external efficacy for the years where final cost of voting index values (COVI) are available: 1996, 2000, 2004, 2008, 2012, 2020.

Since, essentially, there are two values per state---external efficacy and COVI---then it seems viable to conduct an analysis of external efficacy at the state-level regressed on the state's respective cost of voting. 

However there is a slight hiccup with this approach: the external efficacy index can be aggregated at the national level easily since the ANES works to ensure the sample drawn is representative of the national population. However, samples for ANES surveys conducted using face-to-face interviews are drawn using a sampling method known as *stratified cluster sampling*. 

> "Area sampling involves first drawing a sample of regions of the country, and then sampling successively smaller geographic areas within those regions, before sampling specific households within the sampled small areas." [@debell2010, 5]

This geographic clustering prevents using the data to make statistical inferences for geographies below the national level, i.e., states.

That being said, starting in 2012 onward, the ANES began collecting survey data over the internet alongside conducting face-to-face interviews. The two modes of data collection result in two independent samples for the ANES surveys administered in 2012, 2016, 2020, and 2024: a face-to-face sample and an internet sample[^1]. Because the internet samples of these years are not geographically clustered, it is then feasible to conduct analysis and make inferences about populations at sub-national geographic levels (i.e., states, regions). Of course, this is conditional to there being a sufficient sample size at the geographic level of interest. 

[^1]: Due to COVID-19, the 2020 ANES survey used a contactless mixed-mode design that included live video interviews, self-administered online surveys, and telephone interviews.

It might be possible to aggregate the external efficacy index to the state-level, but this would require splitting up the ANES sample according to the geographic level of interest (e.g., state, region) and then weighing that sub-sample against benchmarks for the geographic level. While it is, perhaps, technically feasible, the problem is that depending on the sample size for whatever geography, the variance (sampling error, I think) would end up being quite large. As @debell2009 states, 

> "If constructed well, weights normally enhance accuracy at the price of increased variance (which means less precise estimation and fewer statistically significant findings)..." [-@debell2009, 4].


So if I would like to analyze external efficacy at the state-level, there would need to be a sufficient number of observations for the states included (or whatever sub-geographic level). 

Ideally, there would be a sufficient number of observations for every state, but this is not likely for any year of a particular ANES survey with an internet-only independent sample. 



A frequent question asked[^1], "Does ANES provide data that is representative at the state-level or any small geographic level?"

> "We use a sampling methodology that is scientific and probability-based but is intended to be representative nationally, not at the state level. It can be used to study different sub-populations (education, race, gender) at the national level if there are enough cases available in the sub-populations of interest. But we would not recommend using our data for representative state-level analyses or for analyses at any smaller geographic level."

[^1]: see [ANES FAQ]((https:://electionstudies.org/faq/))

Supposing there are enough cases observed for other sub-populations that are usually of interest (e.g., race, education), it is possible to conduct analysis that is representative of the sub-population/sub-group at the national level. States, or other geographies, are not really sub-groups in the same sense, however; studying a certain demographic sub-group included in the sample is weighed against the total population of people matching that demographic characteristic within the population. 

The geographic-level, however, isn't an individual unit of the population, but a sub-level or component (or category) within the larger population. The geographic-level identifies the population under study, and the sample of said population is drawn to make inferences about the population by use of statistical methods. If I want to estimate a parameter of the population at the state-level, there needs to be enough cases drawn from the state (i.e., sufficiently large sample size) in order for me to make accurate inferences about the state population. Thus, I would need to weigh the cases drawn from each state (state samples) against respective state population benchmark characteristics.

Since the ANES data are weighed to the sample, not the population, the data needs to be weighed against the full (national) population count. However, is it possible for me to take the same unweighted data that pertains to each individual state and weigh said data against the full population of that state? In other words, is it feasible for me to weigh ANES data against benchmarks for each state?  


# 2025-08-22


I want to determine which states enacted new election laws in the period prior
to Shelby but after the 2010 midterms. The idea is that certain states enacted
legislation in anticipation of the Supreme Court ruling in Shelby v Holder. 

I attempted to determine this myself through various sources online, and I
eventually landed on the 25 states that passed restrictive election laws in the
section above. However, I don't have the criteria to justify which laws are
considered "restrictive" versus not, which in turn means I can't really justify
the inclusion of the 25 states selected.

The number of states that enacted restrictive election laws was derived from the Brennan center. Although I don't doubt the researchers there, I need to verify for myself which states
enacted new election laws in the period after 2010 midterms but before the *Shelby v Holder* Supreme Court decision. In order to do so I have downloaded the National Conference of State Legislature's State Elections Legislation Archived Database that includes enacted state legislated from 2011 to 2024.

However here is the current issue: there's no standard criteria for me to classify laws that are restrictive, expansive (or progressive), or simply relevant. It would be an insurmountable endeavor to attempt to classify each law enacted after 2011 but prior to 2013. It certainly is possible for me, using this NCSL database, to include only those laws enacted within the specified period, but given that the interest is in classifying the political context with respect to the people's capacity to shape the political conditions in which they are subject (i.e., popular efficacy), then I would need to classify laws based on a single criterion: 1) whether the law is relevant to the people's popular capacity to govern. This endeavor is beyond the scope of this study.

Fortunately, there exists now a Cost of Voting Index which is a measure of the time and effort required to vote, encompassing criteria such as registration requirements, voter identification laws, early voting availability, absentee voting procedures, and multiple signature requirements for absentee ballot envelopes [@pomante2025]. The COVI can be reasonably considered a factor reflective of the political environment that, in particular, condition the the means available to the people. That is, the higher the cost of voting, the less available are the means of political production to the people *writ large*. Even if some laws are specifically intended to discriminate against those less able to afford higher costs, and even if higher costs seem to *effect* only particular subgroups within the population, the cost of voting is uniformly applied to all who are subject to the conditions of the political environment. Therefore, a higher cost of voting further diminishes the people's popular capacity.

# 2025-08-25

Just a quick thought that sputtered out.

-   Measurement should be conclusive; measurement results should have no other valid interpretation regarding what has been measured or observed. However, due to the fact that I can ***validly*** interpret measurement results as reflective of [satisfaction with government]---a conceptually, logically, semantically distinct construct---then the items purported to measure external efficacy are not valid measures of the construct in question.

-   When it comes to measurement, the construct in question must be measured not estimated. This distinction is crucial to understand, even if elementary: measurement implies observation, estimation implies error.

-   This becomes even more critical to understand considering a construct under study is often not an *object* or an *objectified notion* that is tangible in the social sciences or made to be as such. Given that, there's no tenable claim that we are *measuring* the construct but must be referred to as an estimate. 

-   Researchers are likely to be incredibly apprehensive of the idea that responses to a set of survey items measure a supposed construct without error, not because the methodology, but because the construct in question is understood as being inherently unobservable, psychological, or otherwise intangible. The measurement instrument itself may be flawed such that measurement error must always be presumed. However, when it comes to certain methods employed, values are computed rather than estimated. We observe the height of a person as the sum of an individual's vertical unit length in inches, or any other unit length, from bottom to top standing upright.


-   This isn't to suggest that all constructs of interest in the social sciences are "real-but-unobservable" constituents of the world. Rather, some constructs worth studying are often theoretical concepts developed by, and of interest to, researchers and scholars. This kind of connotation of the word "construct" reflects a viewpoint that, "...constructs are theoretical logical-linguistic tools that researchers use to designate and communicate about a specific domain of inquiry." [@slaney2015] 

-   As such, I start with what I want to know. 

-   As a theoretical concept, the construct refers to a theory of what is the case in this or that respect. 

-   In the other category of "construct" refers to, as stated, a "real-but-unobservable" thing or object, or my favorite, an "inferred entity". Bertrand Russell relayed it best in the "supreme maxim" of scientific philosophizing, "Wherever possible, logical constructions are to be substituted for inferred entities."


-   logical consequence is the relationship between the premises and conclusion in a deductive argument. Three essential features define this relationship:
    -   the conclusion is necessary---the premises necessitate the conclusion
    -   the conclusion is formal---that is, the conclusion depends only on the form or syntax of the premises and conclusion.
    -   it is knowable a priori---no empirical knowledge of the world is necessary to determine whether a deduction is valid.
    

Okay okay, back to what I am trying to do here.

-   I'm struggling to devise the model of inquiry here in my approach. The DV is obviously external efficacy, but at the individual level. The independent contextual factor is the cost of voting index value, and the group is either the state or region. So for the given ANES year, external efficacy is a function of COVI by and within the context chosen (states or region). 


# 2025-08-27


-   External political efficacy is usually referred to as an attitude, which to put simply, refers to that which houses one's *considerations* (i.e., all that one considers) about an issue, topic, or subject[^1]. Attitudes are, "...a kind of database consisting of feelings, beliefs, and knowledge about an issue." [@tourangeau2000, 179]. 

[^1]: To allay a longer paragraph, I'll settle here to clarify that "considerations", made most familiar by @zaller1992, are succinctly described by @tourangeau2000 as, "...a haphazard assortment of beliefs, feelings, impressions, general values, and prior judgments about an issue", whereas attitudes are "memory structures that encompass these considerations about an issue [-@tourangeau2000, 179]. 

-   So given that understanding, external efficacy is an attitude about something in particular, and the measurement thereof must sample from an indefinite number of considerations pertaining to that particular something. Construal of the concept, then, hangs on that aforementioned "something". The theory of the concept concerns that which is relevant to that "something" in particular. 

-   Bear in mind, the theory of the concept is prior to construal of the concept as an individual's attitude about something in particular. Otherwise, one is theorizing the existence of some characteristic of an individual and seeks to estimate the quality of that characteristic by measurement of a set of indicators. Or to put more simply, individual judgements are often construed by researchers as a latent attitude, or trait, or sense, or disposition of an individual. In fact, its difficult now to even think about survey measurement without considering the things measured formally as a latent constructs.   

-   when we want to know an individual's attitude about something in particular, i.e., some issue or event, then we ask questions relevant to that something. We construct the notion of an attitude that encompasses the considerations relevant to that something. Theory determines what considerations are relevant, and the survey items developed are meant to have an individual report those relevant considerations, which accumulate to reflect the attitude as theorized. On the other hand, when we want to estimate some characteristic of an individual, we construe it as an underlying or latent something that explains/influences one's tendencies and temperament.     

-   So the concept in question is constructed as an attitude and multiple items are developed with the aim of developing a global measure of the attitude. 

-   Crucial to measurement, then, is a coherent conception of the construct that conveys what the supposed attitude is about; the conceptual definition of the construct serves as the basis for its measurement. It is also vital that the construct in question is conceptually distinguished from other constructs.   


Okay I took a walk.

-   The theory has not been tested; the selected predictors invalidate the model as an appropriate test of the theory.
-   Due to this, the theory still stands: external efficacy is an attitude based on conditions of the political environment as viewed from the perspective of the subject. As such the hypothesis remains untested: supposing adequate construct validity between the measurement and meaning of external efficacy, then shifts to external political conditions should correspond to, or stimulate, shifts in external efficacy. 

-   One aim of this study is to utilize predictors that are unobjectionable as factors of the political environment and apply a different model or method in order to properly test whether the measurement validly corresponds to the given meaning.

-   If the measures of external efficacy actually measure the construct as it is conceived, then we would expect external efficacy to shift upon corresponding shifts to external conditions (i.e., the political environment).

-   Note that this depends on the level in which there are shifts to external conditions and exactly what conditions. For instance, shifts in political conditions at the national level should correspond to systematic shifts in external political efficacy aggregated across the nation. Since the political system is such that political conditions of the states vary within the bounds of national level conditions (i.e., federal law), then differences in state political conditions should correspond to systematic shifts of external efficacy among state constituents when aggregated at the state level. However, the considerations that may arise when prompted with external efficacy items cannot be so readily separated and attempts to do so would be misplaced, especially given the fact that state laws readily impact national level outcomes of politics and government as well as condition the people's endeavors to effectuate change at every level. In other words, we can't expect respondents to confine their considerations to political conditions at the state level. 

-   If external efficacy is not influenced by shifts to external conditions, then there are two plausible conclusions. Either the measure corresponds to the meaning of the construct which would imply that people in general are insensitive to changes to external conditions, or the items are not valid measures of the construct as conceived.

-   We already know that the former conclusion is a *non sequitur*; people are generally sensitive to changes in the political environment, both in attitude and behavior---especially those of which pertain to their capacity to participate and effectuate change through government and politics. Previous research has already demonstrated that changing the rules significantly effects voter turnout, participation, vote choice, and the like [@ang2019].

-   Relatedly, a recent working paper from the National Bureau of Economic Research (NBER) [@dench2025] shows that after the Supreme Court 2022 decision in *Dobbs v Jackson Women's Health Organization*, bans to abortion increased net migration outflows. This bolsters the notion that people are indeed sensitive to changes to external political conditions

-   A broader, and indeed more substantive, aim of this study goes further to reconsider the given conceptual definition of external political efficacy as it stands today. A sufficient amount of past research has implored future studies to do exactly what this study aims to accomplish.   

-   My argument is not merely that @chamberlain2012's model was incorrectly specified due to the chosen predictors, but goes further to assert that the problems with the measurement of external efficacy in terms of its construct validity stem directly from its misconstrual; we are unable to develop valid measures when we have not a coherent theory about what we're trying to measure in the first place.
 
# 2025-09-03

2012 ANES included different versions of efficacy items (standard, revised) in both the pre- and post-election survey. The major difference between the two versions is that the revised items ask the respondent "How much/often..." and response options are on a range from "Not at all" to "A great deal". The standard versions, in contrast, presented the items as statements for which the respondent indicated their agreement or disagreement on a 5-point scale (agree strongly, agree somewhat, neither agree nor disagree, disagree somewhat, disagree strongly). 

The standard format of the items were thought to subject results to acquiescence bias---the tendency for respondents to agree with a statement regardless of what it says. For the external efficacy items in particular (NOSAY and NOCARE), a format that leads respondents to agree would be especially troublesome given that agreement is supposed to indicate a lack of or absence of external political efficacy. As a consequence results overtime may have been biased downward due to the format of the items rather than, say, conditions of the (external) political environment. That being said, it is apparent that later iterations of ANES surveys have employed the standard external efficacy items over the revisions. However, I am unaware of any documented analysis examining whether results from the standard items demonstrate significant response effects in the form of acquiescence bias.

Since later ANES surveys used the standard external efficacy items, then it is best to use the standard items from 2012 for comparison. Especially if there is no significant difference between results from the standard and revised versions of the items. 

Additionally, there is no harm in using only the post-election survey responses for each respondent so long as there is no difference in external efficacy item responses between the pre- and post-election surveys. It will be worthwhile, however, to determine the number of respondents whose responses differ between the pre- and post-election period. Supposing a sufficient number of responses differ between periods, then it will be worthwhile to explore plausible explanations for why responses differ.

Efficacy 2012:
effic_complicstd   PRE: [STD] Politics/govt too complicated to understand
effic_undstd       PRE: [STD] Good understanding of political issues
effic_carestd      PRE: [STD] Publ officials don't care what people think
effic_saystd       PRE: [STD] Have no say about what govt does
effic_complicrev   PRE: [REV] Politics/govt too complicated to understand
effic_undrev       PRE: [REV] Good understanding of political issues
effic_carerev      PRE: [REV] Publ officials don't care what people think
effic_sayrev       PRE: [REV] Have no say about what govt does
efficpo_complicstd POST: [STD] Politics/govt too complicated to understand
efficpo_undstd     POST: [STD] Good understanding of political issues
efficpo_carestd    POST: [STD] Publ officials don't care what people think
efficpo_saystd     POST: [STD] Have no say about what govt does
efficpo_complicrev POST: [REV] Politics/govt too complicatd to understand
efficpo_undrev     POST: [REV] Good understanding of political issues
efficpo_carerev    POST: [REV] Publ officials don't care what peopl think
efficpo_sayrev     POST: [REV] Have no say about what govt does
efficpo_bothside   POST: How often see both disagreeing parties as right

Efficacy 2016:
V162215 POST: [STD] Publ officials don't care what people think
V162216 POST: [STD] Have no say about what govt does
V162217 POST: [REV] Politics/govt too complicated to understand
V162218 POST: [REV] Good understanding of political issues

Efficacy 2020:
V202212 POST: [STD] Public officials don't care what people think
V202213 POST: [STD] Have no say about what goverment does
V202214 POST: [REV] Politics/government too complicated to understand
V202215 POST: [REV] How well does R understand important political issues

Efficacy 2024
V242200 POST: [STD] Public officials don't care what people think
V242201 POST: [STD] Have no say about what government does
V242202 POST: [REV] Politics/government too complicated to understand
V242203 POST: [REV] How well does R understand important political issues
V241726 SPS: Agree/disagree: public officials don't care what people like me think
V241727 SPS: Agree/disagree: people like me don't have a say about what government does

For the 2012 ANES only, I am able to use the internet-only sample in order to make inferences about sub-national geographies (e.g., state, region). In the survey documentation for each ANES, the internet sample is said to have been a random draw of all residential addresses across the states having equal probability of selection. However, in all but the 2012 ANES, both the in-person interviews and internet samples were stratified and clustered. For the 2012, the internet sample was not stratified or clustered, thus the internet sample weights (`weight_web`) are post-stratified using known population characteristics/parameters to produce estimates that match known population proportions for the selected characteristics.

SIDE NOTE: 
post-stratification: The process of allocating the sample to strata after the sample has been drawn.

# 2025-09-04


Okay, since my objective is to test the construct validity of the external efficacy measures, then it should not really matter whether I weigh the survey data to be representative of the population at any geographic level (e.g., national, state, region). The question is whether the measure coheres with the meaning. If they are valid measures of the construct, then they'll still be valid regardless of geographic level. 

However, the problem is that context is inherent to the construct itself; different contexts with different conditions should affect results of measurement considerably so long as the measures are valid. For example, measurement of one's body weight on Earth is still a measurement of body weight when measured on the Moon, but change in the conditions of gravity (among others) between the two contexts definitely affects the body weight shown on the scale. Now, this measurement error can be corrected for so long as the force of gravity in each context is taken into account.


:::{.callout-note}
Not that it matters, but the formula to calculate one's weight on the moon can be written as

$$
Weight_{moon} = (Weight_{Earth}/9.81) * 1.622
$$
The force of gravity is given in meters per square second $(m/s^2)$. The force of gravity on Earth is $9.81 m/s^2$, where's on the Moon, it is approximately $1.62 m/s^2$. Source [Your Weight on the Moon](https://cosmicopia.gsfc.nasa.gov/qa_earth.html#weight).
:::


The other problem clear to every social scientist is that the construct of interest is intangible, or rather, abstract. That is, what is of interest is an abstract idea constructed (hence *construct*) by researchers. Suppose that the instrument meant to measure one's body weight was put into question, and as such, we were uncertain about whether measurement results could be validly interpreted as reflective of one's body weight. If we (somehow) still were able to account for the differences between the Earth and the Moon in terms of gravity, then we might be able to determine whether results from the measurement instrument validly reflects the thing we intended to measure---body weight. Suppose that the measure captures one's height instead of one's body weight; comparing measures between both contexts would quickly tell us that we are definitely not measuring body weight given the fact that one's height would not change nearly as much as one's weight under different conditions. Given the fact that the force of gravity is inherent to the definition of weight---the force of gravity acting on an object of a certain mass---we cannot know one's body weight without taking into account this condition of the given context, of nature. 

To take the analogy even further, weight is defined as the force of gravity acting on an object of certain mass, where mass is that tangible property of the object. Even though the weight of an object weighs less on the Moon than on Earth, the object still has the same mass. The object is *of a certain mass*. In contrast, the abstract construct of interest to researchers of the social sciences is not an object at all, and whatever there is to know about the construct of interest is confined to the coherence of the researcher's theoretical propositions about the construct.

Nevertheless, what is readily assumed is that there is some true value or property for which there is no surefire way of observing, and thus unmeasurable without error. In other words, almost every construct is conceived as some *underlying unobservable* for which direct empirical measurement is unfeasible. As such under a conventional measurement theory such as Classical Test Theory, the measurement of certain constructs of interest are, indeed, not *measurements* at all but rather *estimates* of a presupposed truth. 


# 2025-09-05

> “Construct validation involves three distinct steps. First, the theoretical relationship between the concepts themselves must be specified. Second, the empirical relationship between the measures of the concepts must be examined. Finally, the empirical evidence must be interpreted in terms of how it clarifies the construct validity of the particular measure.” [@carmines1979, 23]

Something missing here (and in the illustrative example on self-esteem) is the step, or steps, prior to making the theoretical proposition regarding what the construct is related to; we need to provide a definition of the concept. We’re *validating the construct itself*, not simply the relations of a construct taken as a given.

Importantly, the concept must not be defined for the sake of affirming the theoretical proposition, i.e., construed *post hoc* said theoretical propositions (i.e., that self-esteem is positively related to participation). The conceptual definition must stand on its own before being relevant to subsequent propositions. Simply put, we must first explicate what we mean when we refer to self-esteem. If self-esteem, **nominalized** as an *it*, an *object*, a *thing*, a *noun*, then we must present a clear and coherent conception of what *it* is on its own terms. Since, in this example, self-esteem and participation are different constructs (one a property of an individual, the other an extent of one’s activity) then self-esteem should be defined without reference to whatever relation or relational effect it may impose, but importantly, it must be defined without regard of whether *it* can be measured.

This is why, as the authors say, the process is, by necessity, theory-laden; without some tangible empirical referent, then the conception of whatever construct is theoretical in the first place.

In the *hard* sciences (e.g., physics) there may be multiple definitions of certain tangible, material objects that are conceptually distinct but still *physically equivalent*. In contrast, for most constructs of the social sciences there is no physical referent from which to base our definitions and as such the thing that we’re talking about is liable to change upon even subtle changes to the conceptual definition. Thus, since the concept of interest is inherently abstract, and thus immaterial, *construal of the concept must be validated* if it is to be accepted.


> "It should be clear that the process of construct validation is, by necessity, theory-laden. Indeed, strictly speaking, it is impossible to “validate” a measure of a concept in this sense unless there exists a theoretical network that surrounds the concept. For without this network, it is impossible to generate theoretical predictions which, in turn, lead directly to empirical tests involving measures of the concept...What is required is that one be able to state several theoretically derived hypotheses involving the particular concept." [@carmines1979, 23-24]


> "The more elaborate the theoretical framework, of course, the more rigorous and demanding the evaluation of the construct validity of the empirical measure. Notice that in the self-esteem example discussed above, we concluded that the positive association between Rosenberg’s self-esteem scale and participation in school activities provided one piece of evidence supporting the construct validity of this measure. Greater confidence in the construct validity of this measure of self-esteem would be justified if subsequent analyses revealed numerous successful predictions involving diverse, theoretically related variables. Thus, construct validity is not established by confirming a single prediction on different occasions or confirming many predictions in a single study. Instead, construct validation ideally requires a pattern of consistent findings involving different researchers using different theoretical structures across a number of different studies." [@carmines1979, 24]

I think this is okay but could, again, be better said if they emphasized that the aim is to test the assumption of the concept as construed. The essential step of theoretical conception, so to speak, is still skipped over.

The authors suggest that the construct validity of a particular measure cannot really be accepted until a pattern of consistency is shown across multiple studies for which the measure is employed. The problem with this is that many studies will often only include a construct due to its relevance to the particular theory or research objective. Quite often, a relevant construct is included but the construct validity of is measurement is not of interest. Such studies are not always intended to test the construct validity of a measure, as that would be its own research objective. For certain constructs, construct validity is presumed. This is especially prevalent for long standing familiar constructs of which common means of measurement have become an implicit standard. Researchers will make reference to confirmatory literature under the presumption that construct validity of measurement has been well established. Even more so when large annual surveys include a particular set of measures, which then become the standard form of measurement for a particular construct. Depending on how long a certain measure has been included in annual surveys, continuity of measurement becomes a concern. 

As such, it becomes paramount to take into account whether studies that include a particular construct of interest are intended to test the construct validity of its measurement, or whether the construct was merely peripheral to the research objective. Note, however, that a measure for which construct validity is accepted may not then engender subsequent research interest into testing its construct validity. Thus the pattern of consistent findings from a rich body of literature would be lacking. If it ain't broke, don't fix it. On the one hand, a large and extensive body of literature would not consist of mere replication serving to regularly reaffirm the construct validity of a particular measure. On the other hand, an extant body of literature concerned with a certain construct and its measurement may itself indicate that measurement is, at the very least, insecure.

Note also that the authors seem to imply that a single study which may invalidate measurement of a construct is not enough in the face of a pattern of consistent findings from different researchers and methods that appear to confirm construct validity of a particular measure. This, to me, seems incorrect; one study should be enough to falsify a falsifiable theory. And since many of the concepts of the social sciences are fundamentally theoretical, then every such construct is always liable to falsification and evidence against the construct validity of measurement should be taken as such.

Evidence that seemingly contradicts construct validity of some measure should invite subsequent inquiry. Although this does occur, the aforementioned hesitancy to do away with long standing measures for the sake of continuity sets a high bar for contrary evidence to surpass. Continuity for its own sake implicitly functions as the criteria necessary for evidence against construct validity of a certain form of measurement. Contrary evidence may be relegated to the periphery, but what is seemingly more likely is that researchers will go on to develop entirely novel constructs rather than assess the validity of what is already established or long standing. Or, alternatively, research will aim to improve measurement of a particular construct without doing away with what has already become standard, and importantly, *without aiming to challenge the given conception of the construct*.

What I haven't mentioned yet, however, is that there is no standard or clear method to test the construct validity of measurement. What counts as evidence against construct validity isn't uniform but depends primarily on the quality and coherence of the theory thereof. As Cronbach as said, "One validates, not a test, but an interpretation of data arising from a specified procedure"

Moreover, falsifying evidence must be conclusive---that is, the evidence must necessitate the conclusion. Now, we may not have complete confidence in the evidence itself, which would challenge the evidence as a premise to the conclusion. In other words, if it is not the case that the resulting evidence invalidates construct validity of measurement, then it would not follow that the theory of the concept as a given would also be false.


@carmines1979 state that there are at least four interpretations possible when evidence challenges *construct validity*. The first, "...most typical interpretation of such negative evidence is that the measure lacks construct validity. Within this interpretation, it is concluded that the indicator does not measure what it purports to measure." [-@carmines1979, 24]. 

> "This does not mean, of course, that the indicator does not measure some other theoretical construct, but only that it does not measure the construct of interest. In other words, as negative evidence accumulates, the inference is usually drawn that the measure lacks construct validity as a measure of a particular theoretical concept." [@carmines1979, 24]

The authors then suggest that the remaining three interpretations are also valid alternative conclusions that can arise when evidence against construct validity arises. They equivocate all interpretations presented, when in actuality, the remaining three are valid counter arguments against the first.

The first *alternative* interpretation the authors state is that, "...the theoretical framework used to generate the empirical predictions is incorrect." [-@carmines1979, 25] which has to do with whether the theory of some research inquiry coherently leads us to the interpretation challenging construct validity of the given measure.

> "To continue with the earlier example, it may be the case that, from a theoretical perspective, self-esteem should not be positively related to participation in school activities. Therefore, a nonpositive relationship between these variables would not undermine the construct validity of Rosenberg’s self-esteem scale but rather cast doubt on the underlying theoretical perspective." [@carmines1979, 25]

The theory must suggest that this or that relationship would undermine construct validity in order for results to be interpreted as such. The idea is that challenges against construct validity of the given measure would be misplaced if the theoretical framework is insufficient, incorrect, or lacking in the first place. The logic of our theory must reasonably lead to an interpretation challenging the construct validity of the measure with respect to the kind of relationship we'd expect between the construct of interest and some other variable construct. That is to say, the theory must coherently imply the interpretation that the given measurement instrument does not measure the construct it is purported to measure.

This doesn't suggest that this interpretation of results must be conclusive, that is, necessitated. However it does suggest that this kind of interpretation against construct validity must be warranted in theory and, if not conclusive, must compete against other reasonable interpretations. This makes sense given that such inferences drawn from fallible evidence are inductive rather than deductive[^1]. To put more simply, the evidence might simply suggest that the theory is wrong but the measures are fine in terms of construct validity.

This, of course, is an argument made by researchers open to contestation. An argument challenging the theoretical framework used to generate empirical predictions is difficult to make, especially if results are interpreted in such a way as to bolster the theory in question. Frankly put, an argument alone, no matter how reasonable, is likely not enough to sway consensus or even engender doubt against such an interpretation. Especially for fields of study that seem to increasingly shy away from qualitative approaches in favor of the quantitative, computational methodologies. The consequence, however, is the proliferation of weak or even incoherent theories overlooked in the face of compelling data and results. Despite the difficulty, such challenges must be made if only for the sake of progress and strength of the science involved.   

As it concerns the construct validity of the external efficacy measures, the theoretical frameworks used to engender a multitude of empirical predictions are not necessarily incorrect due to the fact that such theories are usually based on the somewhat standard conceptual definition and understanding established in the literature. However, my contention is that the very definition of the concept is incoherent.


The third stated interpretation of evidence against construct validation is that "...the method or procedure used to test the theoretically derived hypotheses is faulty or inappropriate." The authors state, 

> "Perhaps it is the case that, theoretically, self-esteem should be positively associated with participation in school activities and that the researcher has used a reliable and valid measure of self-esteem. However, even under these circumstances, the hypothesis will still not be confirmed unless it is tested properly. Thus, to take a simple example, the negative evidence could be due to the use of an inappropriate statistical technique or using the proper technique incorrectly." [@carmines1979, 25]

However, this interpretation doesn't appear to concern construct validation of the measure *per se*. Indeed, the authors even suppose that in this situation the measure of self-esteem is both reliable and valid---which would include construct validity. In short, this interpretation of negative evidence simply says that the issue is not the construct validity of the measure but rather the incorrect or improper use of method. We'd expect such cases to be apprehended within the peer review process. Ultimately this point doesn't pertain to construct validity in particular as any interpretation of the data arising from the given procedure would be invalid if the methods were inappropriate or improperly applied. 


The final interpretation simply extends argument of construct validity to another variable construct of a given model or analysis. The authors state that negative evidence, "...is due to the lack of construct validity or the unreliability of some other variable(s) in the analysis."

> "In a very real sense, whenever one assesses the construct validity of the measure of interest, one is also evaluating simultaneously the construct validity of measures of the other theoretical concepts. In the self-esteem example, it could be the case that Rosenberg’s self-esteem scale has perfect construct validity but that the measure of “participation in school activities” is quite invalid or unreliable." [@carmines1979, 25]

Surely this is just one potential argument against the idea that measurement of the construct of interest is invalid out of an indefinite number of arguments that can be made. However all that is stated is that a counter argument would simply shift the issue to another variable construct. This surely can happen, but it would be dismissive of any claims against the construct validity of the measures regarding the first construct. 

The three alternative interpretations presented by @carmines1979 are merely arguments against the first argument---that the measured indicators do not measure the construct they are purported to measure. Note that evidence that would be considered negative evidence against construct validation of some measure is not described. Rather, the authors state only what is required to establish construct validity, and that is pretty vaguely put as "a pattern of consistent findings" [-@carmines1979, 24].

The bottom line point I am trying to get at is that the authors leave out that evidence against construct validity doesn't only invalidate the measure as simply erroneous, but also serves to challenge the theory of the concept itself. As Cronbach said, we validate (or invalidate) "an interpretation of the data arising from a specified procedure" [@cronbach1971, 447]. However, unless we're conducting an exploratory analysis of the data, we first posit a particular interpretation of the data *prior* to its collection. As such, we're not dependent on the data for the interpretation if the reason we collected the data in the first place posited a particular interpretation *a priori*. Cronbach is right to say that we validate an interpretation of data arising from a specified procedure.

> "A single instrument is used in many different ways---Smith's reading test may be used to screen applicants for professional training, to plan remedial instruction in reading, to measure the effectiveness of an instructional program, etc. Since each application is based on a different interpretation, the evidence that justifies one application may have little relevance to the next. Because every interpretation has its own degree of validity, one can never reach the simple conclusion that a particular test "is valid."" [@cronbach1971, 447]

To put another way, the measurement instrument takes aim at a target theorized to be somewhere down range. The measurement instrument isn't firing small little bullets, but rather fires a net towards where we suppose the target is present. Crucial to this analogy is that we do not know for sure what the target looks like, so *identification* of the target is done by first clarifying *a priori* what we are aiming for in theory (and by clarifying what we are not aiming for). Accordingly, even the measurement instrument, the net, is designed in such a way to best capture the target of interest identified in theory, which is to say that the net takes the shape of the target itself. The net is meant to capture the target but incidentally will also capture many other things that are not the target, even things that may share similarities to the target. After shots are fired, we sift through everything captured in the net. If nothing within the captured data fits the target description *in accordance to the concept identified in theory*, then we have no evidence that the target as described is even really out there.

Now there's a whole lot of things that could plausibly explain why our net came up empty. Perhaps the net is the wrong size or shape. Or the idea of using a net to somehow capture (measure) the target of interest is incorrect. Yet we designed the net based on the theory of the target; how do we know whether the instrument is invalid or whether the theory is wrong? 

Subsequent tests may be developed continuously until a measurement instrument satisfies construct validity based on a given conception of the construct, but only on the basis that the concept identified in theory is accepted as legitimate and relevant. That is, the reasoning and considerations that formulates the concept as whatever it is formulated to be must be accepted as valid. If, after continued attempts, we cannot interpret the resulting data as reflective, representative, or indicative of the concept identified in theory, then we must question the identity of the concept itself.

Now evidence against construct validity does not invalidate the idea of the concept outright, but instead shifts discussion from construct validity of a measurement instrument to the very identity of the concept itself, which is a very different, basal, kind of validity. 

Nicely stated by @williams2003, "Validity, as a logical concept, refers to relationships within arguments and is not a measure of the truth about the world that the premises or conclusion of the argument claim." 

The theory must properly identify the concept of interest, providing a foundational conceptual definition. We have no fundamental reference for the thing at base, so we first identify the concept in theory. If we fail to validate measurement of the construct, then all that is left holding the idea together as a viable concept is the theory behind it. That is, the theoretical propositions formulating or identifying the concept are the last line of defense before we must do away with the concept as conceived.

All that is to say, the theory of the concept can be understood as an assertion, the propositions of which serve as an argument to identify a concept. 



[^1]: Not to insult anyone's intelligence, but to make clear the position of my own understanding. Induction is reasoning from the particular to the general, which may be otherwise considered as reasoning based on the available evidence, such as observations from a sample. An inference by inductive reasoning doesn't always have to be correct or true, as such inductive logic allows for the possibility of an inference being false or invalid. Deductive reasoning follows from general premises to particular conclusions. The structure of facts are more important than the facts themselves, such that for deduction the premises **must** always lead to the conclusion. This is the defining criterion for **deduction**. More formally, perhaps, deductive reasoning is inference in which the conclusion about particulars follow *necessarily* from general or universal premises. A**deductive**argument uses a collection of general statements as its premises and uses them to propose a specific situation as the conclusion. As I understand it, a theory is essentially a deductive argument.

-   deductive reasoning follows from general premises to particular conclusions;
-   inductive reasoning follows from particular premises or instances to general conclusions;
-   abductive reasoning follows from a syllogism in which the major premise is evident but the minor premise, and therefore conclusion, is only probable.




> "A valid measure is one which measures what it is intended to measure. In fact, it is not the measure that is valid or invalid but the use to which the measure is put. We might use educational level to measure social status. The issue is not whether we have measured education properly but whether this is a suitable measure of social status. The validity of a measure then depends on how we have defined the concept it is designed to measure." [@devaus2002, 53]

> "Since each experiment checking upon a theory is an opportunity to modify or extend the theory,  validation is more than corroboration; it is a process for developing sounder interpretations of observations." [@cronbach1971, 443]


# 2025-09-08

The methods for evaluating construct validity of a particular measure are reliant on relations with other variables or constructs. 


> "Theoretically relevant and well-measured external variables are thus crucial to the assessment of the construct validity of empirical measurements (Curtis and Jackson, 1962; Sullivan, 1971, 1974; Balch, 1974). The logic of construct validation usually implies that the relationship among multiple indicators designed to represent a given theoretical concept and theoretically relevant external variables should be similar in terms of direction, strength, and consistency."


The notion of construct validity is, ultimately, theory dependent. 

My aims in this project are deceptively simple: 

-   attempt to replicate results from @chamberlain2012 incorporating data up to the most recent ANES survey (2024)
-   conduct a better test of the theory proposed by Chamberlain using more appropriate predictors reflective of the (external) political environment.

-   Since external political efficacy is, roughly speaking, an attitude based on considerations of the (external) political environment, then changes to that environment should influence shifts of external efficacy among all of the same political status.

-   the changes to the environment are with respect to contextual factors that condition the individual or public capacity to effectuate change through the political process.

-   One such change occurred after the 2013 Supreme Court ruling in *Shelby v Holder*. The coverage formula of the Voting Rights Act used to determine which states and jurisdictions would be subject to preclearance was ruled to be unconstitutional. Since that ruling, election, voting, and registration laws around the United States have changed dramatically. 

I initially thought that a difference-in-differences model would suffice. However, a DID model requires treatment units and control units, which in this case would be states. The problem is that the Supreme Court ruling applies to all states, which means that there are no states where the ruling would not apply. This would be different if the decision only applied to certain states---then it could be evaluated as though it were simply a new policy adopted by some states and not others. However, the ruling applied to all states and jurisdictions in that it frees them from enacting restrictive election laws. Since 2013, almost every state has passed some law that qualifies.

Arguably, some states enacted more restrictive laws compared to others that enacted more expansive laws in the same domain. I could simply categorize the states according to their rank on the Cost of Voting index (COVI), but one problem with that is a state's rank is relative to other states. This means that for any given year where COVI is computed, a state may have risen or fallen in rank without ever having enacted a new law in the relevant domain. The rank also doesn't really tell me the score for the state, which is what is actually relevant. 

So the context for each individual with respect to voting is the state given that states govern how elections are run within their respective jurisdiction and within the bounds of federal law with respect to the U.S. Constitution.


-   The theory has not been tested; the selected predictors invalidate the model as an appropriate test of the theory.
-   Due to this, the theory still stands: external efficacy is an attitude based on conditions of the political environment as viewed from the perspective of the subject. Supposing adequate construct validity between the measurement and meaning of external efficacy, then shifts to external political conditions should correspond to, or stimulate, shifts in external efficacy. 

-   One aim of this study is to utilize predictors that are unobjectionable as factors of the political environment and apply a different model or method in order to properly test whether the measurement validly corresponds to the given meaning.

-   If the measures of external efficacy actually measure the construct as it is conceived, then we would expect external efficacy to shift upon corresponding shifts to external conditions (i.e., the political environment).

-   Note that this depends on the level in which there are shifts to external conditions and exactly what conditions. For instance, shifts in political conditions at the national level should correspond to systematic shifts in external political efficacy aggregated across the nation. Since the political system is such that political conditions of the states vary within the bounds of national level conditions (i.e., federal law), then differences in state political conditions should correspond to systematic shifts of external efficacy among state constituents when aggregated at the state level. However, the considerations that may arise when prompted with external efficacy items cannot be so readily separated and attempts to do so would be misplaced, especially given the fact that state laws readily impact national level outcomes of politics and government as well as condition the people's endeavors to effectuate change at every level. In other words, we can't expect respondents to confine their considerations to political conditions at the state level. 

-   If external efficacy is not influenced by shifts to external conditions, then there are two plausible conclusions. Either the measure corresponds to the meaning of the construct which would imply that people in general are insensitive to changes to external conditions, or the items are not valid measures of the construct as conceived.

-   We already know that the former conclusion is a *non sequitur*; people are generally sensitive to changes in the political environment, both in attitude and behavior---especially those of which pertain to their capacity to participate and effectuate change through government and politics. Previous research has already demonstrated that changing the rules significantly effects voter turnout, participation, vote choice, and the like [@ang2019].

-   Relatedly, a recent working paper from the National Bureau of Economic Research (NBER) [@dench2025] shows that after the Supreme Court 2022 decision in *Dobbs v Jackson Women's Health Organization*, bans to abortion increased net migration outflows. This bolsters the notion that people are indeed sensitive to changes to external political conditions

-   Suffice to say that people are indeed sensitive to political conditions

-   My argument is not merely that @chamberlain2012's model was incorrectly specified due to the chosen predictors, but goes further to assert that the problems with the measurement of external efficacy stems directly from its misconstrual; we are unable to develop valid measures when we have not a coherent idea about what we're trying to measure in the first place.

# 2025-09-09


The (external) political environment (i.e., context) is emphasized with regard to the construal of external political efficacy, and it is also regarded as vital to consider when formulating theoretical expectations or evaluating validity of measurement. However, despite the reasonable emphasis in theory, the factors chosen are far from being considered reflections of the political environment or conditions thereof. 

Similar to prior research [@coleman1976], Chamberlain confuses approval of government as an appraisal of the efficacy of political activity.


changing topics....


-   It's not exactly clear what behavior we would expect from low or high external efficacy regardless of whether that's at the individual-level or in the aggregate. In the literature, low external efficacy was associated with greater engagement but only upon interaction with high internal efficacy (that is, if I recall correctly). In one of the earlier papers that strongly contributed to the internal and external split, @balch1974 evaluated the inter-item correlations between 'sense of political efficacy' and political participation (denoted as 'conventional' in the original text) and the "propensity to engage in protest behavior". Yet in explaining inclusion of the latter in the analysis, Balch is transparent that no clear expectation follows from the given understanding of political efficacy,

> "One can argue plausibly for any of the following: the more efficacious are (1) more likely, (2) less likely, or (3) neither more nor less likely than the inefficacious to engage in political protest behavior. For instance, protesting is another kind of political participation, and, since the more efficacious participate more, they should also be more prone to protest when the occasion arises. Alternatively, a person who feels politically efficacious may feel that it is unneces sary or illegitimate to engage in protest. Or, the relation ship may be so complicated by additional variables (such as the specific kind of protest act, the situation at hand, the legitimacy of the system, etc. ) that no bivariate relationship can be expected between efficacy and protest." [@balch1974, 17]



-   The methods commonly used for evaluating the measurement validity (construct validity) is common factor analysis. The idea is that certain responses are influenced by a common underlying (latent) factor. Observation of these responses to survey items are observed indicators of the underlying factor.
-   Other methods phrase their analysis differently, stating that particular "external" variables are *determinants* of the construct in question. In that sense, the attempt to is identify the *determinants* of external efficacy by proposing a few or by exploration. 

-   Other methods have simply used "external" variables to help distinguish and validate interpretation of the data as indicative of the construct in question. External efficacy served just that role for the validation of internal efficacy, but couldn't be sufficiently validated itself. Accordingly, such methods examine the inter-item correlations between items that supposedly measure different constructs. 



-   

> "Usually, true scores are conceived of as hypothetical, unobservable quantities that cannot be directly measured. Rather, a person’s true score is the average score that would be obtained if the person were remeasured an infinite number of times on that variable." [@carmines1979, 29]

> "In formal terms, this “average score” is referred to as the expected value (or mean) if someone were remeasured an infinite number of times on that variable."

> "No single measurement would pinpoint the true score exactly but the average of an infinite number of repeated measurements would be equal to the true score. But since it is impossible to ever obtain an infinite number of repeated measurements but only a finite number, true scores are hypothetical, not real, qualities." [@carmines1979, 30]


The other thing, not mentioned here or really elsewhere I think, is that the actual meaning of the concepts shift just as the meaning of words change over time in ordinary language. Even if scholars and researchers painstakingly define the concept, they are not insulated from incorporating accrued (semantic) meaning of a concept through its use in ordinary language. Given that the ‘true’ concept is merely a construction of scholars and scientists aiming to describe, explain, and predict reality, the very construal of the concept in question is liable to change with every variation of its conceptual definition. Unlike other sciences in which multiple competing definitions for some object (e.g., mass) are *physically equivalent*, different definitions of some abstract concept construed in the social sciences literally change the ‘true’ construal of the thing we aim to measure. Although it is well understood that there is no 'true' underlying referent for which definitions are equivalent *beyond what we must assume for the sake of measurement*, the definition meant to convey our conceptual understanding of the construct in question is taken for granted. 

There is a distinct difference between proposing a theory that something exists but is unobservable, and proposing a name for something we've constructed as both necessary and relevant to our understanding. In the former case, evidence is gathered and tests are conducted in order to validate an interpretation that supports the theory of the proposed unobservable something. In the latter case, a name may be given to a particular pattern revealed and found to be relevant, or to an encompassing idea regarding a certain domain. 


# 2025-09-18 and 2025-09-19

I aim to create an external political efficacy index that remains bipolar and symmetric. Negative values reflect less external efficacy (or rather, the contrasting opposing attitude), positive values reflect positive external efficacy, and the middling zero point reflects an insecure neutral position. This corresponds to the symmetrical response option format of the two external efficacy items in which respondents select one of five options to express the extent to which they agree, disagree, or whether they neither agree nor disagree with the given item statement. This differs from the way the American National Election Studies (ANES) codes the two external efficacy items in order to create the external political efficacy index. 


First, I recode the two items so that each ranges from -1 to 1. Specifically, "Agree strongly" = -1, "Agree somewhat" = -0.5, "Neither agree nor disagree" = 0, "Disagree somewhat" = 0.5, "Disagree strongly" = 1.

```{r}

anes2024 <- anes2024 |>
  dplyr::mutate(dplyr::across(c(nocare, nosay), ~dplyr::case_when(
    .x == 1 ~ -1,
    .x == 2 ~ -0.5,
    .x == 3 ~ 0,
    .x == 4 ~ 0.5,
    .x == 5 ~ 1,
    TRUE ~ NA), .names = "{col}.recode")) |>
  dplyr::mutate(
    dplyr::across(
      c(nocare.recode, nosay.recode), 
      ~labelled::add_value_labels(., c("Agree strongly" = -1,
                                       "Agree somewhat" = -0.5,
                                       "Neither agree nor disagree" = 0,
                                       "Disagree somewhat" = 0.5,
                                       "Disagree strongly" = 1))))



```


Second, I create an external efficacy variable per respondent which is composed of the combination of responses to both external efficacy item responses. The responses are combined and summed to reflect a raw value/score of external efficacy that ranges on a 9-point scale from -1 to 1.

```{r}

anes2024 <- anes2024 |> 
  dplyr::rowwise() |> 
  # mean of sum = sum(x1, x2)/valid_n
  dplyr::mutate(exteff.indx = mean(c(nocare.recode, nosay.recode), na.rm = T)) |> 
  # dplyr::mutate(exteff.indx = sum(dplyr::c_across(nocare.recode:nosay.recode), na.rm = T)) |>
  dplyr::mutate(exteff.indx = dplyr::case_when(
    is.na(nocare) & is.na(nosay) ~ NA,
    .default = exteff.indx
  )) |> 
  dplyr::ungroup() |> 
  labelled::set_variable_labels(
    nocare.recode = attr(anes2024$nocare, "label"),
    nosay.recode = attr(anes2024$nosay, "label"),
    exteff.indx = "External political efficacy, bipolar scale"
  )


```


View the recoded values and the constructed `exteff.bi` index variable 

```{r}

anes2024 |> 
  dplyr::select(nocare.recode, nosay.recode, exteff.indx) |>
  # tidyr::drop_na() |> 
  dplyr::group_by(nocare.recode, nosay.recode, exteff.indx) |>
  dplyr::distinct(exteff.indx) |>
  dplyr::arrange(exteff.indx) |> 
  print(n = Inf)

```

:::{.callout-note}
Note that the `exteff.indx` variable is computed by taking the mean of the sum of the recoded `NOSAY` and `NOCARE` variables for each respondent; the variable value equals the sum of the items divided by the number of responses. That is, an individual's raw level of external efficacy is computed by taking the mean of their responses to the two component items. For instance, a respondent who expressed that they "Agree somewhat" ($-0.5$) to one item, but selected "Neither agree nor disagree" ($0$) to the other would have and external efficacy level of $-0.25$ (i.e., $\frac{(-0.5 + 0)}{2} = -0.25$). This seems to be the method employed by the ANES in computing the external efficacy index variable in the ANES CDF. The benefit of this method is that it places the resulting index value back on the same scale as the two recoded items, between $-1$ and $1$. 

An alternative method is to simply take the sum of both items for each respondent, which results in a variable range from $[-2, 2]$. The data doesn't change, and the values of the computed variable are more informative in regard to what responses an individual gave for each item. For instance, an individual who responded "Agree somewhat" ($-0.5$) to one item and "Agree strongly" ($-1$) to the other would result in an external efficacy index score of $-1.5$, thus giving us the ability to understand how a respondent answered to the component items just from their score on the external efficacy index. However, the average of this variable index for the whole representative sample would be placed on the same scale ranging from $[-2, 2]$, which would be slightly confusing to those who aren't aware of the range of the index.

Essentially, the difference is that following the first method, the range of the index is $[-1, 1]$. Following the second method, the range of the index is $[-2, 2]$. The difference is mostly arbitrary and the choice comes down to how one decides to present the information. For the sake of ease of presentation, I employ the first method.
:::


Finally, the average value of the index is computed to reflect the average extent of external political efficacy at the national level.


```{r}

# extract the national average external efficacy index value
exteff_index_2024 <- anes2024 |> 
  dplyr::select(nocare.recode, nosay.recode, exteff.bi) |>
  tidyr::drop_na() |> 
  dplyr::summarise(
    exteff = mean(exteff.bi), # method 1: mean(sum(item1 + item2)/number of items)
    sum_of_means = sum(mean(nocare.recode), mean(nosay.recode)) # method 2: sum of means
  ) |> 
  dplyr::pull(exteff)

# round
exteff_index_2024 <- round(exteff_index_2024, digits = 3)


```

The national average of the external efficacy index in 2024, following the aforementioned coding scheme, is $-0.37$ derived from an index ranging from $-1$ to $1$.

I also create an external efficacy index following the coding scheme of the American National Election Studies (ANES) Cumulative Data File. The way the external efficacy items (e.g., `NOCARE`, `NOSAY`) are coded by the ANES CDF differs to allow the external efficacy index to range on a unipolar scale from 0 to 100, where the middling value of 50 reflects the neutral point. The two component items are first collapsed from a 5-point response scale to a 3-point scale corresponding to a simpler "Agree", "Disagree", or "Neither" format. Specifically, the responses to each item are collapsed such that "Agree strongly" and "Agree somewhat" responses equal 1, "Disagree strongly" and "Disagree somewhat" equal 2, and "neither agree nor disagree" equal 3. The next step is that both items are recoded such that a code of $1 = 0$, $2 = 100$, and $3 = 50$. 

Although each external efficacy item is recoded to have only three values (e.g., 0, 50, 100), it is inevitable that each item includes non-response or missing data usually coded as `NA`. After that, an external efficacy index variable is computed and reflects the joint value of the two component items; that is, each potential combination of item responses corresponds to a particular value on the external efficacy variable. Given that each item has four potential values (i.e., $NOSAY \in \{`NA`, 0, 50, 100\}$), then there are 16 combinations reflecting their joint values (i.e., $4^{2} = 16$).  

The national average of the external efficacy index is then computed the same way: the sum of the component items are divided by the number of valid responses. The result is then rounded.

```{r}
# create recoded variables of NOCARE and NOSAY following ANES CDF coding
# scheme

anes2024 <- anes2024 |>
  dplyr::mutate(dplyr::across(
    c(nocare, nosay),
    ~ dplyr::case_when(.x %in% c(1, 2) ~ 0, .x == 3 ~ 50, .x %in% c(4, 5) ~ 100, TRUE ~ NA),
    .names = "{col}.cdf"
  )) |>
  dplyr::mutate(dplyr::across(c(nocare.cdf, nosay.cdf), ~ labelled::add_value_labels(
    ., c(
      "Agree" = 0,
      "Neither agree nor disagree" = 50,
      "Disagree" = 100
    )
  )))
```


```{r}

# create unipolar external efficacy index variable
anes2024 <- anes2024 |> 
  dplyr::rowwise() |> 
  dplyr::mutate(exteff.cdf = mean(c(nocare.cdf, nosay.cdf), na.rm = T)) |>
  # dplyr::mutate(exteff.cdf = sum(dplyr::c_across(nocare.cdf:nosay.cdf), na.rm = T)) |> 
  dplyr::mutate(exteff.cdf = dplyr::case_when(
    is.na(nocare) & is.na(nosay) ~ NA,
    .default = exteff.cdf
  )) |> 
  dplyr::ungroup() |>  
  # add variable label to each variable
  labelled::set_variable_labels(
    nocare.cdf = paste(attr(anes2024$nocare, "label"), "coded same as ANES CDF", sep = ", "),
    nosay.cdf = paste(attr(anes2024$nosay, "label"), "coded same as ANES CDF", sep = ", "),
    exteff.cdf = "External political efficacy index, unipolar scale"
  )


```


View the external efficacy index following the ANES CDF coding scheme.

```{r}
# view in console
anes2024 |> 
  dplyr::select(nocare.cdf, nosay.cdf, exteff.cdf) |>
  # tidyr::drop_na() |> 
  dplyr::group_by(nocare.cdf, nosay.cdf, exteff.cdf) |>
  dplyr::distinct(exteff.cdf) |>
  dplyr::arrange(exteff.cdf) |> 
  print(n = Inf)
```


```{r}


# now see if external efficacy index values are the same or similar given the
# different coding
anes2024 |>
  dplyr::select(dplyr::contains("nocare"), 
                dplyr::contains("nosay"),
                dplyr::contains("exteff")
                ) |>  
  tidyr::drop_na() |>
  dplyr::summarise(
    n_valid = dplyr::n(),
    exteff.cdf_mean = mean(exteff.cdf),
    exteff.indx_mean = mean(exteff.indx),
    mean_of_sum.cdf = mean(sum(nocare.cdf, nosay.cdf))/dplyr::n(), # mean of sum = sum(x1, x2)/k
    sum_of_means.cdf = sum(mean(nocare.cdf), mean(nosay.cdf)),
    mean_of_sum = mean(sum(nocare.recode, nosay.recode))/dplyr::n(), 
    sum_of_means = sum(mean(nocare.recode), mean(nosay.recode))
      )



```



Although the index itself is still an average value, the external efficacy variable within the ANES Cumulative Data File reflects each individual's external efficacy at a particular interval along a **discrete** range of values. The external efficacy variable in the ANES CDF is not necessarily an interval variable but a ordinal categorical variable where each value reflects an ordinal category that ranks higher than the category preceding. As such, the external efficacy index computed as an average on a unipolar scale is misleading. Given that the values on the index $ \leq .50$ represent either the lack of or the opposite of external political efficacy, then any average index value $ \leq .50$ can only be interpreted as such. However, when presented as the national average level of external political efficacy, all average values of the index are necessarily $ > 0$ which implies that any positive value reflects a positive extent of external political efficacy among the population.


```{r}

# The bottom line is this: the coding scheme of the index takes "neither agree
# nor disagree" responses as positive evidence of external efficacy despite
# respondents making no such expression.

# create a small dataframe (tribble) that represents the potential values of the
# external efficacy index
coding_scheme <- tibble::tribble(
   ~NOSAY,          ~NOCARE,          ~'NOSAY + NOCARE',                    ~EEINDEX, ~INTERPRETATION,
  'NA',             'NA',             'NA AND NA',                          NA,"Missing values removed",
  'NA',             '[0] Agree',      'NA AND [0] Agree',                    0,"Not Efficacious at all",
  'NA',             '[50] Neither',   'NA AND [50] Neither',                50,"Moderately Efficacious",
  'NA',             '[100] Disagree', 'NA AND [100] Disagree',             100,"Fully Efficacious",
  '[0] Agree',      'NA',             'NA AND [0] Agree',                    0,"Not Efficacious at all",
  '[0] Agree',      '[0] Agree',      '[0] Agree AND [0] Agree',             0,"Not Efficacious at all",
  '[0] Agree',      '[50] Neither',   '[0] Agree AND [50] Neither',         25,"A little Efficacious",
  '[0] Agree',      '[100] Disagree', '[0] Agree AND [100] Disagree',       50,"Moderately Efficacious",
  '[100] Disagree', 'NA',             '[100] Disagree AND NA',             100,"Fully Efficacious",
  '[100] Disagree', '[0] Agree',      '[100] Disagree AND [0] Agree',       50,"Moderately Efficacious",
  '[100] Disagree', '[50] Neither',   '[100] Disagree AND [50] Neither',    75,"Very Efficacious",
  '[100] Disagree', '[100] Disagree', '[100] Disagree AND [100] Disagree', 100,"Fully Efficacious",
  '[50] Neither',   'NA',             '[50] Neither AND NA',                50,"Moderately Efficacious",
  '[50] Neither',   '[0] Agree',      '[50] Neither AND [0] Agree',         25,"A little Efficacious",
  '[50] Neither',   '[100] Disagree', '[50] Neither AND [100] Disagree',    75,"Very Efficacious",
  '[50] Neither',   '[50] Neither',   '[50] Neither AND [50] Neither',      50,"Moderately Efficacious",
) 

coding_scheme <- coding_scheme |> 
  dplyr::arrange(EEINDEX) |> 
  dplyr::mutate(Combination = seq_len(length.out = nrow(coding_scheme)), .before = NOSAY)



# print a grid style markdown table of the coding scheme and potential values
pander::pandoc.table(coding_scheme, style = "grid", justify = "cllcrl",
                     split.tables = Inf)




```



The alternative way to compute the external efficacy index without creating a new variable is to get the the sum of the means for both items. 

Recall: the sum of the means is the mean of the sum, and likewise, the mean of the sum is the sum of the means. Bear in mind, however, that this mnemonic only works when the number of elements are equal for each vector or list, i.e., when the means are drawn from an index with the same number of elements. This means that any missing values must be omitted prior to deriving the means for each item.

However, given that the number of missing values (`NA`) differ across each variable of interest, the number of valid responses is not equal across items. In the 2024 ANES sample, the `NOCARE` item has 36 missing values, whereas the `NOSAY` item has 32. There are $40$ cases (respondents) who gave a valid response to one item but not the other for whatever reason. There are $28$ rows where there isn't a response coded for `NOSAY` and `NOCARE`.

Surely if I drop all rows that contain a missing value for either item, this will leave me with no missing values for either item and their combination. In other words, an individual case (a row) will be dropped when there is a missing value for either `NOSAY` or `NOCARE` and in cases where responses for both items are missing. This is problematic as it discounts partial response data. It makes sense to exclude cases in which there is no response data for both `NOSAY` and `NOCARE`, but less justifiable to drop all cases where a respondent answered one item but not the other. The question is how should these partial responses be treated in the construction of the external efficacy index? Given that the response format for both items is on a bipolar scale with a neutral middle point, then the missing response can be coded as zero. In other words, in cases in which an individual responded to one item but not the other, the missing response will be coded to take a value of zero. This works due to the fact that the external efficacy index variable is constructed by taking the mean of 

```{r}

anes2024 |> 
  dplyr::mutate(
    dplyr::across(c(nocare, nosay), 
                  ~sjlabelled::as_label(.,prefix = T, keep.labels = T),
                  .names = "{col}.fct"
                  )) |> 
  dplyr::select(dplyr::contains("nocare"), dplyr::contains("nosay")) |> 
  dplyr::group_by(nocare.fct, nosay.fct) |> 
  dplyr::count() |> 
  dplyr::mutate('NOSAY + NOCARE' = forcats::fct_cross(nocare.fct, nosay.fct, sep = " + "), .before = n) |> 
  print(n = Inf)

```


```{r}

# run a cross tab using `janitor::tabyl` in order to get the valid N
# exclude NA with argument `show_na = F` which will exclude NA values from the
# cross tabulation.
# the bottom-right total value is the number of valid responses
anes2024 |> 
  dplyr::select(nocare, nosay) |>
  janitor::tabyl(nocare, nosay, show_na = F) |> 
  janitor::adorn_totals(where = c("row", "col")) |> 
  janitor::adorn_title(placement = "top")

# alternatively, using base R
table(nocare = anes2024$nocare, nosay = anes2024$nosay, useNA = "no") |> 
  addmargins()




```


```{r}



# this generates a list of tibbles with value counts and a valid total (i.e.,
# missing values excluded)
anes2024 |> 
  dplyr::select(nocare, nosay) |>
  purrr::map(\(x) janitor::tabyl(x, show_na = F) |> 
               janitor::adorn_totals(where = c("row")) |> 
               janitor::adorn_rounding(digits = 2)
             )

# alternatively
anes2024 |> 
  dplyr::select(nocare, nosay) |>
  # tidyr::drop_na() |> 
  purrr::map(~dplyr::count(data.frame(x = .x), x)) |> 
  purrr::map(\(x) tidyr::drop_na(x) |> janitor::adorn_totals(where = "row"))


```


There are two equivalent ways of computing the national average index value

method one: sum of the means

-   exclude missing values from data
-   get the mean of each item;
-   sum the means

```{r}

anes2024 |> 
  dplyr::select(nocare.recode, nosay.recode) |>
  tidyr::drop_na() |> # exclude missing values
  dplyr::summarise(
    nocare_mean = mean(nocare.recode, na.rm = T),
    nosay_mean = mean(nosay.recode, na.rm = T),
    sum_of_means = sum(nocare_mean, nosay_mean, na.rm = T)
    )


```


method two: mean of the sum

-   exclude missing values from data
-   get the sum of each item excluding missing values;
-   divide that sum by the number of valid responses:

```{r}

```


One problem here is that every row that contains a missing value in *either* column is dropped even if a valid response was recorded for one item. 


```{r}

# easier way to get `n_miss` that shows more information
# however doesn't tell me the number of valid responses per item
# for that I need to do the math myself
anes2024 |> 
  dplyr::select(nocare, nosay) |>
  naniar::miss_var_summary(add_cumsum = T) |> 
  dplyr::mutate(n_valid = nrow(anes2024)-n_miss)

```

# 2025-09-25

The goal is to combine each separate ANES data set in order to examine participant responses over time. This means I need to retain the data of interest for each year for the panel respondents. The panel sample from the 2024 ANES data ($n = 2,070$) reflects the number of panel respondents who completed both the pre- and post-election surveys in each of the three most recent ANES surveys. So starting with the 2024 ANES dataset, the variables from 2020 and 2016 are added to all of the cases (panel respondents). Since the ANES variable naming scheme embeds information in the variable column name itself, I can observe how an individual responded to a particular survey item presented/asked each year. 

If I wanted to get really in-depth, I could find those variables that are asked both in the pre- and post-election surveys across years. Most questions are asked in only the pre- or post survey, but sometimes there are certain questions/items asked in both waves. Unfortunately, for the external efficacy items at least, this only occurred a couple of times for certain ANES years: in 2008 and in 2012. These may be useful later. If there are significant differences between a participant's responses to the efficacy items in the pre-election survey compared to the post-election survey, then such results could potentially bolster the notion that the efficacy items capture an attitude less about their external efficacy as a political actor to shape political conditions and more about their degree of satisfaction with the makeup of government. 

Or even considering external efficacy as it is traditionally defined, significant differences between the pre- and post-election responses to identical or similar items would indicate a respondent's considerations are unrelated to "responsiveness of government to citizen demands" when responding to the component survey items, leaving us to conclude that the items fail to measure (and disallow estimation of) the intended attitudinal construct. A shift in external efficacy between survey waves within such a short interval would suggest that the results of the election are much more of a factor than government responsiveness.

More importantly, such results would imply that the items are inadequate as a measure of government responsiveness. No 'responsiveness' of government can be assessed by the individual respondent because the transfer of power to the newly elected government hasn't occurred, the next Congress hasn't been seated, and the next President hasn't been inaugurated. Certainly there are other political affairs and outcomes that occur during the interim period between survey waves, and perhaps such outcomes or events best explain significant shifts in the same attitude between waves, but this would suggest a severely unstable attitude that is liable to dramatically shift upon unidentified political outcomes. In other words, if it is the case that political affairs or outcomes between survey waves ( other than the electoral results) explain the shift in the attitude measures, then this would imply that the public is incredibly sensitive to such political events and the outcomes of government. However this pattern would have to hold for every year in which significant shifts of the same attitude are observed between waves. Or they may be expressing their ideas on the *prospective responsiveness* of government provided the governors and officials just elected, but this too deviates the construct into something conceptually distinct from government responsiveness. 

The bottom line is that significant divergence in the same attitude from one survey wave to the next implies that the considerations of the individual in response to the survey items are unrelated to the attitudinal construct referring to beliefs about the responsiveness of government to citizen demands.

If favorable or disfavorable election outcomes result in significantly divergent evaluations of government responsiveness to citizen demands (i.e., higher or lower external efficacy) in the post-election period compared to the same from the pre-election period, then it is fair to say that the individual's considerations in response to the items are detached substantially from what researchers refer to as "government responsiveness", or rather, *external efficacy defined as government responsiveness*. But this also highlights the fundamental problem with the conceptual definition of external efficacy itself; the conceptual definition is detached from whatever semantic meaning is conveyed by the word *efficacy*. 

The individual attitude captured by the survey items is detached from the conceptual definition given to external efficacy, which is ""...beliefs about the responsiveness of governmental authorities and institutions to citizen demands". It can't be said that respondents are simply misinterpreting the item statements or misunderstanding what they are being asked to consider; It's not the fault of the individual survey respondents. Rather, the fault lies with the researchers and scholars who mistakenly refer to the attitude captured by the items as something like "government responsiveness" or "external political efficacy". 

The items seemingly capture (or measure, or indicate, etc.) something, albeit only partially and hardly well, but we aren't sure what that *something* may be.

As we know from the literature, trust in government, voter confidence, and electoral trust are heavily influenced by the outcome of the election itself; electoral "winners" commonly report higher trust compared to electoral "losers". However the electoral outcome should not have any bearing on measures of external efficacy. Even taken as it is conventionally defined, there should be no significant differences in responses to external efficacy items between the pre- and post-election survey waves. There should be little to no change with respect to which a person believes that people like them have no say in what the government does and that government officials don't care about what they think. All that has happened between survey waves is that an election occurred; the newly elected government hasn't been inducted into office yet and so cannot yet even respond (except perhaps symbolically) to citizen demands. Significant differences in responses to these items between survey waves would imply that agreement or disagreement with the survey item statements are more related to favorability of electoral results and unrelated to the attitudinal construct in which the items are meant to measure.

More to the point, however, is that the link between the items and the construct the items are meant to measure would be invalid given significant differences in responses to identical items between survey waves. And this goes for the construct under any conceptual definition. 


# 2025-09-29

NOTE TO SELF: When generating lags, do so when the data is in `long` format. This allows you to group by `variable` and `year` and so when the data is pivoted to wide format, the lagged variables are on the same row as the original. The other method I was using was problematic because, even though lagged versions of the variables were created, the values were placed on the corresponding year (e.g., `exteff` in 2020 lagged 1-year simply placed the same value on year 2023). This made the analysis difficult as the lagged value for year 2020 wasn't on the row for 2020. You get it.


Hold up. I just figured out the difference in the methods for generating the lagged variables. When generating lagged versions of values from long form data, the lag is of the the prior x-lag values, not of the actual rows. So for instance, in 2004 the average external efficacy index value = 46.6, and the same value **four years prior** = 46.3, however, if we count back to the 4th previous value instead of lagging by year, the lagged value = 37.5 which reflects the value of average external efficacy in the aggregate in 1996 **four ANES Surveys ago**. In other words, lagging by year actually takes the value four years ago whereas the other method takes the value from the 4th previous value. This latter method is somewhat problematic for the "4-year" lag, but not the "1-year" lag. 

Essentially, the difference is in the type of lag (i.e., whether the lag is ordered by the year or ordered by the actual values of the variable). When I use the `dplyr::lag()`, the values of the vector object are shifted by the `n` argument. So `dplyr::lag(x, n = 4, order_by = year)` will *shift* the values back by 4 years but will place values in rows where the variable was not measured. If the lagged versions are generated while the data is in long form and grouped by the variable itself, the lag function `dplyr::lag(x, n = 4, order_by = year)` will shift the values of the vector by *replacing* the x value with the 4th prior value of `x`   
Here's a display that should help clarify


```{r}

df <- tibble::tibble(
  year = c(2000:2025),
  x = runif(n = 26, min = 0, max = 1),
  y = rnorm(n = 26, mean = 0, sd = 1),
  z = rbinom(n = 26, size = 1, prob = 0.5)
  )

df |> print(n = Inf)

# create lags ordering by time (e.g., year)
df <- df |> dplyr::mutate(
  dplyr::across(c(x, y ,z), ~dplyr::lag(., n = 1L, order_by = year), .names = "{col}.L1"),
  dplyr::across(c(x, y ,z), ~dplyr::lag(., n = 2L, order_by = year), .names = "{col}.L2"),
  dplyr::across(c(x, y ,z), ~dplyr::lag(., n = 3L, order_by = year), .names = "{col}.L3"),
  dplyr::across(c(x, y ,z), ~dplyr::lag(., n = 4L, order_by = year), .names = "{col}.L4"))


df |> print(n = Inf)


df[df$y < 0, -1] <- NA
# convert to long format


dt$lagged_manual <- c(NA,dt$base[1:(nrow(dt)-1)])
dt$leading_manual <- c(dt$base[2:nrow(dt)],NA)

dt

```

So `exteff` is the average value of the external efficacy index for a particular year; `exteff.t1` is external efficacy at `t - 1`, or simply the value of external efficacy lagged by 1-year. Since no value was measured the year prior, `exteff.t1` will be NA. Example, `exteff.t1` = NA until year 2021, where `exteff.t1` = 28.5 due to the fact that `exteff` = 28.5 in 2020 the year prior.


## 2025-10-01

Finally, much like Table 1 in Chamberlain's analysis, no predictors save for the lagged dependent variable attain statistical significance. If we choose to understand external political efficacy as beliefs about the responsiveness of government to citizen demands, these results provide us with no supporting information that the survey items validly measure the construct. That is, the public's attitudes about the consumer economy and presidential approval last year, nor the most recent measures of trust in government, seem to bear any weight upon survey items purported to function as measures of beliefs about the responsiveness of government and institutions to citizen demands or preferences. To put in other words, the two items are not measuring what we say they measure. This was Chamberlain's conclusion implied at the end of his research note. And yet, what we think the items measure is semantically, conceptually, or otherwise sensibly unrelated to a coherent conception of external political efficacy. The conventional understanding of external political efficacy is misconstrued as government responsiveness and attempts at its measurement are malformed. In fact, research published a decade ago  [@esaiasson2015]

If we choose an unconventional, but cogent, understanding---external political efficacy as an individual's appraisal of the public's capacity to shape conditions of the political environment---then not only are these results uninformative, but the model and method of analysis intended to test the coherence of measurement and meaning is inappropriate. Such results are to be expected given that none of the chosen predictors are reflective of the political environment---especially as macro-level contextual variables---and thus should not be expected to bear any influence on external political efficacy. 

The freedom to publish varied or alternative conceptions of the same construct is itself an indication of its misconstrual and invalidity, which is perhaps a consequence of the tendency to nominalize constructs of interest within the social sciences. Not only are the given measurement instruments inaccurate, but we can't even be sure that we are measuring the construct we intend to measure since we are often not discussing the same idea in the first place. Even though the name 'external efficacy' remains the same, the meaning gradually shifts until the noun serves as a nominal shell with the capacity to fit contradictory or conflated meanings. The noun continues to proliferate without objection even though the varied meanings given to the construct cannot validly cohere.

Something to consider is that we are not always deriving meaning of the concept from its use in ordinary language. Rather, we are often constructing the meaning of something we deem relevant to the field of study by either the theories we propose or by interpretations of the patterns we observe. Multiple definitions are not physically equivalent, so the way in which scholars construe the meaning of the concept in the abstract is incredibly important; especially when its construal in theory comes first.


## 2025-10-07 - 2025-10-08


The aim is to examine; 

1.    whether external efficacy differs substantially and significantly for people subject to different political conditions (i.e., different states or regions); and  
2.    whether external efficacy shifts when conditions of the political environment change.

Of course in both cases I must control for other factors that may influence an individual's responses to the two external efficacy items. The purpose of the study is to test whether the items justifiably function as measures for the construct. I say justifiably because construct validity seems to rest primarily, or solely, on whether the logical coherence between measure and meaning is sound. The definition of the concept, then, is paramount as it serves as the basal reference to test the logical validity between meaning and measure. 

So how I go about this is by use of panel survey data. The most recent iteration of the ANES survey includes a panel of respondents who completed the 2016, 2020, and 2024 ANES surveys. This panel comes from different states and regions across the United States. Since constituents of each state are subject to different conditions, I can determine whether external efficacy differs significantly between people subject to differing political conditions. That, however, isn't the important part and I wouldn't require panel data for that. The panel comes in handy because I can assess whether changing political conditions of the various contexts (e.g., states, regions) for which panel members resided had any bearing on measures of external efficacy during the length of the panel (i.e., from 2016 to 2024). For many, it is enough to say that much about the political environment has changed since 2016, but the political conditions of interest in this analysis are those ...


Analogously, there are plenty of factors that will influence my weight on the scale---on the measurement instrument meant to determine my body weight. So long as its safe to assume accurate measurement, then I can attribute weight gain or loss to factors other than validity of the measurement instrument itself. Yet the purpose is to test whether the measurement instrument properly (validly) functions to return the measurement of my body weight in the appropriate units corresponding to weight and not of something else. I would know the instrument was faulty if some other unit metric was returned that was entirely unrelated to body weight; if I stepped on the scale for it to return inches instead of pounds. 

If I know that measuring body weight in a different context would result in different results compared to another context relevant to body weight, then I could test the validity of the measurement instrument. For instance, I know my body weight on Earth differs from my body weight on the Moon; not because anything about me is different, but because I (specifically my body mass) am subject to different conditions within each respective environment. Thus, if the measure of my weight on Earth shows no difference in results between the measure of my weight on the Moon, then I would easily infer that my measurement instrument was defective in one way or another. The condition of interest are those which relate to my weight, specifically the gravitational force differs on the surface of either respective context. 

What conditions are of interest with respect to the political context? The relevant conditions are those which pertain to the individual's capacity to bring about political outcomes which may very well shape the conditions in which they are subject. There's a fundamental difference when it comes to conditions of nature and conditions of a political context---the conditions of the latter are formed by people. People fabricate a political reality by establishing the conditions thereof. The extent to which those who are subject to political conditions are capable of shaping said conditions to their will, their needs, or simply their preferences, is what I refer to as popular efficacy.    


The validity of the measurement instrument itself would not be faulty if the definition of body weight was unclear, or contested, or confused in someway. In fact, multiple and varied *conceptual* definitions can exist in tandem because each would be physically or materially equivalent. Other scientific fields may have multiple competing definitions for some object (e.g., mass) that are *physically equivalent*, but different conceptual definitions of some abstract concept construed in the social sciences literally change the ‘true’ construal of the thing we aim to measure.


## 2025-10-08

> "Finkel (1985) and others have shown that participation boosts external efficacy. This is especially true when that participation pays off and the preferred candidate wins." [@valentino2009a, 313]



NOTE: I was brought to this article by @valentino2009a because @chamberlain2012 referenced it in a footnote along with some other citations as research that focuses on the effects of external efficacy exclusively. 

> “Besides the measurement studies already noted, what has research specifically focused on external efficacy discovered?” [@chamberlain2012, 118]. 

However, although this article by @valentino2009a mentions external efficacy, it is primarily focused on internal efficacy. Specifically on the interaction of internal efficacy and anger. The third hypothesis (H3) of this study relates to external efficacy, but largely in order to appreciate a contrast of the results concerning internal efficacy. Simply, the authors hypothesized that external efficacy should not “facilitate anger (or fear) independent of an internal sense of political competence” [@valentino2009a, 318]. In other words, the effects of external efficacy on political participation were not expected to be bolstered or diminished (mediated by) anger or fear.

My overarching impressions of this paper as it relates to political efficacy is that the authors inclination toward psychological theories led them to an asymmetrical focus on internal efficacy as an influential factor that helps explain participation, and incidentally led them to downplay the importance of external efficacy on the same behavior. Somehow, the effect of external efficacy on behavior should not be mediated by anger (or fear) because external efficacy, “is not self-referential”.

> “Our model also predicts the impact of external efficacy to be unmediated emotionally, because it is not self-referential. The belief that the system is responsive in general should not facilitate anger (or fear) independent of an internal sense of political competence.” [@valentino2009a, 313]

> **H3** Neither anger nor fear mediates the impact of external efficacy on participation

More importantly, it inclines them to construe external efficacy as a belief that is not self-referential. That is, the reference object is stated to be the political system and the individual evaluates the extent of the responsiveness of that system. Other authors construe the reference object as government officials and institutions, which is still only a slightly less broad generalization. In this latter case, the system may be divorced from the operative governing actors, which makes the evaluation more particular to the contemporary regime rather than the vague agency of the “system”.

The illustrative difference is that an unresponsive system implies that public input is insignificant by design, whereas a government comprised of unresponsive political actors places blame squarely on the officials who remain insensitive to public input. The officials of whatever contemporary moment may be to blame, but the system itself is left out of the evaluation. This latter assessment omits an evaluation of the public’s capacity, and therefore efficacy, as political actors within the system aiming to influence, direct, or determine the outcomes of that system. It is one thing to say that public activity imposes little to no effect on political outcomes because the system is designed as such, and another thing to say that contemporary governing actors defy the system by dismissing, neglecting, or simply ignoring public input. Simply, the system works fine so long as those in office take heed of public demands, interests, and preferences. 

There is a stark but subtle difference implied when authors construe the object under evaluation differently. When external efficacy is construed as a belief about the responsiveness of governing actors to public demands, the reference object is, broadly, governing officials and they are evaluated on their responsiveness to public input (e.g., demands, expressions, preferences, interests) from the perspective of the individual. When external efficacy is construed as belief about the responsiveness of the (political) system, the object of reference is the system in general, but it is unclear what it means for the system to be more or less responsive to public input.   

Both cases, however, are wrong; the object of evaluation is the subjects *capacity* to bring about some end, thus rendering the belief an appraisal of *efficacy*. The end of which the subject aims is not merely to generate or observe a response from government officials, nor to merely affirm their status as political actors capable of contributing to whatever outcome. The end of political activity is to shape the conditions of the political environment. As such, all political acts of an individual or a collective aim toward this end, regardless of regime type or structure of the political system. A popular rebellion of a collective subjected to the oppressive conditions imposed by an authoritarian government body aims to shape the conditions of the political environment in which they are subject by whatever means necessary. Likewise, a popular mobilization of citizens subject to conditions governed by a Republican form of government aims to shape conditions of the political environment in which they are subject by whatever means necessary. 

The notion of political efficacy must conform with the ends of political activity, except this is often not made explicit. Review of the literature on political participation and of most, if not all, of the literature on political efficacy---before and after its decomposition into its internal and external dimensions---reveals how scholars and researchers of politics and government have established the purpose of political activity. Though often left unstated, researchers have long understood the purpose of political participation as merely *to influence* governing officials. As a consequence, the efficacy of the public's participatory activity is limited to this end. Hence *external political efficacy* is defined as the belief about the responsiveness of government officials to public demands, only subtly implying that the aim of public demand is limited to inducing a response from said officials. Whatever qualifies a government as "responsive" is not so well established; and due to its normative implications, the subject is left under examined by researchers.

This reformulation of the purpose of political activity subsequently leads to a different conception of political efficacy.
Thus, an individual evaluates the capacity of those subject to political conditions to shape those conditions by the means of political production available. 

:::{.callout-note}
Following is taken from my notes in Zotero on the @valentino2009a publication
:::

There’s this issue that both low and high external efficacy theoretically leads to political participation. Low external efficacy is the belief that government officials, or the political system, is unresponsive to popular input; That there are little to no actual means of inducing a response from government or the system available to the people. Simply put, that popular political engagement to that end is futile (this is a very generous conception of external efficacy). As such, it is reasonable to suspect lower or lack of political participation is a function of poor levels of external efficacy. However, higher levels of political engagement are also reasonable to suspect from lower levels of external efficacy, especially when external efficacy refers primarily to one’s belief about the perceived responsiveness of government.

This is where scholars often resort to dividing popular political activity into different types or kinds, e.g., conventional and unconventional. This division of different forms of political activity embeds a normative aspect into the scholarly and scientific assessment of political behavior. There then is an implicit *appropriate* form of political activity vice an *inappropriate* form of political activity. In this case, the authors have already denoted protest activity as an unconventional extreme form of political activity.

This is where scholars often resort to dividing popular political activity into different types or kinds, e.g., conventional and unconventional. This division of different forms of political activity embeds a normative aspect into the scholarly and scientific assessment of political behavior. There then is an implicit *appropriate* form of political activity vice an *inappropriate* form of political activity. In this case, the authors have already denoted protest activity as an unconventional extreme form of political activity.

## 2025-10-09

The aim is to examine; 

1.    whether external efficacy differs substantially and significantly for people subject to different political conditions (i.e., different states or regions); and  
2.    whether external efficacy shifts when conditions of the political environment change.

Of course in both cases I must control for other factors that may influence an individual's responses to the two external efficacy items. The purpose of the study is to test whether the items justifiably function as measures for the construct. I say justifiably because construct validity seems to rest primarily, or solely, on whether the logical coherence between measure and meaning is sound. The definition of the concept, then, is paramount as it serves as the basal reference to test the logical validity between meaning and measure. 

So how I go about this is by use of panel survey data. The most recent iteration of the ANES survey includes a panel of respondents who completed the 2016, 2020, and 2024 ANES surveys. This panel comes from different states and regions across the United States. Since constituents of each state are subject to different conditions, I can determine whether external efficacy differs significantly between people subject to differing political conditions. That, however, isn't the important part and I wouldn't require panel data for that. The panel comes in handy because I can assess whether changing political conditions of the various contexts (e.g., states, regions) for which panel members resided had any bearing on measures of external efficacy during the length of the panel (i.e., from 2016 to 2024). For many, it is enough to say that much about the political environment has changed since 2016, but the political conditions of interest in this analysis are those ...


:::{.callout-note}
Following is the modification of my notes from yesterday taken from my Zotero notes
:::

There’s this issue that both low and high external efficacy theoretically leads to, or is associated with, political participation. Low external efficacy reflects the belief that government officials, or the political system generally, are unresponsive to popular input. Though it becomes important later to discuss how the different ways of characterizing public *input*---e.g., as public 'demands' or as 'interests' or as 'preferences', etc.---is substantially significant. 

-   Depending on the kind of relationship between the two variables, the construal of external efficacy easily becomes distorted under different theoretical explanations. Lower or lacking external efficacy explains both low and high political engagement in theory. Yet given alternative theoretical frameworks [@craig1980], high external efficacy can also explain both low and high political engagement. (is there evidence to support the case in all ways?). 

-   I can illustrate how the construal of the independent variable can be easily distorted depending on interpretation of the (observed) relationship between the dependent and independent variable. An appropriate construal of external efficacy depends on an intuitive strictly positive monotonic relationship between external efficacy and political participation. By "appropriate" I mean construing external efficacy in alignment with the very basic semantic meaning of *efficacy*.    

-   Given a positive association of low external efficacy and low participatory activity, it is reasonable to suspect that lower or lack of political participation is a function of poor levels of external efficacy. In this case, the idea is intuitive: participation is lacking among those who don't believe such efforts to be worthwhile for achieving the ends sought.

-   However, given a positive association between low external efficacy and higher political activity, it is also reasonable to expect that higher levels of political engagement are a function of lower levels of external efficacy, especially when external efficacy refers primarily to one’s belief about the perceived responsiveness of government. In this case, the idea is that beliefs that the government is unresponsive to public demands *compels* political participation. 

-   Both expectations present causal explanations for associations between low external efficacy and low or high participatory activity. In contrast, higher external efficacy also leads to reasonable expectations for both low and high levels of political activity.

-   Just like before, the rational for the first explanation is intuitive---believing that the government is responsiveness to public demands confers the notion that participation is worthwhile as a means to achieve that end. 

-   Conversely, however, we might expect low participation from high degrees of external efficacy. In this case, the idea that public action isn't really necessary simply because of the belief that the government is responsive to the demands, interests, and preferences of the people.

-   Detailing out the different theoretical explanations given the different mixture of associations between external efficacy and political activity helps to clarify the different ways that external efficacy can be construed and misconstrued. 

-   Consider first that the more intuitive explanations consider the relationship as *strictly positive monotonic*---as external efficacy increases, higher levels of political activity are expected. Low external efficacy corresponds to low activity, whereas high external efficacy corresponds with high activity. Accordingly, the *means* to the end are paramount and central to the evaluation. Thus external efficacy reflects an appraisal of the means to a particular end---to engender responsive government. This construal of external efficacy is also semantically aligned with the ordinary meaning of *efficacy*---the capacity to achieve some outcome. Under this conception, the individual would evaluate the maximum effect (possible) of a given intervention toward achieving a particular end.  

-   Now the alternate explanations theorize that relationship between external efficacy and political activity as *strictly negative monotonic*---as external efficacy increases, lower levels of political activity are expected; Low external efficacy corresponds with greater activity, whereas higher external efficacy corresponds with lower active engagement. The rationale to explain these relationships are un-intuitive, but not necessarily irrational. In this case of low external efficacy and high political activity, the idea is that beliefs that the government is unresponsive to public demands *compels* political participation[^1]. Conversely, in the case of high external efficacy, low political activity is expected under the notion that increased political activity is not necessary given the belief that government officials are responsive to public demands, preferences, or interests. This construes external efficacy more as an indication of "diffuse support" 

[^1]: Gamson proposed such an idea with the hypothesis that higher sense of political efficacy and low political trust leads to increased political activity. According to Gamson's construal, political efficacy was but one dimension of political alienation, with trust (in government) referring to the other dimension. Trust, in this hypothesis, is important as it is an attitude that interacts with political efficacy

-   To @gamson1968, the 'efficacy dimension' clearly referred to *people's perception of their ability to influence* [@gamson1968, 42].

This is where scholars often resort to dividing popular political activity into different types or kinds, e.g., conventional and unconventional. This division of different forms of political activity embeds a normative aspect into the scholarly and scientific assessment of political behavior. There then is an implicit appropriate form of political activity vice an inappropriate form of political activity.


This belief, however, can be characterized in two slightly different ways. In one view, the belief is that there are little to no actual means available to the people capable of inducing a response from government or the system. Yet in a slightly different view, the belief is that despite public efforts proceeding through particular means, the government remains unresponsive to public input via those means. Ultimately, the belief is that the government is unresponsive to public input. However, the nuance is this: either one believes that there are simply no means available to the people capable of inducing response from government, or one believes that the contemporary government is unresponsive to public input given via particular means. Simply, there's nothing that we can do, or government officials are unresponsive to our efforts. This is really a distinction without a difference, but I think the point I'm trying to get at is that one belief is that there are no means available and the other is not so definitive---the government IS responsive just not to the typical means available to the public. Some stuff works, some stuff doesn't; whereas the other view is that no action functions as a means to achieve the end sought. 


## 2025-10-13


The aim is to examine; 

1.    whether external efficacy differs substantially and significantly for people subject to different political conditions (i.e., different states or regions); and  
2.    whether external efficacy shifts when conditions of the political environment change.

The important part is to determine whether external efficacy shifts in ways expected given the conventional definition of the concept itself. Since external efficacy is an attitude that concerns the *external* political environment, then we should see shifts in the attitude upon *changes* to the political environment. 

The key is whether individual attitudes, efficacy beliefs in particular, are responsive to **changes** in the environment. This becomes difficult with respect to whether an individuals are sensitive to changes at all. Another important factor is that the differences between context should result in differences in external efficacy. Even if there are differences in external efficacy that can be attributed to group differences, the context should be the ultimate basis of one's evaluation.

It is important to remember that the aim of the items is to capture (measure or estimate) the individual's belief about the responsiveness of government officials and institutions to public input (demands, etc.). The conceptual definition provides the framework for which the items are evaluated logically and empirically. 

First, people's attitudes may be insensitive to changes and shifts to the conditions of the political environment generally speaking. Not only is it difficult to maintain awareness over the complexity of political conditions (e.g., laws, policies, regulations), but one's general impressions and attitudes regarding said conditions may be relatively unrelated to their awareness of political conditions and thus unresponsive when changes to the *status quo* occur. That is, political awareness of the given state or changes to it may be unrelated to their impressions of it, thus rendering their efficacy beliefs insensitive to the political environment. 

Second, even if one is more or less aware of when changes to conditions occur, whether or not they judge this to be substantially different from their previous impressions is not just likely to vary between individuals but be resistant to change. Moreover, it is possible that there's little that increases one's external efficacy but plenty that functions to decrease it. This gives credence to a general negative bias where only factors detrimental to the construct impose any significance.

Of course, I can expect that the attitudes of some people will be relatively insensitive to environmental changes. Especially because the general national political context is considered, presumably, before any sub-national political contexts (e.g., regions, states, locales). I can also expect a general negative bias stemming from acquiescence bias as has been the most persistent worry with respect to efficacy measures.

However, supposing that the construct is being validly measured by the items in question, then there are some things that should still allow me to apply a proper test.



### 1

-   First, even if many or most people's attitudes are pretty insensitive to changing political conditions, their political behavior is responsive regardless. Prior research and history demonstrates that political behavior changes after policy change. The increases to turnout after enactment of the Voting Rights Act is a testament to this. 

-   Places where conditions changed to reduce the overall cost of voting should correspond to increased political behavior, but even if this is the case, we still aren't sure what to expect when it comes the direction of efficacy attitudes. Intuitively, we can expect higher efficacy to correspond with *changes to conditions* that lower costs and induce increased engagement. It is the **change** to less oppressive conditions that people would be responsive to, which should tell us whether the measures are validly capturing an individual's assessment of, and sensitivity to, the *external* political context. 

    -   For instance, If the particular change relaxes political conditions (e.g., expanding voting rights, accessibility, etc.) corresponds to upward increases in political engagement, then this would suggest that the prior conditions were too oppressive to the subjects in which they applied. However, this leaves us without clear expectations for the direction of external efficacy. That is, changes that lower the costs of voting, for instance, may not correspond to any shift in external efficacy beliefs, may increase said beliefs, or may decrease beliefs. Although the latter case seems counter-intuitive, it does concord with the given definition of external efficacy; individuals who are not satisfied with the change of political conditions would be expected to agree with the efficacy items. They see the government as unresponsive to the demands, preferences, and interests of "people like me". This is especially likely if the change was salient and colored by partisanship. Such results in either case would suggest that external efficacy items merely capture whether changes are acceptable from the perspective of the individual's partisanship. 

    -   If, however, after controlling for partisanship, external efficacy beliefs decrease upon changes that reduce the cost of voting, yet the same factor significantly corresponds to increases in voter turnout and engagement, then what is it that can be said about external efficacy measures? The only theoretical framework that would suffice would be the one that postulates that low external efficacy compels engagement. That is, the individual engages out of perceived necessity due to the contradictory beliefs that "people like me" have no say about what the government does and that the government doesn't care about what "people like me" think. In essence, this would suggest that low external efficacy resistent to environmental change is far better understood as a low trust in government. 

    -   If external efficacy beliefs are unmoved by changes to political conditions, but political behavior is upwardly responsive to less oppressive political conditions, then we would be observing a clear divergence between attitudes and behavior that requires explanation. But most importantly, this divergence would bring into question whether the measure of the construct is valid. 

-   Lower external efficacy may correspond with increases in behavior (voting, registration) and lowered cost of voting in a particular area under a theoretical understanding of the relationship of efficacy beliefs to political participation---that engagement and voting is necessary because I view the government as unresponsive to public demands. This logic, of course, doesn't make sense. If one perceives the government to be unresponsive to public input, then why would that necessitate more public input? The only reasoning I can come up with is that the individual would understand the government to be unresponsive to *public circumstances*, *revealed preferences*, and *indications of public interests*, but not unresponsive to public input-as-participatory-activity. That is, the individual would judge the government as unresponsive to the needs of the public as it is revealed by the state of affairs, but importantly, the individual believes that without public activity the government would remain blind to public grievances. Simply put, the individual believes that public participatory input is necessary to express public grievances that government officials are otherwise blind to recognize. 

-   Ironically, this interpretation of results corresponds to the conventional definition of external efficacy so long as that which stimulates government responsiveness (i.e., public demands/preferences/interests) refers to public circumstances and well-being and has nothing to do with political activity (public input). In essence, then, external efficacy would refer to beliefs about government responsiveness to public circumstances and conditions. Low efficacy, under this notion, would characterize the individual as someone who believes in the necessity of popular political participation to (influence) engender responsive government, hence the irony.

### 2

The second case is where political conditions become more oppressive resulting in downward reduction of participatory behavior. The decrease in political activity would be the obvious result expected as conditions change to become ever more oppressive than previously. The expected impact on external efficacy might also be in the same direction; as conditions become more oppressive, then we'd reasonably expect external efficacy to *decrease* to some extent. 

However, the conventional definition of external efficacy doesn't necessarily lead to this expectation. Rather, given the definition as referring to a belief about the responsiveness of government officials to public demands, then we can also reasonably expect *increases* in external efficacy for those who view the change to more oppressive conditions as responsive in some respect insofar as the perceived demands comport with the individual's preferences. This seems even more plausible considering that an individual agrees or disagrees with statements referring to "People like me", giving an implicit comparison of "people not like me" from which to contrast. That is, perceived government responsiveness may correspond to the composition of government officials---i.e., whatever changes come about are uncritically accepted so long as the right people are in office. This places a substantial weight on the perceived identity of government in relation to one's own.

As such, it is reasonable to expect differences between groups under the same conditions in terms of external efficacy. Such differences are apt to be based on partisanship, but might also be based on other group identities such as race and ethnicity, gender, and the like. In essence, whichever group becomes most prominent in the mind when the respondent considers "people like me" in response to the two efficacy items is likely to be a significant determinant of how the individual responds. 

Again, however, results from measures do not coherently conform to an understanding of efficacy as an appraisal of the individual's or the public's capacity to engender responsive government.

:::{.aside}

It is important to remember, however, that the aim is to capture (measure or estimate) the individual's *appraisal of the people's popular capacity to shape the political environment*. Under this conceptual framework, the only changes to the political environment that should matter are those that effect, or rather *condition*, the people's popular capacity to that end. Thus, it isn't that individual's should be sensitive to **any** changes to conditions thereof, but to particular conditions pertaining to their capacity as political actors whose activity aims toward particular ends. 

It is, therefore, important to be clear and explicit of the end to which political activity aims in general. Although individuals or groups with common interests may have particular outcomes which they aim to bring about, the general purpose of political activity must be established and clear in order for the conception of efficacy to be coherent. 

Scholars of the past have asserted the aims or purpose of political participation, and this assertion has had profound effects on the ways in which political participation is defined, measured, and understood in political studies and theory.

External efficacy has been conceptualized as a belief about the government or political system (less so about the political environment) understood in terms of attitudinal valence---i.e., whether one's attitude about the focal object is positive or negative. Although valence may matter to some degree, such an understanding reduces the conception of external efficacy down to simply whether one is more or less *satisfied* with government or the system today. In particular, whether one is satisfied with the extent to which they perceive government to be concerned with, and considerate of, "people like me". This misconstrual deviates the construct away from an appraisal of an actor's *capacity* to achieve some end, and thus divorces the concept from even a semantic relation to efficacy.

To put in simpler words, external efficacy has been misconstrued as beliefs about government officials or institutions responsiveness to public demands, or preferences, or interests. 

This definition makes it unclear as to how these demands, preferences, or interests should be regarded. It is easy enough to presume that these terms imply public activity as the means to which demands/preferences/interests are conveyed. These terms, however, connote more ambiguity as officials or institutions responding to public demands/preferences/interests, does not **necessarily** mean that said demands/preferences/interests are revealed or conveyed through political activity but may be ascertained in ways wholly independent of public activity. For instance, consider the notion of *revealed preferences* in economics where the preferences of consumers are revealed by observation of purchasing habits [@samuelson1948; @samuelson1938]. The important point to make clear whether the belief is an evaluation of government responsiveness to *public input* or simply to public circumstance.  

That being said, assuming that the definition implies public input as the stimulant, then  the external efficacy items must have an individual *evaluate the efficacy of public input*. That is, in order for the external efficacy items to be (logically) tenable as measures of the construct, the individual must evaluate the means to engender responsive government. 

The two external efficacy items do no such thing. Rather, the two items merely imply that which *should* induce responsiveness from government officials and institutions (e.g., "have a say"), but do not have the respondent explicitly evaluate the efficacy of those means. The implicit normative idea is that public expression (public opinion) should have the effect of influencing government officials in what they consider and in the actions they take. 

:::



## 2025-10-15

The aim is to examine; 

1.    whether external efficacy differs substantially and significantly for people subject to different political conditions (i.e., different states or regions); and  
2.    whether external efficacy shifts when conditions of the political environment change.

The important part is to determine whether measures of external efficacy differs and shifts in ways expected given the conventional definition of the concept itself. Since external efficacy is an attitude that concerns the *external* political environment, then we should see consistent differences between political contexts, and also *significant movement* in the attitude upon substantial *changes* within the political environment. In particular, changes that condition the public's efficacy to achieving the end implied by the conventional definition of external political efficacy.


1.  "People like me don't have any say about what the government does." [NOSAY]

2.  "I don't think public officials care much what people like me think." [NOCARE]

These two items are invalid as valid measures of the construct, first, on the ground of their logical coherence with the conventional meaning/understanding of the concept itself.

Measures of external efficacy have the respondent report (or rather, agree or disagree with assertive statements on) 

1.    the extent to which they believe the actions of government officials and institutions are *influenced by the expressions* of "people like me"; and  
2.    the extent to which they believe governing actors *care about the opinions or concerns* of "people like me".

I'll take note to mention that these two points generously paraphrase the survey item statements presented to respondents. The first item (NOSAY) has the respondent consider the extent to which they "*have a say*" in, simply, whatever government does. 

Presumably, the point is to evaluate the impact of one's "*say*" on either the actions of governing actors or the resulting outcomes of politics and government. We may readily suppose that one's *say* refers to public expression taken as a form of public's input[^1]. However, the statement doesn't permit evaluation of the efficacy of public input---of expressing one's *say* on the matters at hand. Instead the respondent must give a response that conveys whether they believe they *have a say or not*[^2]. 

To put in other words, the individual considers whether there are particular means available to them instead of evaluating the capacity of those means to achieve the end implied by the statement. Both considerations are important in terms of appraising the efficacy of something, but it is important to emphasize that it is the efficacy of the given means---i.e., expressing one's *say*---that is supposed to be under scrutiny.

The aim is to capture whether one represents a particular means as available to them given their (modal) condition, and more importantly, their appraisal of the efficacy of said means to a particular end. First, however, it is most important to determine whether the individual views the act (e.g., expressing one's *say*) as a means to the end at all.   

The government, generally speaking, does a lot of things. Not only is '*the government*' invoked as a homogeneous body of political actors, but also what government *does* can refer to practically anything. It can't be assumed that the respondent limits consideration of 'what the government does' to the official actions of governing actors or the outcomes that result from said actions. So this lack of specificity doesn't make it clear to respondents exactly what the respondent's *say* is supposed to achieve, produce, or induce. 

[^1]: Although, given the ambiguity present in the statement itself, 'having a say' in what government does doesn't necessarily imply reference to public input as *active* expression. The range of valid interpretations of the statement are potentially vast, as one may consider whether the *passive* public opinion of "people like me" reflected in public opinion polls and surveys function to influence whatever government does.

[^2]: It is important to be clear with respect to the different connotations of *having* the means toward some end. In one sense, to *have* means to *possess* some object which enables one's capacity to do or achieve some end (e.g., I *have* the one ring to rule them all, but without the ring, I am incapable). Where evaluations of efficacy become confused is when the means to some end are invoked as something the individual, or group, possesses as an object or even as an abstract internal quality. However in this case, *having a say* doesn't refer to possession of some object, but rather refers to one's *condition* in which they are capable of expressing their *say* to the end of influencing government action. 

-   So the statement "People like me have no say in what the government does" is supposed to convey, "the condition of people like me is such that our public expressions of grievances/demands/preferences do not suffice as a means to influence the actions taken by the government writ large." Or simply, "the effect of our public expression is equivalent to that of silence". 

-   There's no reason to suspect that a respondent takes heed of the different branches of government and the complexity of relations between them, as well as the inherent aspect of contest and conflict embedded within government before expressing their overall impression of whether their *say* has any impact on the government writ large. To the individual, the government is a homogeneous body of political actors who act in concert.  

-   It is not clear whether the individual considers 'what government does' to refer to the *actions* of political actors or groups, or whether 'what government does' refers to the *outcomes* of politics and government. Of course it doesn't really matter since. 

The second item (NOCARE) is not a statement asserting the efficacy of any act, which means that the respondent is not made to consider the statement on such grounds. It should be clear from the statement itself that a respondent bases their response on whose "*thoughts*" the government appears to care about compared to the *thoughts* of "people like me". The *thoughts* of "People like me" refers to public opinion in either an active or passive sense (i.e., expressed or revealed), but the statement has one consider whether the government writ large is partial to the public opinion of groups of "people like me" implicitly compared to groups of "people not like me". The comparative element dilutes one's considerations regarding whether the government cares to take heed of public opinion in general. Moreover, one's consideration boils down to an assessment of congruence between the thoughts of the government and the thoughts of whatever group of "people like me" that comes to mind. If partisan considerations are not at the forefront of one's mind, then some other complex (or simple) coalition of other group identities are likely to take precedence as the reference for considering whom or what government officials care most about. 

Giving credence to this point, researchers have recently coined another kind of group-centric efficacy construct further extending the conceptual periphery based on the notion that "people like me" implicitly invokes an unknown reference group [@phoenix2024]. Offering a somewhat novel set of survey items, @phoenix2024 propose *racial group efficacy* as a concept distinct from other notions of efficacy. Yet again, however, the measures purporting to measure racial group efficacy only put further strain on any kind of semantic coherence with the term "efficacy".

-   How often would you say public officials work hard to help [Respondent’s racial group]?
    
-   How often would you say [Respondent’s racial group] has a say in how government handles important issues?
    
-   How often would you say [Respondent’s racial group] elected to office can make changes for people in your racial group?

Rather than resolve the issue of an unidentified “People like me” statement wording that compels respondents to compare against "people not like me”, @phoenix2024 chose to make the “people like me” comparison explicitly in regard to one's racial group identity. Recognizing that “people like me” invites comparison, the authors explicitly refer to the kind of people the respondent has identified. What they have constructed, then, is merely a measure of the perceived racial priority of government action. Its less so about the capacity to produce responsive government and more so on the extent to which they perceive that the directed priority of government responsiveness aligns to benefit or serve their racial group.

In that last item, for instance, public officials are not generalized and the focal point of the item no longer concerns responsiveness of those public officials to public demands as it has no connection to public input via political action. Rather, the respondent evaluates *the capacity of public officials* belonging to a particular racial group to enact changes for the sake of the same racial group. The item becomes detached entirely from the foundational basis of which political efficacy was initially conceived, "...the feeling that individual political action does have, or can have, an impact upon the political process" [@campbell1954, 187].  


## 2025-10-16


The aim is to examine; 

1.    whether external efficacy differs substantially and significantly for people subject to different political conditions (i.e., different states or regions); and  
2.    whether external efficacy shifts when conditions of the political environment change.

Efficacy is a noun. 

The theory I have is that results from the two items will not cohere to any conception of external efficacy.


(how do we determine whether the construct is validly measured by the items?)


This point requires emphasis: There is no physical, or material, or tangible basis for the notion of external efficacy itself, which in turns means that the given conception is the only foundation we have. For many concepts of the social sciences there is no physical referent from which to base our definitions and as such the thing that we’re talking about is liable to change upon even subtle changes to the conceptual definition. Since the concept of interest is inherently abstract and often immaterial, *theoretical construal of the concept must be validated* if it is to be accepted. In simple terms, a particular conception (i.e., a theory of the concept) serves as the basal reference to evaluate the adequacy of the proposed items intended for measurement.

(How is the concept construed? The conception is identified in theory, and as such its entire identity (so to speak) rests on the theory of the concept proposed. From the theory of the concept we can discern its theoretical form, e.g., as a homogeneous attitude that encapsulates considerations about a particular subject matter.)

Importantly, it may be the case that the items intended to measure (estimate, indicate) one construct are capturing some other construct instead. Or the items may reveal a pattern that does not identifiably cohere to any extant concept. The way that we would recognize if either were the case is dependent on the strength of the theory of the concept, i.e., its conception. The logical coherence of the given conception allows us to reason about what we should expect. Results from items intended to (measure, capture, estimate) the formalized idea are, indeed, measured against the theory of the concept insofar as reasonable expectations can be derived from that conception. However, unless the given conception is coherent on its own terms, then no reasonable expectations can be derived. A circular definition of a concept, for instance, presents a logically incoherent conception that makes subsequent inquiry hard if not impossible. 

I use 'coherence' to also refer to a kind of semantic coherence between the term used to name the idea and its explicit or implied conception. A concept poorly (inadequately) conceived may be logically incoherent on its own terms, but even bad ideas are often given names, which makes all subsequent use of the named-idea inherently dubious. I will describe a problem that occurs when the **name of the idea** and **the very idea itself** either begins or becomes incoherent. In the case of external efficacy, the meaning of the ordinary word 'efficacy' is gradually detached from the definition of the concept itself.

The danger with *nominalizing* a belief about the responsiveness of government officials to public demands as *external efficacy* (a noun) is the strong inclination toward reification. In other words, by giving the idea an identifiable name such as *external efficacy*, there's a tendency to then refer to the name of the idea as though it were a concrete object. 

The *meaning* of the named-idea is mistakenly thought to derive from the measurement of it as though it were an object.

The consequence is that the meaning conveyed by the ordinary name of the concept gradually deviates from its conception under the notion that results from attempts to measure it as an attitudinal construct reveal to us what the concept actually means. This is a disaster. Such results don't reveal meaning of the concept when meaning is already established in theory; rather such results allow us to determine whether the interpretation of the data coheres to the foundational meaning of the concept identified by the theory thereof. If not, then the items intended to measure the given construct are invalid and cannot validly serve as measurement instruments---hence, construct validity. 

The point is that the interpretation of results from measurements or even relationships between different measures are interpreted as revealing to us the "true" meaning of the supposed underlying construct.



-   One problem is that any significant inter-correlation or observed pattern among a set of items meant to measure one thing is often implicitly conveyed in research as evidence indicative of the validity of the construct (or rather, validity of the measurement of the construct). Results from the measurement items may be related to some degree, but the logical connection between the results of measurement and the theoretical notion of the concept is not validated by inter-correlation. Cronbach's $\alpha$ coefficient is commonly provided in research that makes use of some measure. However, Cronbach's $\alpha$ coefficient should not be confused as sufficient validation that the items indicate a homogeneous construct. The $\alpha$ coefficient is a direct function of the number of items and the magnitude of their inter-correlation; yet the notion that the items are all measuring a single homogeneous (latent) construct is merely assumed. 

-   How do you falsify an idea? The theory of a concept is proposed, and a theory should be testable, i.e., falsifiable. Otherwise, the theory is taken to be true regardless of logical or empirically observed contradictions. A concept is, more or less, an idea. 

-   Take note that this discussion concerns the troubled *conception* of external efficacy, and as such the focus pertains to the theory of the concept, given or implied. I use 'conception' to denote the whole understanding of a more general and abstract notion, which would be the concept. Accordingly, I am not supplying an analysis *on the concept of* external efficacy (i.e., a conceptual analysis), but scrutinizing the varied and conventional conceptions of external efficacy that are either explicitly given or implied within the literature. 

-   I've often read the term "theoretical concept" employed, which to me conveys the idea that the concept has no observable reference beyond theoretical propositions[^3]. The issue of validating "theoretical concepts" concerns testing the proposition that an unobservable construct imposes some kind of influence upon observable referents, or 'indicators'.

[^3]: A similar term is "hypothetical construct", seems to be interchangeable

Multiple definitions are not physically equivalent, so the way in which scholars construe the meaning of the concept in the abstract is incredibly important; especially when its construal in theory comes first.

-   Once we reify (i.e., "real-ify", "thing-ify", "thing-make") the named-idea, a degree of conceptual space envelopes the construct and subsequent authors are evermore inclined to supply varied conceptions of the same idea.   

## 2025-10-17

The aim is to examine; 

1.    whether external efficacy differs substantially and significantly for people subject to different political conditions (i.e., different states or regions); and  
2.    whether external efficacy shifts when conditions of the political environment change.

The hypothesis is that results from the two items will not cohere to any conception of external efficacy.


Efficacy is a noun. Ordinarily, efficacy refers to the capacity to produce some intended result or outcome.

External political efficacy is a noun (rather, a noun phrase). The conventional meaning of external political efficacy refers to the belief about the responsiveness of government officials and institutions to public demands.

Juxtaposing the meanings together like this illustrates that external political efficacy has diverged from having a basic semantic connection with the ordinary meaning of 'efficacy'. Although ordinary meanings do not authoritatively prescribe meaning, external political efficacy is a technical term in political science that is divorced from what it would appear to mean on its face. 

The problem is not simply that we're referring to something by the wrong name. The problem is that the conception of the construct is also detached from the items purported to measure it, and results of those measures do not permit an interpretation coherent with the conventional theory of the concept nor with an improved conception of external political efficacy better aligned with the nominal meaning of the word 'efficacy'.

So there are three claims here:

1.    The conception (theory of the concept) has almost nothing to do with efficacy
2.    The item statements designed to elicit responses are not coherently connected to the construct as defined
3.    results derived from the two survey items do not (cannot) lead to a valid interpretation under any conception of the construct---i.e., results cannot be considered an evaluation of government responsiveness, nor trust in government, nor as an evaluation of efficacy.  

Not only are we not measuring what we think we are measuring, we aren't even clear about what it is we think we're trying to measure. We don't really seem to have a good, clear, and cohesive idea of what it is we're trying to ascertain. 

Conventionally, external efficacy refers to a belief about responsiveness of government to public input. However the items employed as measures do not elicit an appraisal of the efficacy of public input as a means to an end. The items don't have a respondent evaluate the *prior nor potential* effects of public efforts aimed at inducing a response from government officials or some other end. The items do not even simply ask "*does* public input produce results" or "*can* public input produce results".

At the heart of it all, we want to know what people believe themselves to be capable of achieving as political actors subject to the conditions of the contemporary political environment. 


-   If I try to decipher meaning by breaking down just the noun phrase, then I can surmise that external political efficacy refers to one's political capacity that is endowed or conditioned by that which is external to oneself. That is, a political capacity endowed from factors not inherent (intrinsic) to the individual. or said another way, one's political capacity is conditioned by external factors[^1]. The 'political' qualifier describes the capacity but doesn't really tell us much other than the notion that the capacity is of the political kind; whatever that means is unclear. This cannot be simply answered as "the capacity to act politically", as that tells us nothing and also renders the 'external' qualifier meaningless. Since external political efficacy pertains to actors, then the focal object is the capacity of the actions available to them. 

[^1]: Notable is that this implies an unconditioned political capacity of an individual's nature that is only conditioned by external (and perhaps internal) factors. In the 'endowment' sense, one's political capacity is endowed (provisioned) by whatever external factors, implying an individual would be politically incapacitated without such endowment. This distinction, though subtle here, echoes throughout classic texts significant to political philosophy. For instance, take Rousseau's famous opening line, "Man is born free, and everywhere He is in chains." And conversely, the U.S. Declaration of Independence asserts "certain unalienable Rights" as endowed to mankind.  

So when we talk about the efficacy of some thing or act, we're discussing the maximum effect of some intervention or stimulus on something else. To say that we appraise the efficacy of something or some act is to say that we are evaluating the capacity of said thing or act toward a definite end. We might consider in our evaluation of somethings efficacy whether or not previous observations of the thing resulted in the intended outcome, or we might also judge the efficacy of something in a more predictive sense based on what we deem necessary to achieve the intended result or produce the intended outcome.

However, when it comes to external political efficacy as it is defined and understood, we are discussing the extent that one believes the government to be responsive to public demands, preferences, interests, or the like. The intended result is apparently to induce response from government and the apparent intervention is public demands. 

Even if I strongly believe the government to be responsive to public demands, that does not imply high appraisal of "public demands" as an effective means available for stimulating responsive government. on the face of it, we can hardly consider external political efficacy as a belief about the efficacy of public input even if the stated aim is to induce responsiveness from government officials and institutions.    

Here is an example of how small, seemingly innocuous, differences in word choice matter when presenting the conceptual definition. Although it may be presumed that 'public demands' refers to some form of active political engagement, different scholars have employed different terms such as preferences, interests, needs, or sometimes a combination. This slight difference changes the stimulus that is to induce responsive government officials, and in turn, deviates the meaning of the concept away from one pertaining to efficacy. 

The point is that the definition emphasizes the concept as a belief about responsiveness of government rather than an appraisal of the means to produce responsive government. So the coherence of the conceptual definition on its own terms is important, but more so because it serves as the foundational reference for which to assess the validity of measurement instruments and interpretations of results produced from those instruments.  

Without a clear, cohesive, conception, there's no way to calibrate that which is designed specifically to measure the construct of interest. 


## 2025-10-21

The aim is to examine; 

1.    whether external efficacy differs substantially and significantly for people subject to different political conditions (i.e., different states or regions); and  
2.    whether external efficacy shifts when conditions of the political environment change.

The conventional conception is taken from literature in which external political efficacy refers to "...beliefs about the responsiveness of governmental authorities and institutions to citizen demands" [@craig1990, 290; @niemi1991a, 1408].

In order to determine whether results from measurement items cohere with the given conception of external efficacy, item responses must imply the belief that government officials are responsive to citizen demands. Determining this, however, is the challenge. @chamberlain2012 stated that, "...the definition of the measure implies that past government performance should affect it".

The theory: results from the two items will not cohere to expectations derived from the given conception of external efficacy. 

If the theory holds, then results in differing political contexts should move independent of the political context. In other words, changes in external efficacy should not be significantly associated with similar changes in different contexts. 



Multiple conceptions of external efficacy must be offered and tested against results from measurement. For that theory to hold, results must not cohere to any prior interpretation of results. 

For instance, first consider a (crude) conception of external efficacy that refers to a belief about one's capability to participate in the political process and effectuate change in political conditions. Now consider the external efficacy of similar/matched people in different states. If each state where those people live have enacted similar or identical changes to election laws, then we would expect the external efficacy of those matched people to change in similar direction regardless of other factors. That is to say, changes to political conditions should effect external efficacy in the same direction when controlling for other factors.

-   One hypothesis is that average external efficacy   


> “Likewise, a multi-item scale will mislead when *something other than the underlying predisposition* of interest causes one group to systematically respond differently from another.” [@pietryka2022, 1075]

This is important as it highlights the chief issue regarding the construal of external political efficacy. External efficacy is construed as an attitude---a belief about something---but the way the attitude is construed in theory implies that it should be responsive to particular considerations or a particular stimulus. What is not clear is whether external efficacy is a belief about government responsiveness or a belief about some aspect of the political environment. 

On the one hand, the political context is established as the main focus of the belief from the name of the construct itself---external political efficacy concerns the *external* political environment. Specifically, external efficacy concerns one's beliefs about their own and others political efficacy (capacity) as conditioned by the *external* political environment. This conception also complements conception of the sister construct, internal political efficacy: Internal efficacy concerns one's beliefs about their own political efficacy conditioned by that *internal environment*, so to speak. One's subjective assessment of their own political knowledge, awareness, esteem, and whatever other personal quality pertains to their perceived political competence conditions the extent of what we call their internal political efficacy[^1]. In fact, the foundation of the concept is political efficacy as it was initially conceived; the internal and external distinctions simply serve to identify categories of which to separate that which condition one's political efficacy.      

[^1]: Indeed it may be less confusing to simply refer to this construct as perceived personal political competence as @converse1972 did, or even subjective political competence. 

On the other hand, the perceived responsiveness of government takes central emphasize in the conceptual definition of external political efficacy. Even though the conventional definition refers to external efficacy as a belief about responsiveness *to public input*, it is not defined as an evaluation or appraisal on *the efficacy of public input*. Indeed, external efficacy is primarily *an evaluation of government responsiveness* and much less an appraisal of the efficacy of public demands, if at all. 


However, even taking the conventional definition into consideration, review of the external efficacy items don't appear related to conception of the construct.

1.  "People like me don't have any say about what the government does." [NOSAY]

2.  "I don't think public officials care much what people like me think." [NOCARE]
 
-   Going back further to when "sense of political efficacy" was reformulated into two related but separate dimensions, @balch1974 referred explicitly to "influence attempts".   

The stimulus, or intervention, that is supposed to be evaluated is ambiguous and general; public demands is easier to imply as active public input of some kind, but public preferences may have nothing to do with an active input of any kind. 

 

(showing that the construct isn't about the efficacy of some thing or act, and that measures don't produce responses interpretable as appraisal of efficacy of any thing or act.)

The point being is that the construal of external efficacy is malformed. So we can understand it as a belief sure, but in order to devise and evaluate measurement of the belief, we need items that indicate the position and intensity of the belief that logically coheres with its theoretical conception.

The fact that multiple conceptions of external efficacy is at all feasible is indicative of the poor conception of the construct, and in turn, helps explain the trouble regarding measurement. I offer up two valid and unobjectionable conceptions of external efficacy from the same literature to demonstrate the incoherence that plagues the study of political efficacy.



A multi-item measurement instrument is validated first by the logical coherence between the items and the theory of the concept, i.e., the conception of the construct. So long as that logical link is valid, then interpretations of responses to the items logically follow as indicative of the construct.


:::{.distraction}

> “All survey questions and response options contain ambiguity. Consequently, some respondents will interpret even a carefully worded item differently from how other respondents will. Respondents’ personal backgrounds shape their interpretations, causing their understanding to differ from individuals with dissimilar educations, ethnicities, or other social circumstances. For instance, the Authoritarianism scale asks respondents to choose which of two desirable traits is more important for a child to have. One item asks whether it is better for a child to be considerate or well behaved. This item promotes inequivalence by gender if women differ from men in their conception of a “well behaved” child.” [@pietryka2022, 1076]

The ‘inequivalence’ the authors speak of refers to the different interpretations respondents have to the same item. What they say isn’t necessarily untrue---respondents with different backgrounds, etc., will respond differently to the same question item. However this doesn’t mean the items are measuring something different for different groups, it means that the items aren’t measuring anything at all. There’s no need to believe that there’s something being measured at all simply because enough responses have been collected from a multi-item scale. 

-    There’s no need to believe that there’s something being measured at all simply because enough responses have been collected from a multi-item scale.

What the authors attempt to say is that the cognitive paths of reasoning taken, and the considerations along the way, differs systematically between groups even though they are prompted with the same question item on the survey. Case-in-point, the authors say, “If women differ from men in…” their conception of the terms given---i.e., if the qualitative meaning of the term differs systematically between men and women. 

Yes, the scale is not measuring what is intended, but not because the conceptual notion, the meaning, the idea of a “well behaved child” differs between men and women. The scale is not measuring what is intended because it cannot be logically discerned how one’s response to the item coheres to the construct as conceived in theory. We would need to first accept, i.e., validate, the reasoning for why responses to this item reflect authoritarianism.

One significant problem is that results will arise from any combination of items, even if random. I can put together any set of items, generate an average from coded responses, and give that average value a name. I might also present a sufficiently high (Cronbach’s) coefficient $\alpha$ as a testament to the internal-consistency reliability of my made up construct. I can inflate this coefficient $\alpha$ by including more items with decent covariance. Including $\alpha$ is not enough on its own, of course, but in many papers it is often the only validation metric of measurement supplied. The traditional ways of validating measurement of a social construct is often with reference to the relationship with other social constructs established first in theory. This thing should relate to that, but should be wholly independent from this other thing, and so on. Additionally, a measurement instrument is tested multiple times in order to determine whether results are reliably consistent. So even if I took a random set of items, computed an average from coded responses, and gave it a name, the same set of items would still need to produce reliably consistent results each time they are deployed in a survey.

Common factor analysis aims to help us determine whether responses to multiple items are all influenced from the same underlying factor. Specifically if item variation is commonly attributable to (explained by) one or more common factors. Yet even this method is imperfect, as any name can be attributed to whatever factors arise from an analysis. Confirmatory factor analysis first supplies a theory regarding a set of items, i.e., responses to this set of items are expected to be associated with a single-common factor or a certain number of common factors.

A popular method referred to as *Exploratory* factor analysis quite literally explores whether any factors result from measures taken from multiple items. When multiple factors account for variation in items, then these factors are sometimes given names that are either arbitrary or correspond to the apparent coherence between items that share a common factor. To me exploratory factor analysis seems a-theoretical, but this isn’t to deem the method as useless. Finding patterns in data is obviously important; the trouble comes when researchers endeavor to discover theoretical concepts in data by means of an a-theoretical method.

:::


The conception of the construct should provide us with an understanding of how or why the construct drives responses to the measurement items.


## 2025-10-22

The conceptual definition is the basal reference from which the coherence of the measurement items is evaluated. A valid interpretation of results as measurement (or estimation) of the intended construct depends on this coherent link between meaning and measurement; first, and primarily, in theory. Then, to the extent possible, by analysis of correlations with other theoretically related factors or constructs. The conceptual definition guides us on how best to measure the construct, but the quality and coherence of the measurement item questions or statements and response options are all that permit valid interpretations of measurement results. We can say that agreement/disagreement with this item statement implies this sentiment, but the validity of the interpretation of the response data as measurement of the construct depends on the logical force of the theory.


The aim is to examine; 

1.    whether external efficacy differs substantially and significantly for people subject to different political conditions (i.e., different states or regions); and  
2.    whether external efficacy shifts when conditions of the political environment change.

The conventional conception is taken from literature in which external political efficacy refers to "...beliefs about the responsiveness of governmental authorities and institutions to citizen demands" [@craig1990, 290; @niemi1991a, 1408].

To determine whether results from measurement items cohere with the given conception of external efficacy, the interpretation of item responses must indicate the belief that government officials are responsive to citizen demands. 

Determining this, however, is the challenge. @chamberlain2012 stated that, "...the definition of the measure implies that past government performance should affect it". 

Yet that is not implied by the definition. In fact, definition of the construct implies that government performance should affect measurement only when it is *presumed, implied, or stated to be induced by public input*. In other words, the only instance when government performance should affect measurement of external efficacy is when the actions or output of government are believed to be a result of citizen demands. 

Chamberlain would have been better off stating that the definition of the construct "*suggests*" that government performance indicators would affect measurement results, but this still would not save the invalid theory. 

Evaluating the efficacy of something requires an assessment of the means to some end; but assessing the efficacy of the means by evaluating the extent or quality of the end state embeds a converse error in the logic of the concept. That is, the notion that an individual evaluates government performance in order to evaluate whether they have, or can have, any effect upon said performance commits the traditional fallacy of affirming the consequent[^1]. 

[^1]: Affirming the consequent is a formal fallacy---an invalid form of argument---wherein which the consequent, $Q$, is affirmed (asserted) and the antecedent $P$ is inferred. In other words, the converse of the conditional statement $P \rightarrow Q$ (If $P$, then $Q$, $P$ implies $Q$) is taken to invalidly conclude that because the consequent is true, therefore the antecedent is true ($\therefore Q \rightarrow P$; therefore $Q$ implies $P$).

In other words, @chamberlain2012 is stating that, according to the conceptual definition of external efficacy, individuals will evaluate past government performance, which leads us to expect (i.e., *implies*) an effect on levels of external efficacy in theory. This theory is logically invalid unless we have reason to believe that individual reasoning in this case follows such invalid reasoning. 

There's no expectation that an individual's considerations prompted by the item statement will conform to perfect rationality. On the contrary we have plenty of reason and evidence to believe that individual reasoning is often incoherent, messy, and biased in more ways than a dozen. 

As such it may seem fair to assume, at least, that considerations of past government performance would inform one's assessment regarding their efficacy to influence government responsiveness. To illustrate the fallacious, but not implausible, rationale presumably implied by lacking external efficacy: Since government officials appear indifferent to the needs, opinions, interests, or demands of the public, or even just "people like me", then I can take that to infer that public influence attempts are ineffective. 

However, it is indeed not fair, or valid, to assume that this invalid line of reasoning will take place, or is implied by the definition of external efficacy as Chamberlain stated. Variables of perceived government performance may have some association with external efficacy, but there's no expectation people will draw on past government performance before assessing whether they bear any influence on government activity.

Chamberlain is saying that it is reasonable to expect that people will draw upon their impressions of government performance---which are captured by presidential approval ratings and economic sentiment---in order to, or simply prior to, assessing their capacity to influence government activity and output. 

reasoning will be invalid as they will affirm the consequent to infer the antecedent; that a low evaluation of government responsiveness implies a lack of (external) political efficacy. 


The theory: results from the two items will not cohere to expectations derived from the given conception of external efficacy. 

If the theory holds, then results in differing political contexts should move independent of the political context. In other words, changes in external efficacy should not be significantly associated with similar changes in different contexts. 


:::{.aside}

> “Alternatively, a strong sense of internal efficacy indicates to that individual that he or she possesses the means to secure a response from government officials, even when those officials generally are unresponsive to the demands of other citizens.” [@craig1982, 87]

Aside from what I've said about this distinction previously, this assertion also doesn't cohere with the professed understanding and measure of internal political efficacy. One's internal efficacy is, simply put, a self-assessment of one's own competence *to confront and engage with political topics and considerations*. This self-assessment is a compared against one's impressions about the general political competence of the public writ large. The notion of internal efficacy cannot be understood as a sense indicating to the individual that they *possess* the (internal) means "to secure a response from government officials..." simply because this is 1) not in accordance with the given conceptual definition, and 2) incoherent with the meaning implied by the internal efficacy item statements. Upon review of the internal efficacy item statements, **it does not follow** that one's self-assessment of their "internal means" (i.e., of one's political competence) is "to secure a response from government officials". At best, agreement with the item statements lead to the interpretation that, in comparison with most other people in general, the individual believes theirself competent enough to engage with and consider political topics, affairs, or issues when confronted.

:::


:::{.aside}

The conventional understanding of external efficacy is explicated further by @miller1989,

> “External Political Efficacy, unlike internal political efficacy, measures expressed beliefs about political institutions rather than perceptions about one’s own abilities. A sense of external efficacy denotes the feeling that an individual and the public can have an impact on the political process because government institutions will respond to their needs. The lack of external efficacy or the feeling of inefficacy indicates the belief that the public cannot influence political outcomes because government leaders and institutions are unresponsive to their needs.” [@miller1989, 254]

This excerpt states that external efficacy denotes the feeling that the public can have an impact because of the presumption that government will respond to their *needs*, not their demands or some other form of engagement or input. That is, it states that a response from government is induced by simply having particular needs for the government to address---not by actively doing anything to arouse government into action. This particular definition, in essence, seems confused with trust in government---the individual trusts that the government will aim to benefit the public’s best interest, acting accordingly in response to the needs of the public.

Note that this understanding diverges considerably away from having to do with 'efficacy' at all. The individual believes that the public "can have an impact" because government "will respond to their needs". It is not understood as a belief about the efficacy of public input, and in fact @miller1989's conception removes public input from the idea. Public *needs* aren't necessarily conveyed via some form of public input---by overt expressions or explicit demands or the like---but may be recognizable from observation. Whatever the public needs is not tenable as a means of any kind. In short, the conception of external efficacy espoused here refers to a belief regarding whether, and to what extent, the government responds to the needs of the public. An evaluation of the influential capacity of 'public needs' may be an evaluation of efficacy sure enough, insofar as 'public needs' can be objectified in noun form and denoted as a stimulus. This is the same as evaluating the efficacy of hunger towards influencing another to feed the hungry. But this is not *necessarily* an evaluation regarding the efficacy of the means of public input (e.g., public activity) aimed at influencing or stimulating government response to address public needs.


:::


There's a few reasons as to why the theory is invalid: first, performance evaluations aren't evaluations of responsiveness to public input. At best, the index of consumer sentiment reflects an individual's impressions of contemporary economic conditions, but even if the economy relates to how the public evaluates government performance, the theory is still required to link why the economy conditions the political capacity to influence government officials. Chamberlain justifies the ICS variable on the grounds that high consumer sentiment "...typically indicates that the government is doing a good job" [@chamberlain2012, 121]. 

Second, the definition of the construct implies nothing about how individuals will consider or respond to survey item statements. 



Third, the coherent link between measurement items and the construct 

## 2025-10-23

The aim is to examine; 

1.    whether external efficacy differs substantially and significantly for people subject to different political conditions (i.e., different states or regions); and  
2.    whether external efficacy shifts when conditions of the political environment change.

There are two arguments I am making here;

1.    The concept *external political efficacy* is misconstrued as government responsiveness and semantically divorced from "efficacy".
2.    Responses to the items purported to measure the construct cannot be validly interpreted as beliefs about the efficacy of means to an end.

The trouble is that these arguments are primarily based on the theory of the concept and the coherence between its measurement and its meaning. Since external efficacy is primarily understood as an evaluation of government responsiveness to public input (i.e., influence attempts), then it is perhaps necessary to test whether the items validly capture the construct according to the given conception. 

The conventional conception is taken from literature in which external political efficacy refers to "...beliefs about the responsiveness of governmental authorities and institutions to citizen demands" [@craig1990, 290; @niemi1991a, 1408].

The two items that comprise the measurement of external efficacy follow,

1.  "People like me don't have any say about what the government does." [NOSAY]

2.  "I don't think public officials care much what people like me think." [NOCARE]

In most cases, response options are bipolar and symmetrical around a neutral middling option on either a 5-point or 7-point scale. Survey respondents are prompted to indicate whether they agree or disagree with each item statement, with enough options to include the magnitude of their agreement or disagreement (e.g., strongly agree, strongly disagree). If they neither agree nor disagree with either statement, they also have that option available to choose as their response.

To determine whether results from measurement items cohere with the conventional conception of external efficacy, the interpretation of item responses must indicate the belief that government officials are responsive to citizen demands. It is questionable, however, whether this is at all feasible by use of the two items purported to measure external efficacy. In fact, there is already a long history of empirical studies that have scrutinized these two items to determine whether they sufficiently correspond to a  multitude of different conceptions of "efficacy". 

Indeed, the conventional conception of external efficacy is essentially boiled down from a torrid conceptual journey in which multiple scholars have contributed varied distortions to the meaning of the concept. As such the conventional conception of external efficacy is an amalgamation of meanings accrued from the residue of past attempts to make sense of the '*internal*' and '*external*' decomposition of political efficacy. 

For instance, the conventional conception of external political efficacy is not much more than the combined ideas of "Incumbent-Based Efficacy" and "Regime-Based Efficacy" offered by @shingles1987. Shingles delineation of Incumbent- and Regime-based efficacy is itself drawn from earlier conceptions of external political efficacy made in an attempt to distinguish a precise conception of the construct distinct from political trust [@shingles1987; @gamson1968; @easton1967].

> "Gamson defines political trust as a belief in the basic integrity of government; it is the expectation that government will produce preferred outcomes whether or not citizens participate (1968, p.54). Political efficacy is the belief that citizen participation is effective. Easton's distinguishes between two foci of political support: (1) effectiveness of citizens' inputs (supports and demands) in policy making and implementation and (2) satisfaction with policy outputs (the quality, efficiency and equity of government's response). Political efficacy is the belief that citizen participation is effective. Easton's distinguishes between two foci of political support: (1) effectiveness of citizens' inputs (supports and demands) in policy making and implementation and (2) satisfaction with policy outputs (the quality, efficiency and equity of government's response). Whereas political trust focuses solely on outputs; [External Political Efficacy] addresses both. As such, political trust is a component of [External Political Efficacy]. [External Political Efficacy] refers to whether one can condition policy outputs by making political inputs. Political trust does not require inputs. As Gamson states, [External Political Efficacy] is the perceived ability to act effectively. Political trust addresses the need to act. Trusting citizens need not participate in politics (unless otherwise motivated). Cynical citizens must act to protect their own interests." [@shingles1987, 2]

Coleman and Davis make an important contribution stating that the conception of external efficacy must take stock of the political context. And not much later, @craig1979 provides more theoretical support for the multi-dimensional distinction 

compiled together from @craig1990 interpretation of results from confirmatory factor analysis in which they state, "...the results suggest that (1) NOSAY and NOCARE combine both regime- and incumbent-based assessments of governmental responsiveness to citizen demands" [@craig1990, 294]


From the start the meaning and measure of internal political efficacy was of special interest to researchers who endeavored to develop a robust instrument in order to estimate one's belief in their own political competence. The conceptual foundation of internal political efficacy benefited immensely from burgeoning theories and research in psychology and especially from theories of self-efficacy [@bandura1969; @bandura1977; @bandura1986]. Much the same way in which the initial "sense of political efficacy" concept was construed by political researchers and sociologists enamored with psychoanalysis. Yet where internal political efficacy developed asymmetrically into a pristine measure of the intended construct, the meaning of external political efficacy was left to rummage through the waning embers of scant political theory. 

Many diverse scholars imparted substantive independent theoretical work and empirical analysis that tried to better delineate the conceptual distinction between external efficacy and, well, everything else it was related to empirically.   



The plausibility of the interpretations proposed by the theory of the concept is lacking, dubious, or simply implausible; and the extent to which the evidence supports the proposed interpretation of measurement results is insufficient or otherwise absent. In fact, the claim espoused here is that results *refute* the proposed interpretation of the evidence derived from survey item responses. 

The interpretation proposed by the theory of the concept is provided simply by the conceptual definition taken together with whatever additional explication is provisioned by the researcher. Responses to the survey item statements (taken together or separately) do not imply the interpretation proposed regardless of whether the individual agrees or disagrees.

It usually goes without saying, but the response options corresponding to the statement implies the interpretation given by the researcher. That interpretation, however, is given by the theory of the construct---i.e., the conceptual understanding of what the items are purported to measure. As such, whatever "agree", "disagree", or "neither agree nor disagree" means is asserted first in the theory of the concept.

Traditionally, when a respondent agrees with the statement, "People like me don't have any say about what the government does", the interpretation is simply taken as an indication for a lack of, or diminished, belief referred to as external political efficacy. That is, agreement is taken as an indicator of the belief that government is not responsive to public influence attempts. However, this interpretation is not implied[^1] by the statement and correspondent response. 

[^1]: To be clear, by *imply* I mean in the conclusion does not logically follow from the stated premise.   

The first item (NOSAY) has the respondent consider the extent to which they "*have a say*" in, simply, whatever government does. The simple phrase "have a say" carries a lot of weight in the statement but it isn't explicitly clear what that refers to. They then must decide whether they agree or disagree with the assertion that "People like me" do not have any say, whatever that means.

Presumably, the aim is to have the respondent evaluate the impact of one's "*say*" on either the actions of governing actors or the resulting outcomes of politics and government (i.e., "what the government does"). We may readily suppose that one's *say* refers to public expression taken as a form of public's attempts at influencing the actions of governing officials[^3].

However, the statement doesn't permit evaluation of the *efficacy* of public input---of expressing one's *say* on the matters at hand. To put in other words, the respondent is not evaluating the means to the end of influencing the acts of government officials and outcomes of politics. Instead, the individual is prompted to evaluate whether "people like me" 


because of this, the respondent is no longer evaluating the efficacy of one's *say* toward influencing what the government does. 

Taken together with "People like me don't have a say", the individual is set up to consider whether the particular demands, interests, needs, or opinions of "People like me" somehow function to influence on what the government does. The important takeaway here is that the respondent is not evaluating *efficacy of the means to some end*, but the relative status and perceived importance of "People like me" implicitly demarcated from "People not like me". 

What this means is that responses to the first item (NOSAY) cannot be interpreted as pertaining to, or indicating, one's beliefs about the efficacy


[^2]: Although, given the ambiguity present in the statement itself, 'having a say' in what government does doesn't necessarily imply reference to public input as *active* expression. The range of valid interpretations of the statement are potentially vast, as one may consider whether the *passive* public opinion of "people like me" reflected in public opinion polls and surveys function to influence whatever government does.

[^3]: It is important to be clear with respect to the different connotations of *having* the means toward some end. In one sense, to *have* means to *possess* some object which enables one's capacity to do or achieve some end (e.g., I *have* the one ring to rule them all, but without the ring, I have not the means to rule them all). Where evaluations of efficacy become confused is when the means to some end are invoked as something the individual, or group, possesses as an object or even as an abstract internal quality. However in this case, *having a say* doesn't refer to possession of some object, but rather refers to one's *condition* in which they are capable of expressing their *say* to the end of influencing government action. 


These two items are not valid measures of the construct, first, on the ground of their logical coherence with the conventional meaning/understanding of the concept itself.


-   The statement "People like me have no say in what the government does" *does not* convey, "the condition of people like me is such that our public expressions of grievances/demands/preferences do not suffice as a means to influence the actions taken by the government writ large." Or simply, "the effect of our public expression is equivalent to that of silence".


:::{}

Thus, it is hard to validate the expectation that external efficacy would shift upon changes to the political environment based on understanding of the concept expressed in the literature; the expectation doesn't follow from its conceptual definition. The political environment is not interchangeable with government responsiveness in meaning nor metric. Indeed, the very moniker of the construct as "external political efficacy" seems incoherent with its stated meaning.

:::


:::{.}

The following two points generously paraphrase the survey item statements in order to explicate the interpretations proposed by the theory of the construct.

1.    the extent to which they believe the actions of government officials and institutions are *influenced by the expressions* of "people like me"; and  
2.    the extent to which they believe governing actors *care about the opinions or concerns* of "people like me".



:::

 

To put in other words, the individual considers whether there are particular means available to them instead of evaluating the capacity of those means to achieve the end implied by the statement. Both considerations are important in terms of appraising the efficacy of something, but it is important to emphasize that it is the efficacy of the given means---i.e., expressing one's *say*---that is supposed to be under scrutiny.

The aim is to capture whether one represents a particular means as available to them given their (modal) condition, and more importantly, their appraisal of the efficacy of said means to a particular end. First, however, it is most important to determine whether the individual views the act (e.g., expressing one's *say*) as a means to the end at all.   

The conceptual definition is the basal reference from which the coherence of the measurement items is evaluated. A valid interpretation of results as measurement (or estimation) of the intended construct depends on this coherent link between meaning and measurement; first, and primarily, in theory. Then, to the extent possible, by analysis of correlations with other theoretically related factors or constructs. The conceptual definition guides us on how best to measure the construct, but the quality and coherence of the measurement item questions or statements and response options are all that permit valid interpretations of measurement results. We can say that agreement/disagreement with this item statement implies this sentiment, but the validity of the interpretation of the response data as measurement of the construct depends on the logical force of the theory.


## 2025-10-28 --- 2025-10-30

This study addresses the construct validity of external political efficacy. Specifically, I aim to test the validity of a particular interpretation of data arising from survey items purported to measure the construct. 

Taken together, responses from these survey items are thought to indicate, to some extent, one's position along the dimension of the belief as it has been construed in theory. The external efficacy belief informs or influences responses to the respective survey items. As such, an individual is considered more or less 'externally efficacious' as indicated by their responses to the appropriate survey items. 

The question is how do we validate the interpretation that responses to the survey items represent the belief they are purported to measure. How are we sure that agreement or disagreement with these particular items describes a person as more or less 'externally efficacious'? Given the conventional definition, do the item responses really indicate the degree to which a person believes the government is responsive to citizen demands?  

Because the foundational conception of external efficacy is semantically disconnected from efficacy, attempts to measure the construct are doomed to fail. Even taken on their own, response data resulting from the items purported to measure the construct cannot be validly interpreted as evaluations of efficacy at all. As such, no interpretation of response data from external efficacy items cohere with its given conception, but worse, the given conception itself is misconstrued and semantically divorced from "efficacy" in the first place.

The trouble with external efficacy has not gone unnoticed in prior literature, but there's been little in terms of proper scrutiny despite the attention given to validating the multidimensional conception of political efficacy starting around the early 1970's if not earlier. 

From the start the meaning and measure of internal political efficacy was of special interest to researchers who endeavored to develop a robust instrument in order to estimate one's belief in their own political competence. The conceptual foundation of internal political efficacy benefited immensely from burgeoning theories and research in psychology and especially from theories of self-efficacy [@bandura1969; @bandura1977; @bandura1986]. Much the same way in which the initial "sense of political efficacy" concept was construed by political researchers and sociologists enamored with psychoanalysis. Yet where internal political efficacy developed asymmetrically into a pristine measure of the intended construct, the meaning of external political efficacy was left to rummage through the waning embers of scant political theory. 

Many diverse scholars imparted substantive independent theoretical work and empirical analysis that tried to better delineate the conceptual distinction between external efficacy and, well, everything else it was related to empirically. 

One notable effort by @chamberlain2012 stands out as a lonely attempt to validate the meaning and measure of external efficacy. 


There are two arguments I am making here;

1.    The concept *external political efficacy* is misconstrued and semantically divorced from "efficacy".
2.    Responses to the items purported to measure the construct cannot be validly interpreted as beliefs about the efficacy of means to an end.

The trouble is that these arguments are primarily based on the theory of the concept and the coherence between its measurement and its meaning. That is to say, no empirical analysis is necessary to show the misconstrual of external efficacy (see part 1) and that the interpretations of item responses are untenable as efficacy beliefs (see part 2). However despite this, it will be necessary assess the validity of the survey items as a measure of the construct in question. The way to go about this, however, is the very challenge confronted here (part 3).


The aim is to examine; 

1.    whether external efficacy differs substantially and significantly for people subject to different political conditions (i.e., different states or regions); and  
2.    whether external efficacy shifts when conditions of the political environment change.


The two items that comprise the measurement of external efficacy follow,

1.  "People like me don't have any say about what the government does." [NOSAY]

2.  "I don't think public officials care much what people like me think." [NOCARE]

In most cases, response options are bipolar and symmetrical around a neutral middling option on either a 5-point or 7-point scale. Survey respondents are prompted to indicate whether they agree or disagree with each item statement, with enough options to include the magnitude of their agreement or disagreement (e.g., strongly agree, strongly disagree). If they neither agree nor disagree with either statement, they also have that option available to choose as their response.


::: {not sure where to include this yet}

An attitude, to put simply, refers to that which houses one's *considerations* (i.e., all that one considers) about an issue, topic, or subject[^1]. Attitudes are, "...a kind of database consisting of feelings, beliefs, and knowledge about an issue." [@tourangeau2000, 179]. So survey items prompt an individual to retrieve some indefinite multitude of various considerations sampled from a particular belief *identified in theory*, combine them to produce an overall judgement, and then translate that judgement into a response on the respective close-ended survey item[^2]. 

[^1]: To allay a longer paragraph, I'll settle here to clarify that "considerations", made most familiar by @zaller1992, are succinctly described by @tourangeau2000 as, "...a haphazard assortment of beliefs, feelings, impressions, general values, and prior judgments about an issue", whereas attitudes are "memory structures that encompass these considerations about an issue [-@tourangeau2000, 179]. 

[^2]: This roughly describes the key assumptions of the belief-sampling model [@tourangaeu2000, see chapters 6-8].  

:::




### part 1: the misconstrual of external efficacy

In a very basic sense, a theory must be logically valid before all else. In this case, the conception of external political efficacy is, simply, not logically valid because even if the premises of the concept were true, the truth of the 'conclusion' is not guaranteed. 

Now this is an elementary understanding of validity in the logic of deductive reasoning---an argument is valid if and only if it takes a form that makes it impossible for the premises to be true and the conclusion to be false. 

The conceptual definition is the basal reference from which the coherence of the measurement items is evaluated. A valid interpretation of results as measurement (or estimation) of the intended construct depends on this coherent link between meaning and measurement; first, and primarily, in theory. Then, to the extent possible, by analysis of correlations with other theoretically related factors or constructs. The conceptual definition guides us on how best to measure the construct, but the quality and coherence of the measurement item questions or statements and response options are all that permit valid interpretations of measurement results. We can say that agreement/disagreement with this item statement implies this sentiment, but the validity of the interpretation of the response data as measurement of the construct depends on the logical force of the theory.


-   A broader argument made here follows from my contention on external political efficacy which is that neither the external nor internal dimension corresponds to a cohesive idea of political efficacy. That is, neither the internal nor external qualifiers make sense as dimensions of political efficacy because they don't really correspond to assessments of efficacy at all. 

-   Now the internal dimension is akin to the idea of Self-Efficacy found in psychology [@bandura1982; @bandura1997]. However in political studies of public opinion and behavior, internal political efficacy is better named by how it has been understood---as one's judgement regarding their personal political competence. That is, what we refer to as internal political efficacy reflects an aspect of one's self-esteem, of confidence in their ability to confront topics and considerations regarding politics and government to include the mere prospect of participating. This confidence in their own political competence stems from how well they know and understand political affairs, issues, figures, processes and what not, as well as their own interest in sustaining awareness, and of course, their educational attainment. Now self-efficacy in psychology is generally accepted as 'efficacy' outright in the sense that a person believes in their own capacity, or capacities generally speaking, to "execute courses of action required to deal with prospective situations" [@bandura1982, 122]. In the simplest sense, Self-efficacy concerns impressions about one's own capacity to act, generally speaking. Self-efficacy tells us whether the general statement "I believe in myself" would be uttered as a meek whisper, screamed in false bravado, or stated without a hint of self-doubt when confronted with the prospect of some engagement. 

-   Internal political efficacy has been conceived in much the same way, except that instead of being general, it is a particular judgement of one's own competence in regard to prospective engagements with politics and government. Dealing with the "prospective situation" of a simple discussion over political affairs requiring one's capacity to demonstrate awareness, knowledge, sophistication, or simply put, engage in political discussion. Or dealing with the prospect of partaking in political activity of some or any sort requiring much of the same and then some. Hence the internal efficacy items have a person report how qualified they perceive themselves to be 'to participate in politics', their self-perceived level of understanding of contemporary political issues, their prospective performance in public office, and their self-perceived level of awareness in comparison to most others. It is fine to refer to the construct by what the items tell us. As a personal evaluation of their own political competence, we need not refer to this as 'political efficacy' at all, and indeed, many recognized the nominal moniker for nothing more than that. Yet there's more substantive reason given its conceptual, even semantic, departure from the original 'sense of political efficacy', which specifically concerned one's belief about *the efficacy of political action*.

-   The measures of internal and external political efficacy do not tell us whether one believes that individual political action is worthwhile, whether political action matters, whether and to what extent active political engagement imposes any influence on the actions of governing actors, nor whether public intervention results in political outcomes.

-   The important part is that, taken together or separately, neither external nor internal efficacy measures tell us the maximum effect of individual nor popular political activity from the perspective of the subject. This means that neither are tenable as evaluations of political efficacy.

-   For interested researchers, the conventional measures of political efficacy do not nor can not inform us as whether the impact of public intervention, if any, would be recognizable as such from the perspective of the public. This point requires emphasis: scholars are unable to evaluate whether an individual, and by extension the mass public, is sensitive to the effects, if any, of their own political participation. Most importantly, scholars are also unable to evaluate whether the public is sensitive to substantial changes to the political environment---to conditions that pertain to the people's capacity to produce political outcomes, to impose influence, or even to participate as political actors. That is, we're unable to ascertain whether the people are sensitive to the conditions of their political status.


### part 2: the interpretations of item responses are untenable as efficacy beliefs

It is very important to remember, "In general, the evidence to be expected in a validity analysis depends on the proposed interpretations and uses of the test scores." [@kane2009, 45]. "One validates, not a test, but an interpretation of data arising from a specified procedure." [@cronbach, 1971, 447].

To determine whether results from measurement items cohere with the conventional conception of external efficacy, the interpretation of item responses must indicate the belief that government officials are responsive to citizen demands. It is questionable, however, whether this is at all feasible by use of the two items purported to measure external efficacy. In fact, there is already a long history of empirical studies that have scrutinized these two items to determine whether they sufficiently correspond to a  multitude of different conceptions of "efficacy". 

Indeed, the conventional conception of external efficacy is essentially boiled down from a torrid conceptual journey in which multiple scholars have contributed varied distortions to the meaning of the concept. As such the conventional conception of external efficacy is an amalgamation of meanings accrued from the residue of past attempts to make sense of the '*internal*' and '*external*' decomposition of political efficacy. 

For instance, the conventional conception of external political efficacy is not much more than the combined ideas offered by @shingles1987: "*Incumbent-Based Efficacy*" and "*Regime-Based Efficacy*". @craig1990 compiled together an interpretation of results from confirmatory factor analysis in which they state, "...the results suggest that (1) NOSAY and NOCARE combine both regime- and incumbent-based assessments of governmental responsiveness to citizen demands" [@craig1990, 294]


Shingles delineation of Incumbent- and Regime-based efficacy is itself drawn from earlier conceptions of external political efficacy made in an attempt to distinguish a precise conception of the construct distinct from political trust [@shingles1987; @gamson1968; @easton1967].

> "Gamson defines political trust as a belief in the basic integrity of government; it is the expectation that government will produce preferred outcomes whether or not citizens participate (1968, p.54). Political efficacy is the belief that citizen participation is effective. Easton's distinguishes between two foci of political support: (1) effectiveness of citizens' inputs (supports and demands) in policy making and implementation and (2) satisfaction with policy outputs (the quality, efficiency and equity of government's response). Political efficacy is the belief that citizen participation is effective. Easton's distinguishes between two foci of political support: (1) effectiveness of citizens' inputs (supports and demands) in policy making and implementation and (2) satisfaction with policy outputs (the quality, efficiency and equity of government's response). Whereas political trust focuses solely on outputs; [External Political Efficacy] addresses both. As such, political trust is a component of [External Political Efficacy]. [External Political Efficacy] refers to whether one can condition policy outputs by making political inputs. Political trust does not require inputs. As Gamson states, [External Political Efficacy] is the perceived ability to act effectively. Political trust addresses the need to act. Trusting citizens need not participate in politics (unless otherwise motivated). Cynical citizens must act to protect their own interests." [@shingles1987, 2]

Coleman and Davis make an important contribution stating that the conception of external efficacy must take stock of the political context. And not much later, @craig1979 provides more theoretical support for the multi-dimensional distinction.

### part 3

The supposed and conventional interpretation of results from the two items is that they are each independently indicative of the construct and together are useful as an instrument to accurately represent a (quantitative) measure of the concept referred to as external political efficacy.


Do the two items function sufficiently as an instrument for which to measure the construct as conceived in theory? If not, then there are no other ways for which we can validate the very idea as a homogeneous latent construct following the theoretical framework provided by classical test theory. Although represented as a theoretical concept, no items prove adequate to test that theory. Rather, at best, the construct must be understood as a variable manifested from the totality of observations from a set of items. This would remove external efficacy from its understanding as a belief or attitude revealed by a set of indicators, to a different kind of variable formed, and defined, by the composition of particular observations. 

No interpretation is necessary for this latter kind of variable, as the component items are perfectly measured (i.e., recorded) during observation and the variable is computed from the formula of its component parts. That formula may simply be a summary of component observations (e.g., sum, mean, ratio), or could be something more complex. For instance, when one asks for the definition of speed, a formulaic definition cohesively describes the idea---speed refers to the rate of motion, or even *the measure* of the rate of motion. Or in more detail, the speed of an object refers to the magnitude of change of its position (i.e., distance traveled) per unit of time. Thus, it is easy to provide a formula to convey the definition of speed: $v = \frac{d}{t}$, where $v$ is speed, $d$ is distance, and $t$ is time. The conceptual understanding of speed is not difficult to understand as a property of a thing, an object in motion; and even though speed itself isn't a thing, it is an observable property that is equal to the formula of its component parts, distance over time. The formula defines the concept, hence formative.

This *formed* variable (contra. latent variable) is not too different, or not different at all, from other common variables such as a country's GDP. 

Since external efficacy is primarily understood as an evaluation of government responsiveness to public input (i.e., influence attempts), then it is perhaps necessary to test whether the items validly capture the construct according to the given conception. 

The conventional conception is taken from literature in which external political efficacy refers to "...beliefs about the responsiveness of governmental authorities and institutions to citizen demands" [@craig1990, 290; @niemi1991a, 1408].

The two items that comprise the measurement of external efficacy follow,

1.  "People like me don't have any say about what the government does." [NOSAY]

2.  "I don't think public officials care much what people like me think." [NOCARE]