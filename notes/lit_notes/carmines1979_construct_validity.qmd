---
title: "On Construct Validity"
subtitle: "A critical review of @carmines1979"
---


:::{.callout-note}
I began writing out this note on 2025-09-05 which was intented to be on construct validity itself, but this became more of a review of a particular book by @carmines1979. The relevance of all this is directly applied to my contentions with the meaning and measure of external political efficacy.
:::


> “Construct validation involves three distinct steps. First, the theoretical relationship between the concepts themselves must be specified. Second, the empirical relationship between the measures of the concepts must be examined. Finally, the empirical evidence must be interpreted in terms of how it clarifies the construct validity of the particular measure.” [@carmines1979, 23]

Something missing here (and in the illustrative example on self-esteem) is the step, or steps, prior to making the theoretical proposition regarding what the construct is related to; we need to provide a definition of the concept. We’re *validating the construct itself*, not simply the relations of a construct taken as a given.

Importantly, the concept must not be defined for the sake of affirming the theoretical proposition, i.e., construed *post hoc* said theoretical propositions (i.e., that self-esteem is positively related to participation). The conceptual definition must stand on its own before being relevant to subsequent propositions. Simply put, we must first explicate what we mean when we refer to self-esteem. If self-esteem, nominalized as an *it*, a *thing*, a *noun*, then we must present a clear and coherent conception of what *it* is on its own terms. Since, in this example, self-esteem and participation are different constructs (one a property of an individual, the other an extent of one’s activity) then self-esteem should be defined without reference to whatever relation or relational effect it may impose, but importantly, it must be defined without regard of whether *it* can be measured.

This is why, as the authors say, the process is, by necessity, theory-laden; without some tangible empirical referent, then the conception of whatever construct is theoretical in the first place.

In the *hard* sciences (e.g., physics) there may be multiple definitions of certain tangible, material objects that are conceptually distinct but still *physically equivalent*. In contrast, for most constructs of the social sciences there is no physical referent from which to base our definitions and as such the thing that we’re talking about is liable to change upon even subtle changes to the conceptual definition. Thus, since the concept of interest is inherently abstract, and thus immaterial, *construal of the concept must be validated* if it is to be accepted.


> "It should be clear that the process of construct validation is, by necessity, theory-laden. Indeed, strictly speaking, it is impossible to “validate” a measure of a concept in this sense unless there exists a theoretical network that surrounds the concept. For without this network, it is impossible to generate theoretical predictions which, in turn, lead directly to empirical tests involving measures of the concept...What is required is that one be able to state several theoretically derived hypotheses involving the particular concept." [@carmines1979, 23-24]


> "The more elaborate the theoretical framework, of course, the more rigorous and demanding the evaluation of the construct validity of the empirical measure. Notice that in the self-esteem example discussed above, we concluded that the positive association between Rosenberg’s self-esteem scale and participation in school activities provided one piece of evidence supporting the construct validity of this measure. Greater confidence in the construct validity of this measure of self-esteem would be justified if subsequent analyses revealed numerous successful predictions involving diverse, theoretically related variables. Thus, construct validity is not established by confirming a single prediction on different occasions or confirming many predictions in a single study. Instead, construct validation ideally requires a pattern of consistent findings involving different researchers using different theoretical structures across a number of different studies." [@carmines1979, 24]

I think this is okay but could, again, be better said if they emphasized that the aim is to test the assumption of the concept as construed. The essential step of theoretical conception, so to speak, is still skipped over.

The authors suggest that the construct validity of a particular measure cannot really be accepted until a pattern of consistency is shown across multiple studies for which the measure is employed. The problem with this is that many studies will often only include a construct due to its relevance to the particular theory or research objective. Quite often, a relevant construct is included but the construct validity of is measurement is not of interest. Such studies are not always intended to test the construct validity of a measure, as that would be its own research objective. For certain constructs, construct validity is presumed. This is especially prevalent for long standing familiar constructs of which common means of measurement have become an implicit standard. Researchers will make reference to confirmatory literature under the presumption that construct validity of measurement has been well established. Even more so when large annual surveys include a particular set of measures, which then become the standard form of measurement for a particular construct. Depending on how long a certain measure has been included in annual surveys, continuity of measurement becomes a concern. 

As such, it becomes paramount to take into account whether studies that include a particular construct of interest are intended to test the construct validity of its measurement, or whether the construct was merely peripheral to the research objective. Note, however, that a measure for which construct validity is accepted may not then engender subsequent research interest into testing its construct validity. Thus the pattern of consistent findings from a rich body of literature would be lacking. If it ain't broke, don't fix it. On the one hand, a large and extensive body of literature would not consist of mere replication serving to regularly reaffirm the construct validity of a particular measure. On the other hand, an extant body of literature concerned with a certain construct and its measurement may itself indicate that measurement is, at the very least, insecure.

Note also that the authors seem to imply that a single study which may invalidate measurement of a construct is not enough in the face of a pattern of consistent findings from different researchers and methods that appear to confirm construct validity of a particular measure. This, to me, seems incorrect; one study should be enough to falsify a falsifiable theory. And since many of the concepts of the social sciences are fundamentally theoretical, then every such construct is always liable to falsification and evidence against the construct validity of measurement should be taken as such.

Evidence that seemingly contradicts construct validity of some measure should invite subsequent inquiry. Although this does occur, the aforementioned hesitancy to do away with long standing measures for the sake of continuity sets a high bar for contrary evidence to surpass. Continuity for its own sake implicitly functions as the criteria necessary for evidence against construct validity of a certain form of measurement. Contrary evidence may be relegated to the periphery, but what is seemingly more likely is that researchers will go on to develop entirely novel constructs rather than assess the validity of what is already established or long standing. Or, alternatively, research will aim to improve measurement of a particular construct without doing away with what has already become standard, and importantly, *without aiming to challenge the given conception of the construct*.

What I haven't mentioned yet, however, is that there is no standard or clear method to test the construct validity of measurement. What counts as evidence against construct validity isn't uniform but depends primarily on the quality and coherence of the theory thereof. As Cronbach as said, "One validates, not a test, but an interpretation of data arising from a specified procedure"

Moreover, falsifying evidence must be conclusive---that is, the evidence must necessitate the conclusion. Now, we may not have complete confidence in the evidence itself, which would challenge the evidence as a premise to the conclusion. In other words, if it is not the case that the resulting evidence invalidates construct validity of measurement, then it would not follow that the theory of the concept as a given would also be false.


@carmines1979 state that there are at least four interpretations possible when evidence challenges *construct validity*. The first, "...most typical interpretation of such negative evidence is that the measure lacks construct validity. Within this interpretation, it is concluded that the indicator does not measure what it purports to measure." [-@carmines1979, 24]. 

> "This does not mean, of course, that the indicator does not measure some other theoretical construct, but only that it does not measure the construct of interest. In other words, as negative evidence accumulates, the inference is usually drawn that the measure lacks construct validity as a measure of a particular theoretical concept." [@carmines1979, 24]

The authors then suggest that the remaining three interpretations are also valid alternative conclusions that can arise when evidence against construct validity arises. They equivocate all interpretations presented, when in actuality, the remaining three are valid counter arguments against the first.

The first *alternative* interpretation the authors state is that, "...the theoretical framework used to generate the empirical predictions is incorrect." [-@carmines1979, 25] which has to do with whether the theory of some research inquiry coherently leads us to the interpretation challenging construct validity of the given measure.

> "To continue with the earlier example, it may be the case that, from a theoretical perspective, self-esteem should not be positively related to participation in school activities. Therefore, a nonpositive relationship between these variables would not undermine the construct validity of Rosenberg’s self-esteem scale but rather cast doubt on the underlying theoretical perspective." [@carmines1979, 25]

The theory must suggest that this or that relationship would undermine construct validity in order for results to be interpreted as such. The idea is that challenges against construct validity of the given measure would be misplaced if the theoretical framework is insufficient, incorrect, or lacking in the first place. The logic of our theory must reasonably lead to an interpretation challenging the construct validity of the measure with respect to the kind of relationship we'd expect between the construct of interest and some other variable construct. That is to say, the theory must coherently imply the interpretation that the given measurement instrument does not measure the construct it is purported to measure.

This doesn't suggest that this interpretation of results must be conclusive, that is, necessitated. However it does suggest that this kind of interpretation against construct validity must be warranted in theory and, if not conclusive, must compete against other reasonable interpretations. This makes sense given that such inferences drawn from fallible evidence are inductive rather than deductive[^1]. To put more simply, the evidence might simply suggest that the theory is wrong but the measures are fine in terms of construct validity.

This, of course, is an argument made by researchers open to contestation. An argument challenging the theoretical framework used to generate empirical predictions is difficult to make, especially if results are interpreted in such a way as to bolster the theory in question. Frankly put, an argument alone, no matter how reasonable, is likely not enough to sway consensus or even engender doubt against such an interpretation. Especially for fields of study that seem to increasingly shy away from qualitative approaches in favor of the quantitative, computational methodologies. The consequence, however, is the proliferation of weak or even incoherent theories overlooked in the face of compelling data and results. Despite the difficulty, such challenges must be made if only for the sake of progress and strength of the science involved.   

As it concerns the construct validity of the external efficacy measures, the theoretical frameworks used to engender a multitude of empirical predictions are not necessarily incorrect due to the fact that such theories are usually based on the somewhat standard conceptual definition and understanding established in the literature. However, my contention is that the very definition of the concept is incoherent.


The third stated interpretation of evidence against construct validation is that "...the method or procedure used to test the theoretically derived hypotheses is faulty or inappropriate." The authors state, 

> "Perhaps it is the case that, theoretically, self-esteem should be positively associated with participation in school activities and that the researcher has used a reliable and valid measure of self-esteem. However, even under these circumstances, the hypothesis will still not be confirmed unless it is tested properly. Thus, to take a simple example, the negative evidence could be due to the use of an inappropriate statistical technique or using the proper technique incorrectly." [@carmines1979, 25]

However, this interpretation doesn't appear to concern construct validation of the measure *per se*. Indeed, the authors even suppose that in this situation the measure of self-esteem is both reliable and valid---which would include construct validity. In short, this interpretation of negative evidence simply says that the issue is not the construct validity of the measure but rather the incorrect or improper use of method. We'd expect such cases to be apprehended within the peer review process. Ultimately this point doesn't pertain to construct validity in particular as any interpretation of the data arising from the given procedure would be invalid if the methods were inappropriate or improperly applied. 


The final interpretation simply extends argument of construct validity to another variable construct of a given model or analysis. The authors state that negative evidence, "...is due to the lack of construct validity or the unreliability of some other variable(s) in the analysis."

> "In a very real sense, whenever one assesses the construct validity of the measure of interest, one is also evaluating simultaneously the construct validity of measures of the other theoretical concepts. In the self-esteem example, it could be the case that Rosenberg’s self-esteem scale has perfect construct validity but that the measure of “participation in school activities” is quite invalid or unreliable." [@carmines1979, 25]

Surely this is just one potential argument against the idea that measurement of the construct of interest is invalid out of an indefinite number of arguments that can be made. However all that is stated is that a counter argument would simply shift the issue to another variable construct. This surely can happen, but it would be dismissive of any claims against the construct validity of the measures regarding the first construct. 

The three alternative interpretations presented by @carmines1979 are merely arguments against the first argument---that the measured indicators do not measure the construct they are purported to measure. Note that evidence that would be considered negative evidence against construct validation of some measure is not described. Rather, the authors state only what is required to establish construct validity, and that is pretty vaguely put as "a pattern of consistent findings" [-@carmines1979, 24].

The bottom line point I am trying to get at is that the authors leave out that evidence against construct validity doesn't only invalidate the measure as simply erroneous, but also serves to challenge the theory of the concept itself. As Cronbach said, we validate (or invalidate) "an interpretation of the data arising from a specified procedure" [@cronbach1971, 447]. However, unless we're conducting an exploratory analysis of the data, we first posit a particular interpretation of the data *prior* to its collection. As such, we're not dependent on the data for the interpretation if the reason we collected the data in the first place posited a particular interpretation *a priori*. Cronbach is right to say that we validate an interpretation of data arising from a specified procedure.

> "A single instrument is used in many different ways---Smith's reading test may be used to screen applicants for professional training, to plan remedial instruction in reading, to measure the effectiveness of an instructional program, etc. Since each application is based on a different interpretation, the evidence that justifies one application may have little relevance to the next. Because every interpretation has its own degree of validity, one can never reach the simple conclusion that a particular test "is valid."" [@cronbach1971, 447]

To put another way, the measurement instrument takes aim at a target theorized to be somewhere down range. The measurement instrument isn't firing small little bullets, but rather fires a net towards where we suppose the target is present. Crucial to this analogy is that we do not know for sure what the target looks like, so *identification* of the target is done by first clarifying *a priori* what we are aiming for in theory (and by clarifying what we are not aiming for). Accordingly, even the measurement instrument, the net, is designed in such a way to best capture the target of interest identified in theory, which is to say that the net takes the shape of the target itself. The net is meant to capture the target but incidentally will also capture many other things that are not the target, even things that may share similarities to the target. After shots are fired, we sift through everything captured in the net. If nothing within the captured data fits the target description *in accordance to the concept identified in theory*, then we have no evidence that the target as described is even really out there.

Now there's a whole lot of things that could plausibly explain why our net came up empty. Perhaps the net is the wrong size or shape. Or the idea of using a net to somehow capture (measure) the target of interest is incorrect. Yet we designed the net based on the theory of the target; how do we know whether the instrument is invalid or whether the theory is wrong? 

Subsequent tests may be developed continuously until a measurement instrument satisfies construct validity based on a given conception of the construct, but only on the basis that the concept identified in theory is accepted as legitimate and relevant. That is, the reasoning and considerations that formulates the concept as whatever it is formulated to be must be accepted as valid. If, after continued attempts, we cannot interpret the resulting data as reflective, representative, or indicative of the concept identified in theory, then we must question the identity of the concept itself.

Now evidence against construct validity does not invalidate the idea of the concept outright, but instead shifts discussion from construct validity of a measurement instrument to the very identity of the concept itself, which is a very different, basal, kind of validity. 

Nicely stated by @williams2003, "Validity, as a logical concept, refers to relationships within arguments and is not a measure of the truth about the world that the premises or conclusion of the argument claim." 

The theory must properly identify the concept of interest, providing a foundational conceptual definition. We have no fundamental reference for the thing at base, so we first identify the concept in theory. If we fail to validate measurement of the construct, then all that is left holding the idea together as a viable concept is the theory behind it. That is, the theoretical propositions formulating or identifying the concept are the last line of defense before we must do away with the concept as conceived.

All that is to say, the theory of the concept can be understood as an assertion, the propositions of which serve as an argument to identify a concept. 



[^1]: Not to insult anyone's intelligence, but to make clear the position of my own understanding. Induction is reasoning from the particular to the general, which may be otherwise considered as reasoning based on the available evidence, such as observations from a sample. An inference by inductive reasoning doesn't always have to be correct or true, as such inductive logic allows for the possibility of an inference being false or invalid. Deductive reasoning follows from general premises to particular conclusions. The structure of facts are more important than the facts themselves, such that for deduction the premises **must** always lead to the conclusion. This is the defining criterion for **deduction**. More formally, perhaps, deductive reasoning is inference in which the conclusion about particulars follow *necessarily* from general or universal premises. A**deductive**argument uses a collection of general statements as its premises and uses them to propose a specific situation as the conclusion. As I understand it, a theory is essentially a deductive argument.

-   deductive reasoning follows from general premises to particular conclusions;
-   inductive reasoning follows from particular premises or instances to general conclusions;
-   abductive reasoning follows from a syllogism in which the major premise is evident but the minor premise, and therefore conclusion, is only probable.




> "A valid measure is one which measures what it is intended to measure. In fact, it is not the measure that is valid or invalid but the use to which the measure is put. We might use educational level to measure social status. The issue is not whether we have measured education properly but whether this is a suitable measure of social status. The validity of a measure then depends on how we have defined the concept it is designed to measure." [@devaus2002, 53]

> "Since each experiment checking upon a theory is an opportunity to modify or extend the theory,  validation is more than corroboration; it is a process for developing sounder interpretations of observations." [@cronbach1971, 443]


